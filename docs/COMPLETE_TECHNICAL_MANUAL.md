# å¤šæ¨¡æ…‹åœ–æ–‡å¤šæ¨™ç±¤åˆ†é¡å®Œæ•´å¯¦é©—è¨ˆç•« (SigLIP 2 + æ–¹å‘/å¹…åº¦åˆ†è§£ + Hadamard èåˆ + Hash + KNN)

> **ç‰ˆæœ¬**: v3.0 (çµ±æ•´ç‰ˆ - æ•´åˆ v2.2 + v2.3)  
> **æ—¥æœŸ**: 2026-02-02  
> **å°ˆæ¡ˆ**: AGCH-Improvement  
> **ç¡¬é«”**: RTX 5080 16GB | 32-core CPU | 42GB RAM | **CUDA 12.8**  
> **ç’°å¢ƒ**: Python 3.11+ | PyTorch 2.6.0+cu128 | uv å¥—ä»¶ç®¡ç†  
> **ç›®æ¨™**: åœ¨ MS-COCO è³‡æ–™é›†ä¸Šå¯¦ç¾é«˜æ•ˆèƒ½çš„åœ–æ–‡å¤šæ¨™ç±¤åˆ†é¡ç³»çµ±ï¼ˆå« 5-Fold CVï¼‰

---

## ğŸ“‹ æ›´æ–°æ—¥èªŒ

### v3.4 (2026-02-06) - æ¶ˆèå¯¦é©—å¯¦ä½œç‰ˆ

- âœ… **æ¶ˆèå¯¦é©—æ¶æ§‹**: æ”¯æ´ `skip_hash` åƒæ•¸èˆ‡å‹•æ…‹ classifier ç¶­åº¦èª¿æ•´
- âœ… **å¯¦é©—é…ç½®**: æ–°å¢ `ablation_no_hash.yaml` (AB-1) èˆ‡ `ablation_bce_only.yaml` (AB-3)
- âœ… **è‡ªå‹•åŒ–è…³æœ¬**: å»ºç«‹ `scripts/run_ablation.sh` æ‰¹æ¬¡åŸ·è¡Œæ¶ˆèå¯¦é©—
- âœ… **Baseline å°æ¯”**: å®Œæˆ SigLIP2-MLP Baseline å¯¦é©— (mAP 0.8384) ä¸¦å¯«å…¥å ±å‘Š

### v3.3 (2026-02-05) - æ”¹é€²å¯¦ä½œå•Ÿå‹•ç‰ˆ

- âœ… **Test Set è©•ä¼°ä¿®æ­£**: å®Œæˆ `test_on_holdout.py` é‡æ§‹ï¼Œæ”¯æ´å®Œæ•´ 11 é …æŒ‡æ¨™èˆ‡ `weights_only=False` æ¨¡å‹è¼‰å…¥
- âœ… **5-Fold æŒ‡æ¨™è£œå®Œ**: æ‰‹å‹•æå–ä¸¦æ–¼ `EXPERIMENT_REPORT.md` è£œå…¨ 5 æŠ˜äº¤å‰é©—è­‰çš„ AUC/F1 ç­‰é—œéµæŒ‡æ¨™
- âœ… **æ–°å¢å¯¦ä½œè¨ˆç•«**: å»ºç«‹ `docs/IMPROVEMENT_IMPLEMENTATION_PLAN.md` ä½œç‚ºå¾ŒçºŒåˆ†æèˆ‡å„ªåŒ–å°èˆª
- âœ… **å°ˆæ¡ˆæ¸…ç†**: å°‡èˆŠç‰ˆè¨ˆç•«æ›¸ç§»è‡³ `docs/old/`ï¼Œä¿æŒæ–‡æª”æ•´æ½”

### v3.2 (2026-02-04) - æ¨¡çµ„é‡æ§‹ç‰ˆ

- âœ… **æ¨¡å‹è¼‰å…¥ä¿®æ­£**: æ¡ç”¨ `AutoModel` + `AutoImageProcessor` + `GemmaTokenizerFast` åˆ†é›¢è¼‰å…¥
  - è§£æ±º `Siglip2Processor` tokenizer æ˜ å°„ bug
- âœ… **é…ç½®ç¨ç«‹åŒ–**: `cv_experiment.yaml` ä¸å†ä¾è³´ `hardware` ç¹¼æ‰¿ï¼Œå®Œæ•´ç¨ç«‹é…ç½®
- âœ… **æå¤±å‡½æ•¸ä¿®æ­£**: `compute_total_loss` æ”¹ç‚ºç›´æ¥æ¥æ”¶ `config.loss` å€å¡Š
- âœ… **ç’°å¢ƒé©—è­‰å¢å¼·**: `verify_setup.py` å¤§å¹…æ“´å……è‡³ 7 é …æª¢æŸ¥
- âœ… **æ–°å¢å·¥å…·è…³æœ¬**: `organize_checkpoints.py` ç”¨æ–¼æ•´ç† checkpoint ç›®éŒ„çµæ§‹
- âœ… **å¯¦é©—å ±å‘Šæ–‡ä»¶**: æ–°å¢ `docs/EXPERIMENT_REPORT.md` æ ¼å¼åŒ–å¯¦é©—è¨˜éŒ„

### v3.1 (2026-02-03) - è©•ä¼°æŒ‡æ¨™æ“´å……ç‰ˆ

- âœ… **æ–°å¢è©•ä¼°æŒ‡æ¨™**: åŠ å…¥ 11 å€‹å¤šæ¨™ç±¤åˆ†é¡ç ”ç©¶å¸¸ç”¨æŒ‡æ¨™
  - AUC-ROC (Macro/Micro)
  - Precision & Recall (Macro/Micro)
  - Hamming Loss
  - Coverage Error, Ranking Loss, LRAP
  - MAE (å¹³å‡çµ•å°èª¤å·®)
- âœ… **Checkpoint è·¯å¾‘ä¿®æ­£**: ä¿®å¾© 5-Fold CV çš„ checkpoint å„²å­˜ç›®éŒ„å•é¡Œ
  - æ¯å€‹ fold å„²å­˜åˆ°ç¨ç«‹ç›®éŒ„: `outputs/checkpoints/{exp_name}/best_model.pth`
- âœ… **èšåˆè…³æœ¬å‡ç´š**: æ”¯æ´æ‰€æœ‰æ–°æŒ‡æ¨™çš„çµ±è¨ˆèˆ‡è«–æ–‡æ ¼å¼è¼¸å‡º
- âœ… **wandb è¨˜éŒ„æ“´å……**: æ–°å¢æŒ‡æ¨™è‡ªå‹•åŒæ­¥åˆ° Weights & Biases

### v3.0 (2026-02-02) - çµ±æ•´ç‰ˆ

- âœ… **æ–‡ä»¶æ•´åˆ**: åˆä½µ v2.2 èˆ‡ v2.3 çš„æ‰€æœ‰å…§å®¹
- âœ… **æ–°å¢ 5-Fold CV ç« ç¯€**: å®Œæ•´çš„äº”æŠ˜äº¤å‰é©—è­‰å¯¦ä½œæŒ‡å—
- âœ… **ç¨‹å¼ç¢¼æ›´æ–°**: æ•´åˆæœ€æ–°çš„ K-Fold æ”¯æ´

### v2.3 (2026-01-31) - äº”æŠ˜äº¤å‰é©—è­‰ç‰ˆ

- âœ… **æ¡ç”¨ 5-Fold CV**: æå‡å¯¦é©—å¯ä¿¡åº¦èˆ‡è«–æ–‡èªªæœåŠ›
- âœ… **åš´æ ¼è³‡æ–™éš”é›¢**: Karpathy Test Set å®Œå…¨ä¸ç¢°ï¼Œåƒ…ç”¨æ–¼æœ€çµ‚è©•ä¼°
- âœ… **Dev Pool è¨­è¨ˆ**: train + val åˆä½µï¼ˆ~118,287 å¼µï¼‰
- âœ… **è¨“ç·´å„ªåŒ–**: epochs 30â†’20, patience 5â†’3ï¼ˆåŠ é€Ÿæ”¶æ–‚ï¼‰
- âœ… **è‡ªå‹•åŒ–æµç¨‹**: Shell Script æ§åˆ¶ 5 è¼ªè¨“ç·´
- âœ… **çµæœèšåˆ**: æä¾› Mean Â± Std çš„æ¨™æº–å­¸è¡“å ±å‘Š

### v2.2 (2026-01-30) - AGCH-Improvement å°ˆæ¡ˆå„ªåŒ–ç‰ˆ

- âœ… **CUDA ç‰ˆæœ¬ä¿®æ­£**: 13.0 â†’ **12.4**ï¼ˆå°æ‡‰ä½ çš„ç³»çµ±ï¼‰
- âœ… **PyTorch é…ç½®**: å·²è¨­å®š pytorch-cu124 index
- âœ… **å°ˆæ¡ˆçµæ§‹æ•´åˆ**: å®Œå…¨å°æ‡‰ `AGCH-Improvement` å°ˆæ¡ˆ
- âœ… **è…³æœ¬å°é½Š**: æ‰€æœ‰ç¨‹å¼ç¢¼åŒ¹é…ä½ ç¾æœ‰çš„ scripts/
- âœ… **FAISS å‡ç´šæŒ‡å¼•**: faiss-cpu â†’ faiss-gpu
- âœ… **è³‡æ–™é›†è·¯å¾‘**: å°æ‡‰ä½ çš„ `data/coco/` çµæ§‹
- âœ… **Python ç‰ˆæœ¬**: 3.11+ (ç¬¦åˆ pyproject.toml)

### é‡å° RTX 5080 16GB çš„æ ¸å¿ƒå„ªåŒ–

- âœ… Batch size: 64 â†’ **32**
- âœ… æ··åˆç²¾åº¦: **å¿…é ˆå•Ÿç”¨**
- âœ… æ¢¯åº¦ç´¯ç©: **2 æ­¥**
- âœ… è¨˜æ†¶é«”ç›£æ§: å¯¦æ™‚è¿½è¹¤
- âœ… DataLoader: åˆ©ç”¨ 32 æ ¸å¿ƒï¼ˆnum_workers=16ï¼‰

---

## ç›®éŒ„

1. [å°ˆæ¡ˆçµæ§‹](#1-å°ˆæ¡ˆçµæ§‹)
2. [ç’°å¢ƒé…ç½®](#2-ç’°å¢ƒé…ç½®)
3. [å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³](#3-å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³)
4. [è³‡æ–™é›†å”è­°](#4-è³‡æ–™é›†å”è­°)
5. [æ¨¡å‹æ¶æ§‹](#5-æ¨¡å‹æ¶æ§‹)
6. [æ¨è«–ç­–ç•¥](#6-æ¨è«–ç­–ç•¥)
7. [å¯¦é©—è¨­è¨ˆ](#7-å¯¦é©—è¨­è¨ˆ)
8. [è¶…åƒæ•¸é…ç½® (RTX 5080 å„ªåŒ–)](#8-è¶…åƒæ•¸é…ç½®-rtx-5080-å„ªåŒ–)
9. [å¯¦ä½œç´°ç¯€ (è¨˜æ†¶é«”å„ªåŒ–)](#9-å¯¦ä½œç´°ç¯€-è¨˜æ†¶é«”å„ªåŒ–)
10. [è¶…åƒæ•¸é…ç½® (å°æ‡‰ä½ çš„å°ˆæ¡ˆ)](#10-è¶…åƒæ•¸é…ç½®-å°æ‡‰ä½ çš„å°ˆæ¡ˆ)
11. [å¯¦ä½œç´°ç¯€ (å®Œæ•´ç¨‹å¼ç¢¼)](#11-å¯¦ä½œç´°ç¯€-å®Œæ•´ç¨‹å¼ç¢¼)
12. [è©•ä¼°æŒ‡æ¨™](#12-è©•ä¼°æŒ‡æ¨™)
13. [ç¡¬é«”ç‰¹å®šå„ªåŒ–](#13-ç¡¬é«”ç‰¹å®šå„ªåŒ–)
14. [åƒè€ƒæ–‡ç»](#14-åƒè€ƒæ–‡ç»)
15. [é™„éŒ„](#15-é™„éŒ„)
16. [äº”æŠ˜äº¤å‰é©—è­‰ (5-Fold CV)](#16-äº”æŠ˜äº¤å‰é©—è­‰-5-fold-cv)
17. [æ¶ˆèå¯¦é©—èˆ‡ Hash+KNN ç­–ç•¥è©•ä¼°](#17-æ¶ˆèå¯¦é©—èˆ‡-hashknn-ç­–ç•¥è©•ä¼°)

---

## 1. å°ˆæ¡ˆçµæ§‹

### 1.1 ç›®å‰çš„ç›®éŒ„æ¨¹

```plaintext
AGCH-Improvement/
â”œâ”€â”€ configs/                    # âœ… å¯¦é©—èˆ‡ç¡¬é«”é…ç½®
â”‚   â”œâ”€â”€ experiments/           # å¯¦é©—åƒæ•¸
â”‚   â”‚   â”œâ”€â”€ ablation_fusion.yaml
â”‚   â”‚   â”œâ”€â”€ ablation_hash.yaml
â”‚   â”‚   â”œâ”€â”€ baseline.yaml      # Baseline å¯¦é©—é…ç½®ï¼ˆæ”¹é€²ç‰ˆï¼‰
â”‚   â”‚   â”œâ”€â”€ siglip2_mlp_baseline.yaml  # ç´” MLP Baseline é…ç½®
â”‚   â”‚   â”œâ”€â”€ cv_experiment.yaml # 5-Fold CV å¯¦é©—é…ç½®
â”‚   â”‚   â””â”€â”€ grid_search.yaml
â”‚   â””â”€â”€ hardware/              # ç¡¬é«”è³‡æºé…ç½®
â”‚       â””â”€â”€ rtx5080_16gb.yaml  # RTX 5080 å°ˆç”¨é…ç½®
â”‚
â”œâ”€â”€ data/                      # è³‡æ–™é›†ç›®éŒ„
â”‚   â””â”€â”€ coco/                  # âœ… å·²æº–å‚™
â”‚       â”œâ”€â”€ 5fold_split.json   # âœ… 5-Fold åˆ‡åˆ†æª”
â”‚       â”œâ”€â”€ annotations/       # COCO æ¨™è¨»
â”‚       â”œâ”€â”€ images/            # COCO å½±åƒ
â”‚       â”‚   â”œâ”€â”€ train2014/     # 82,783 å¼µè¨“ç·´å½±åƒ
â”‚       â”‚   â””â”€â”€ val2014/       # 40,504 å¼µé©—è­‰å½±åƒ
â”‚       â”œâ”€â”€ index_train2014.pkl # âœ… å¿«é€Ÿç´¢å¼• (Train)
â”‚       â”œâ”€â”€ index_val2014.pkl   # âœ… å¿«é€Ÿç´¢å¼• (Val)
â”‚       â””â”€â”€ karpathy_split.json # å¾…ä¸‹è¼‰
â”‚
â”œâ”€â”€ docs/                      # å°ˆæ¡ˆæ–‡ä»¶
â”‚   â”œâ”€â”€ COMPLETE_TECHNICAL_MANUAL.md # æœ¬æŠ€è¡“æ‰‹å†Š
â”‚   â””â”€â”€ EXPERIMENT_REPORT.md         # å¯¦é©—å ±å‘Š
â”‚
â”œâ”€â”€ experiments/               # å¯¦é©—è¨˜éŒ„
â”‚   â”œâ”€â”€ baseline_rtx5080/     # å¯¦é©—è¼¸å‡º
â”‚   â”œâ”€â”€ tensorboard/          # TensorBoard æ—¥èªŒ
â”‚   â””â”€â”€ wandb/                # W&B æ—¥èªŒ
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”‚
â”œâ”€â”€ outputs/                  # æ¨¡å‹ç”¢å‡º
â”‚   â””â”€â”€ checkpoints/          # è¨“ç·´æª¢æŸ¥é»
â”‚
â”œâ”€â”€ scripts/                  # âœ… åŸ·è¡Œè…³æœ¬ (å®Œæ•´)
â”‚   â”œâ”€â”€ aggregate_cv_results.py   # CV çµæœèšåˆ
â”‚   â”œâ”€â”€ analyze_dataset.py        # è³‡æ–™é›†åˆ†æ
â”‚   â”œâ”€â”€ build_knn_index.py        # KNN ç´¢å¼•å»ºç«‹
â”‚   â”œâ”€â”€ create_dataset_index.py   # å»ºç«‹å¿«é€Ÿç´¢å¼•
â”‚   â”œâ”€â”€ create_kfold_split.py     # å»ºç«‹ 5-Fold Split
â”‚   â”œâ”€â”€ download_coco.sh          # ä¸‹è¼‰ COCO
â”‚   â”œâ”€â”€ download_karpathy_split.py
â”‚   â”œâ”€â”€ evaluate.py               # æ¨¡å‹è©•ä¼°
â”‚   â”œâ”€â”€ monitor_training.sh       # è¨“ç·´ç›£æ§
â”‚   â”œâ”€â”€ run_5fold_cv.sh           # åŸ·è¡Œ 5-Fold CV
â”‚   â”œâ”€â”€ organize_checkpoints.py  # Checkpoint æ•´ç†å·¥å…·
â”‚   â”œâ”€â”€ test_on_holdout.py        # Hold-out æ¸¬è©¦
â”‚   â”œâ”€â”€ test_siglip2.py           # æ¨¡å‹æ¸¬è©¦
â”‚   â”œâ”€â”€ train.py                  # ä¸»è¨“ç·´è…³æœ¬ï¼ˆæ”¹é€²ç‰ˆï¼‰
â”‚   â”œâ”€â”€ train_baseline.py         # Baseline è¨“ç·´è…³æœ¬ï¼ˆç´” MLPï¼‰
â”‚   â””â”€â”€ verify_setup.py           # ç’°å¢ƒé©—è­‰ (7 é …æª¢æŸ¥)
â”‚
â”œâ”€â”€ src/                      # âœ… æ ¸å¿ƒåŸå§‹ç¢¼ (å®Œæ•´)
â”‚   â””â”€â”€ siglip2_multimodal_hash/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ baseline_model.py # SigLIP2-MLP Baseline æ¨¡å‹
â”‚       â”œâ”€â”€ dataset.py        # è³‡æ–™è¼‰å…¥å™¨
â”‚       â”œâ”€â”€ knn.py            # KNN æª¢ç´¢æ¨¡çµ„
â”‚       â”œâ”€â”€ losses.py         # æå¤±å‡½æ•¸ (BCE+Cos+Hash)
â”‚       â”œâ”€â”€ model.py          # SigLIP2+Hash æ¨¡å‹æ¶æ§‹ï¼ˆæ”¹é€²ç‰ˆï¼‰
â”‚       â””â”€â”€ utils.py          # å·¥å…·å‡½æ•¸
â”‚
â”œâ”€â”€ utils/                    # é€šç”¨å·¥å…·
â”‚   â””â”€â”€ memory_monitor.py     # è¨˜æ†¶é«”ç›£æ§
â”‚
â”œâ”€â”€ .gitignore               # âœ… Git è¨­å®š
â”œâ”€â”€ .venv/                   # âœ… è™›æ“¬ç’°å¢ƒ
â”œâ”€â”€ pyproject.toml           # âœ… å°ˆæ¡ˆé…ç½® (CUDA 12.8 Nightly)
â”œâ”€â”€ README.md                # âœ… å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ requirements.txt         # âœ… ä¾è³´æ¸…å–®
â””â”€â”€ uv.lock                  # âœ… ç‰ˆæœ¬é–å®š
```

### 1.2 å¾…å»ºç«‹çš„æª”æ¡ˆæ¸…å–®

#### é…ç½®æª”æ¡ˆ

```bash
# å»ºç«‹é…ç½®ç›®éŒ„çµæ§‹
mkdir -p configs/{experiments,hardware}

# æ ¸å¿ƒé…ç½®æª”æ¡ˆï¼ˆä¸‹æ–‡æœƒæä¾›å…§å®¹ï¼‰
configs/hardware/rtx5080_16gb.yaml          # RTX 5080 ç¡¬é«”é…ç½®
configs/experiments/baseline.yaml           # Baseline å¯¦é©—é…ç½®
configs/experiments/ablation_fusion.yaml    # Fusion ç­–ç•¥ ablation
configs/experiments/ablation_hash.yaml      # Hash bits ablation
```

#### åŸå§‹ç¢¼

```bash
# æ ¸å¿ƒæ¨¡å‹æª”æ¡ˆï¼ˆä¸‹æ–‡æœƒæä¾›å®Œæ•´å¯¦ä½œï¼‰
src/siglip2_multimodal_hash/model.py        # æ¨¡å‹å®šç¾©
src/siglip2_multimodal_hash/dataset.py      # è³‡æ–™è¼‰å…¥å™¨
src/siglip2_multimodal_hash/losses.py       # æå¤±å‡½æ•¸
src/siglip2_multimodal_hash/utils.py        # å·¥å…·å‡½æ•¸
src/siglip2_multimodal_hash/knn.py          # KNN æª¢ç´¢
```

#### è¨“ç·´èˆ‡è©•ä¼°è…³æœ¬

```bash
# ä¸»è¦è…³æœ¬ï¼ˆä¸‹æ–‡æœƒæä¾›å®Œæ•´å¯¦ä½œï¼‰
scripts/train.py                            # è¨“ç·´è…³æœ¬
scripts/evaluate.py                         # è©•ä¼°è…³æœ¬
scripts/build_knn_index.py                  # å»ºç«‹ KNN ç´¢å¼•
scripts/monitor_training.sh                 # GPU ç›£æ§è…³æœ¬
```

---

## 2. ç’°å¢ƒé…ç½®

### 2.1 ç•¶å‰ç’°å¢ƒç‹€æ…‹

```bash
# æª¢æŸ¥ç•¶å‰ç’°å¢ƒ
python --version
# Python 3.12.8 (ä½ çš„ requirements.txt é¡¯ç¤º)

torch --version
# 2.6.0+cu124 (âœ… æ­£ç¢ºçš„ CUDA 12.8 Nightly ç‰ˆæœ¬)

nvidia-smi
# Driver: 580.126.09, CUDA: 13.0 (runtime æ”¯æ´ 12.4)
```

### 2.2 pyproject.toml é…ç½®æª¢æŸ¥

ä½ çš„ `pyproject.toml` å·²æ­£ç¢ºé…ç½®ï¼š

```toml
# âœ… æ­£ç¢ºï¼šCUDA 12.8 Nightly ç‰ˆæœ¬
[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu124", marker = "sys_platform == 'linux'" },
]
torchvision = [
  { index = "pytorch-cu124", marker = "sys_platform == 'linux'" },
]
```

### 2.3 å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬

ä½ ç•¶å‰ä½¿ç”¨ `faiss-cpu`ï¼Œéœ€è¦å‡ç´šåˆ° GPU ç‰ˆæœ¬ï¼š

```bash
# æ–¹æ³• 1: ä½¿ç”¨ condaï¼ˆæ¨è–¦ï¼‰
conda install -c pytorch -c nvidia faiss-gpu

# æ–¹æ³• 2: å¾æºç¢¼ç·¨è­¯ï¼ˆå¦‚æœ conda å¤±æ•—ï¼‰
# è¦‹ä¸‹æ–‡ 2.4 ç¯€

# é©—è­‰
python -c "import faiss; print(f'FAISS version: {faiss.__version__}')"
python -c "import faiss; print(f'GPU support: {hasattr(faiss, \"index_gpu_to_cpu\")}')"
```

### 2.4 FAISS-GPU å¾æºç¢¼ç·¨è­¯ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰

```bash
# å®‰è£ä¾è³´
sudo apt-get update
sudo apt-get install cmake libopenblas-dev

# ä¸‹è¼‰ FAISS
cd ~/Downloads
git clone https://github.com/facebookresearch/faiss.git
cd faiss

# é…ç½®ï¼ˆé‡å° RTX 5080 Ada Lovelaceï¼Œcompute capability 8.9ï¼‰
cmake -B build \
  -DFAISS_ENABLE_GPU=ON \
  -DFAISS_ENABLE_PYTHON=ON \
  -DCMAKE_BUILD_TYPE=Release \
  -DCMAKE_CUDA_ARCHITECTURES=89 \
  -DCMAKE_CUDA_COMPILER=/usr/local/cuda-12.4/bin/nvcc \
  .

# ç·¨è­¯ï¼ˆåˆ©ç”¨ 32 æ ¸å¿ƒï¼‰
make -C build -j32

# å®‰è£
cd build/faiss/python
pip install .

# é©—è­‰
python -c "import faiss; print('FAISS-GPU installed successfully')"
```

### 2.5 ç’°å¢ƒé©—è­‰

```bash
# åŸ·è¡Œä½ å·²æœ‰çš„é©—è­‰è…³æœ¬
cd ~/Documents/Coding/github.com/natsuki221/AGCH-Improvement
python scripts/verify_setup.py
```

**é æœŸè¼¸å‡º**:

```bash
============================================================
ç’°å¢ƒé©—è­‰
============================================================

[1/5] æª¢æŸ¥ Python ç‰ˆæœ¬...
âœ“ Python 3.12.8

[2/5] æª¢æŸ¥ CUDA...
âœ“ CUDA 12.8 Nightly
  GPU: NVIDIA GeForce RTX 5080
  VRAM: 16.3 GB

[3/5] æª¢æŸ¥ Python å¥—ä»¶...
âœ“ torch                2.6.0+cu124
âœ“ transformers         5.0.0
âœ“ faiss                1.13.2  # âš ï¸ éœ€ç¢ºèªæ˜¯å¦ç‚º GPU ç‰ˆæœ¬
âœ“ pycocotools          2.0.11

[4/5] æª¢æŸ¥è³‡æ–™é›†...
âœ“ ./data/coco/images/train2014 (82,783 å¼µå½±åƒ)
âœ“ ./data/coco/images/val2014 (40,504 å¼µå½±åƒ)
âœ“ ./data/coco/annotations/instances_train2014.json (145.6 MB)
âœ“ ./data/coco/annotations/captions_train2014.json (78.2 MB)
âœ— ./data/coco/index_train2014.pkl ä¸å­˜åœ¨  # âš ï¸ éœ€å»ºç«‹

[5/5] æª¢æŸ¥ SigLIP2 æ¨¡å‹...
æ­£åœ¨æ¸¬è©¦ SigLIP2 æ¨¡å‹è¼‰å…¥...
âœ“ SigLIP2 æ¨¡å‹è¼‰å…¥æˆåŠŸ
  åƒæ•¸é‡: 87.1M

============================================================
âš ï¸  éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œè«‹ä¿®æ­£å¾Œå†è©¦ã€‚
============================================================
```

### 2.6 å»ºç«‹è³‡æ–™é›†ç´¢å¼•

```bash
# åŸ·è¡Œä½ å·²æœ‰çš„ç´¢å¼•å»ºç«‹è…³æœ¬
python scripts/create_dataset_index.py

# é æœŸè¼¸å‡ºï¼š
# æ­£åœ¨è™•ç† train2014...
# Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82783/82783 [01:23<00:00, 991.32it/s]
# âœ“ ç´¢å¼•å·²å„²å­˜: data/coco/index_train2014.pkl
#   - å½±åƒæ•¸é‡: 82,783
#   - é¡åˆ¥æ•¸é‡: 80
# 
# æ­£åœ¨è™•ç† val2014...
# Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40504/40504 [00:41<00:00, 978.15it/s]
# âœ“ ç´¢å¼•å·²å„²å­˜: data/coco/index_val2014.pkl
#   - å½±åƒæ•¸é‡: 40,504
#   - é¡åˆ¥æ•¸é‡: 80
# 
# âœ“ æ‰€æœ‰ç´¢å¼•å»ºç«‹å®Œæˆï¼

# ä¸‹è¼‰ Karpathy split
python scripts/download_karpathy_split.py
```

---

## 3. å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³

### 3.1 ä»»å‹™å®šç¾©

- **è¼¸å…¥**: åœ–ç‰‡ `image` + å°æ‡‰æ–‡å­—æ•˜è¿° `caption`
- **è¼¸å‡º**: `C` å€‹ tags çš„ multi-hot å‘é‡ $y \in \{0,1\}^C$
- **è³‡æ–™é›†**: MS-COCO (80 å€‹ç‰©ä»¶é¡åˆ¥)

### 3.2 æ ¸å¿ƒå‰µæ–°é»

æœ¬ç ”ç©¶æå‡ºä¸€å€‹çµåˆç›£ç£å¼å­¸ç¿’èˆ‡è¿‘é„°æª¢ç´¢çš„æ··åˆæ¶æ§‹ï¼š

1. **æ–¹å‘/å¹…åº¦åˆ†è§£ (æ–¹æ¡ˆ B)**
   - å°‡ embedding åˆ†è§£ç‚ºã€Œæ–¹å‘ã€ï¼ˆèªæ„ï¼‰èˆ‡ã€Œå¹…åº¦ã€ï¼ˆç½®ä¿¡åº¦ï¼‰
   - ç†è«–å‹•æ©Ÿï¼šä¿ç•™å‘é‡çš„å¼·åº¦è³‡è¨Šï¼Œé¿å… L2 æ­£è¦åŒ–éæ—©æ¶ˆé™¤ç½®ä¿¡åº¦è¨Šè™Ÿ

2. **Hadamard ä¹˜ç©èåˆ**
   - æ•æ‰è·¨æ¨¡æ…‹çš„ dimension-wise å…±ç¾æ¨¡å¼ (co-activation pattern)
   - åƒè€ƒ VQA é ˜åŸŸçš„ MCB/MUTAN æ–¹æ³•

3. **å¯å­¸ç¿’ Hash å±¤**
   - åˆ©æ–¼é«˜æ•ˆè¿‘é„°æª¢ç´¢ (Hamming space)
   - æ”¯æ´å¤§è¦æ¨¡è³‡æ–™åº«çš„å¿«é€Ÿæª¢ç´¢

4. **KNN åŠ æ¬ŠæŠ•ç¥¨**
   - çµåˆç›£ç£å¼èˆ‡éåƒæ•¸å¼åˆ†é¡çš„å„ªå‹¢
   - æä¾›å¯è§£é‡‹æ€§ï¼ˆå¯è¦–è¦ºåŒ–é„°å±…æ¨£æœ¬ï¼‰

---

## 4. è³‡æ–™é›†å”è­°

### 4.1 MS-COCO åŸºæœ¬è³‡è¨Šï¼ˆä½ å·²ä¸‹è¼‰ï¼‰

- **ç‰ˆæœ¬**: COCO 2014 (train2014 + val2014) âœ…
- **å½±åƒæ•¸é‡**:
  - è¨“ç·´é›†: 82,783 å¼µ âœ…
  - é©—è­‰é›†: 40,504 å¼µ âœ…
- **ç‰©ä»¶é¡åˆ¥**: 80 å€‹ (detection annotations) âœ…
- **Captions**: æ¯å¼µåœ–ç‰‡æœ‰ 5 å€‹äººå·¥æ¨™è¨»çš„ captions âœ…

### 4.2 å¯¦é©—åˆ‡åˆ†å”è­°

æ¡ç”¨ **Karpathy split**ï¼ˆå½±åƒæª¢ç´¢èˆ‡ captioning ç¤¾ç¾¤æ¨™æº–ï¼‰ï¼š

| Split | å½±åƒæ•¸é‡ | ç”¨é€” | ç‹€æ…‹ |
| ------- | --------- | ------ | ------ |
| Train | 113,287 | æ¨¡å‹è¨“ç·´ | âš ï¸ å¾…ä¸‹è¼‰ karpathy_split.json |
| Val | 5,000 | è¶…åƒæ•¸èª¿æ•´ã€early stopping | åŒä¸Š |
| Test | 5,000 | æœ€çµ‚è©•ä¼° | åŒä¸Š |

**ä¸‹è¼‰ Karpathy split**:

```bash
python scripts/download_karpathy_split.py
```

### 4.3 è³‡æ–™é›†è·¯å¾‘å°æ‡‰

```python
# åœ¨ä½ çš„å°ˆæ¡ˆä¸­ä½¿ç”¨ä»¥ä¸‹è·¯å¾‘
DATA_ROOT = Path("./data/coco")  # å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ data/coco/

# å½±åƒè·¯å¾‘
TRAIN_IMG_DIR = DATA_ROOT / "images/train2014"
VAL_IMG_DIR = DATA_ROOT / "images/val2014"

# æ¨™è¨»è·¯å¾‘
TRAIN_ANNO = DATA_ROOT / "annotations/instances_train2014.json"
TRAIN_CAP = DATA_ROOT / "annotations/captions_train2014.json"

# ç´¢å¼•è·¯å¾‘
TRAIN_INDEX = DATA_ROOT / "index_train2014.pkl"
VAL_INDEX = DATA_ROOT / "index_val2014.pkl"

# Karpathy split
KARPATHY_SPLIT = DATA_ROOT / "karpathy_split.json"
```

---

## 5. æ¨¡å‹æ¶æ§‹

### 5.1 å®Œæ•´æ¶æ§‹åœ–

```mermaid
flowchart TB

subgraph INPUT["è¼¸å…¥å±¤"]
    I["Image<br/>(ä»»æ„è§£æåº¦)"]
    T["Caption<br/>(æ–‡å­—æ•˜è¿°)"]
end

subgraph ENCODER["ç·¨ç¢¼å™¨å±¤ (SigLIP2)"]
    P1["SigLIP2 Processor<br/>(NaFlex mode)"]
    P2["SigLIP2 Processor<br/>(Text tokenizer)"]
    
    IT["Image Tower<br/>(Vision Transformer)<br/>âš ï¸ å¿…é ˆå‡çµ"]
    TT["Text Tower<br/>(Language Transformer)<br/>âš ï¸ å¿…é ˆå‡çµ"]
    
    I --> P1
    T --> P2
    P1 --> IT
    P2 --> TT
    
    IT --> V_img["v_img âˆˆ â„áµˆ<br/>(raw image embedding)"]
    TT --> V_txt["v_txt âˆˆ â„áµˆ<br/>(raw text embedding)"]
end

subgraph DECOMPOSE["æ–¹å‘/å¹…åº¦åˆ†è§£å±¤ (æ–¹æ¡ˆ B)"]
    V_img --> CALC_IMG["è¨ˆç®—:<br/>n_img = ||v_img||â‚‚<br/>d_img = v_img / (n_img + Îµ)<br/>m_img = log(n_img + Îµ)"]
    V_txt --> CALC_TXT["è¨ˆç®—:<br/>n_txt = ||v_txt||â‚‚<br/>d_txt = v_txt / (n_txt + Îµ)<br/>m_txt = log(n_txt + Îµ)"]
    
    CALC_IMG --> D_img["d_img<br/>(æ–¹å‘, unit vector)"]
    CALC_IMG --> M_img["m_img<br/>(å¹…åº¦, log-norm)"]
    
    CALC_TXT --> D_txt["d_txt<br/>(æ–¹å‘, unit vector)"]
    CALC_TXT --> M_txt["m_txt<br/>(å¹…åº¦, log-norm)"]
end

subgraph FUSION["èåˆå±¤ (å¯è¨“ç·´)"]
    D_img --> HADAMARD["Hadamard ä¹˜ç©:<br/>p_dir = d_img âŠ™ d_txt"]
    D_txt --> HADAMARD
    
    D_img --> CONCAT["æ‹¼æ¥:<br/>[d_img; d_txt; p_dir; m_img; m_txt]"]
    D_txt --> CONCAT
    HADAMARD --> CONCAT
    M_img --> CONCAT
    M_txt --> CONCAT
    
    CONCAT --> MLP["Fusion MLP<br/>[3d+2 â†’ 1024 â†’ 512]<br/>+ Dropout + ReLU"]
    MLP --> Z["z âˆˆ â„âµÂ¹Â²<br/>(èåˆ embedding)"]
end

subgraph HASH["Hash å±¤ (å¯è¨“ç·´)"]
    Z --> H_LAYER["Hash Transform:<br/>h = tanh(W_h Â· z + b_h)<br/>h âˆˆ â„á´® (B=64)"]
end

subgraph TRAIN["è¨“ç·´åˆ†æ”¯ (Supervised)"]
    H_LAYER --> HEAD["åˆ†é¡ Head:<br/>logits = W_cls Â· h + b_cls<br/>logits âˆˆ â„á¶œ (C=80)"]
    HEAD --> BCE["BCEWithLogitsLoss"]
    GT["Ground Truth<br/>y_true âˆˆ {0,1}â¸â°"] --> BCE
    
    D_img --> L_COS["Cosine Alignment Loss:<br/>L_cos = 1 - cos(d_img, d_txt)"]
    D_txt --> L_COS
    
    H_LAYER --> L_HASH["Hash Regularization:<br/>L_quant + L_balance + L_decorr"]
    
    BCE --> TOTAL["Total Loss:<br/>L = L_bce + Î±Â·L_cos + Î³Â·L_hash"]
    L_COS --> TOTAL
    L_HASH --> TOTAL
end

subgraph INFERENCE["æ¨è«–åˆ†æ”¯ (KNN)"]
    H_LAYER --> INDEX["Hash Index<br/>(FAISS binary index)"]
    INDEX --> KNN_SEARCH["KNN Search<br/>(Hamming distance)"]
    KNN_SEARCH --> NEIGHBORS["Top-K Neighbors<br/>{(h_i, y_i, sim_i)}"]
    NEIGHBORS --> VOTE["åŠ æ¬ŠæŠ•ç¥¨:<br/>score_c = Î£ w_i Â· y_i,c<br/>w_i = softmax(sim_i / Ï„)"]
    VOTE --> OUTPUT["Top-N Tags<br/>(sorted by score)"]
end

subgraph MEMORY["âš ï¸ è¨˜æ†¶é«”ç®¡ç† (16GB VRAM)"]
    MEM1["Mixed Precision (FP16)<br/>ç¯€çœ 40% VRAM"]
    MEM2["Gradient Accumulation<br/>æ¨¡æ“¬å¤§ batch size"]
    MEM3["Gradient Checkpointing<br/>ç¯€çœ 30% VRAM"]
    MEM4["å®šæœŸæ¸…ç† CUDA å¿«å–"]
end

style INPUT fill:#e1f5ff
style ENCODER fill:#fff4e1
style DECOMPOSE fill:#ffe1f5
style FUSION fill:#e1ffe1
style HASH fill:#ffe1e1
style TRAIN fill:#f5e1ff
style INFERENCE fill:#e1ffff
style MEMORY fill:#ffcccc
```

### 5.2 ç¸½é«”æå¤±å‡½æ•¸

$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{bce}} + \alpha \mathcal{L}_{\text{cos}} + \gamma \mathcal{L}_{\text{hash}}
$$

**æ³¨æ„**: ç§»é™¤ Euclidean lossï¼ˆå› å…¶èˆ‡ cosine é«˜åº¦è€¦åˆï¼‰

### 5.2 Binary Cross-Entropy Loss (ä¸»è¦ç›£ç£è¨Šè™Ÿ)

$$
\mathcal{L}_{\text{bce}} = -\frac{1}{C} \sum_{c=1}^C \left[ y_c \log \hat{y}_c + (1-y_c) \log(1-\hat{y}_c) \right]
$$

å…¶ä¸­ï¼š
$$
\hat{y}_c = \sigma(\text{logit}_c), \quad \text{logit}_c = (W_{\text{cls}} h + b_{\text{cls}})_c
$$

**é¡åˆ¥ä¸å¹³è¡¡è™•ç†**:

- è€ƒæ…®ä½¿ç”¨ **Focal Loss** æˆ– **class-balanced weights**
- COCO 80 é¡åˆ¥åˆ†å¸ƒä¸å‡ï¼ˆperson å‡ºç¾é »ç‡é é«˜æ–¼ toothbrushï¼‰

### 5.3 Cosine Alignment Loss

$$
\mathcal{L}_{\text{cos}} = 1 - \cos(d_{img}, d_{txt}) = 1 - \frac{d_{img}^\top d_{txt}}{\|d_{img}\|_2 \|d_{txt}\|_2}
$$

ç”±æ–¼ $d$ å·²æ˜¯ unit vectorï¼š
$$
\mathcal{L}_{\text{cos}} = 1 - d_{img}^\top d_{txt}
$$

**ç‰©ç†æ„ç¾©**: é¼“å‹µé…å°çš„åœ–æ–‡åœ¨æ–¹å‘ç©ºé–“ä¸­å°é½Š

### 5.4 Hash Regularization (ä¸‰é …çµ„åˆ)

#### 5.4.1 Quantization Loss (æ¨å‘ Â±1)

$$
\mathcal{L}_{\text{quant}} = \frac{1}{B} \sum_{i=1}^B (|h_i| - 1)^2
$$

#### 5.4.2 Bit Balance Loss (é¿å…æ‰€æœ‰ bit åå‘åŒä¸€æ¥µ)

$$
\mathcal{L}_{\text{balance}} = \frac{1}{B} \sum_{i=1}^B \left( \frac{1}{N} \sum_{n=1}^N h_{n,i} \right)^2
$$

å…¶ä¸­ $N$ æ˜¯ batch sizeï¼Œ$h_{n,i}$ æ˜¯ç¬¬ $n$ å€‹æ¨£æœ¬çš„ç¬¬ $i$ å€‹ bitã€‚

**ç‰©ç†æ„ç¾©**: å¸Œæœ›æ¯å€‹ bit åœ¨ batch ä¸­çš„å‡å€¼æ¥è¿‘ 0ï¼ˆä¸€åŠ +1ï¼Œä¸€åŠ -1ï¼‰

#### 5.4.3 Bit Decorrelation Loss (é¼“å‹µ bit ç¨ç«‹)

$$
\mathcal{L}_{\text{decorr}} = \frac{1}{B^2} \sum_{i \neq j} (\text{Cov}(h_i, h_j))^2
$$

ç°¡åŒ–å¯¦ä½œï¼ˆä½¿ç”¨ Frobenius normï¼‰:
$$
\mathcal{L}_{\text{decorr}} = \|\text{Cov}(H)\|_F^2 - \text{trace}(\text{Cov}(H)^2)
$$

**ç¸½ hash loss**:
$$
\mathcal{L}_{\text{hash}} = \mathcal{L}_{\text{quant}} + \lambda_1 \mathcal{L}_{\text{balance}} + \lambda_2 \mathcal{L}_{\text{decorr}}
$$

---

## 6. æ¨è«–ç­–ç•¥

### 6.1 å»ºç«‹ Hash Index

```python
import faiss
import numpy as np

# 1. æå–è¨“ç·´é›†çš„ hash codes
train_hashes = []  # List of np.ndarray, shape (B,)
train_labels = []  # List of np.ndarray, shape (C,)

for batch in train_loader:
    with torch.no_grad():
        h = model.get_hash(batch)  # shape: (batch_size, B)
        train_hashes.append(h.cpu().numpy())
        train_labels.append(batch['labels'].cpu().numpy())

train_hashes = np.vstack(train_hashes)  # (N_train, B)
train_labels = np.vstack(train_labels)  # (N_train, C)

# 2. äºŒå€¼åŒ–ï¼ˆhard binaryï¼‰
train_binary = (train_hashes > 0).astype(np.uint8)  # {0, 1}^B

# 3. å»ºç«‹ FAISS binary index
index = faiss.IndexBinaryFlat(B)  # Hamming distance index
index.add(train_binary)
```

### 6.2 KNN æª¢ç´¢èˆ‡æŠ•ç¥¨

```python
def predict_tags(query_hash, index, train_labels, K=20, tau=0.07, top_n=5):
    """
    Args:
        query_hash: (B,) torch.Tensor or np.ndarray
        index: faiss.IndexBinaryFlat
        train_labels: (N_train, C) np.ndarray
        K: number of neighbors
        tau: temperature for softmax
        top_n: number of tags to return
    
    Returns:
        predicted_tags: (top_n,) np.ndarray (tag indices)
        scores: (top_n,) np.ndarray (confidence scores)
    """
    # 1. äºŒå€¼åŒ– query
    query_binary = (query_hash > 0).astype(np.uint8).reshape(1, -1)
    
    # 2. KNN æœå°‹ï¼ˆè¿”å› Hamming distancesï¼‰
    distances, indices = index.search(query_binary, K)  # (1, K)
    distances = distances[0]  # (K,)
    indices = indices[0]  # (K,)
    
    # 3. è½‰æ›ç‚º similarityï¼ˆHamming -> cosine-likeï¼‰
    similarities = 1 - distances / B  # [0, 1] range
    
    # 4. Softmax weighting
    weights = np.exp(similarities / tau)
    weights = weights / weights.sum()
    
    # 5. åŠ æ¬ŠæŠ•ç¥¨
    neighbor_labels = train_labels[indices]  # (K, C)
    tag_scores = (weights[:, None] * neighbor_labels).sum(axis=0)  # (C,)
    
    # 6. Top-N
    top_indices = np.argsort(tag_scores)[-top_n:][::-1]
    top_scores = tag_scores[top_indices]
    
    return top_indices, top_scores
```

---

## 7. å¯¦é©—è¨­è¨ˆ

### 7.1 Baseline æ–¹æ³•å°æ¯”

| æ–¹æ³• | æè¿° | ç”¨é€” |
| ------ | ------ | ------ |
| **SigLIP2-MLP** | ç›´æ¥ç”¨ MLP åˆ†é¡å™¨ on `[v_img, v_txt]`ï¼ˆç„¡ decomposition, ç„¡ hash, ç„¡ KNNï¼‰ | è­‰æ˜ hash+KNN çš„å¿…è¦æ€§ |
| **SigLIP2-ZeroShot** | è¨ˆç®— image embedding èˆ‡æ¯å€‹ tag prototypeï¼ˆå¾ tag name ç·¨ç¢¼ï¼‰çš„ cosine similarityï¼Œå– Top-N | è­‰æ˜ç›£ç£å¼è¨“ç·´çš„åƒ¹å€¼ |
| **æ–¹æ¡ˆ A (Direction only)** | æ‹¿æ‰ magnitude åˆ†æ”¯ï¼ˆåƒ…ç”¨ `[d_img, d_txt, p_dir]`ï¼‰ | è­‰æ˜æ–¹æ¡ˆ B çš„åƒ¹å€¼ |
| **Ours-Full** | å®Œæ•´æ¶æ§‹ï¼ˆæ–¹æ¡ˆ B + Hadamard + Hash + KNNï¼‰ | ä¸»è¦æ–¹æ³• |

### 7.2 ç³»çµ±åŒ– Ablation Study

#### Tier 1: æ ¸å¿ƒæ¶æ§‹é¸æ“‡ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰

| ID | è®Šé‡ | é¸é … | å›ºå®šåƒæ•¸ |
| ---- | ------ | ------ | ---------- |
| **A1** | Fusion ç­–ç•¥ | concat / +Hadamard / +Hadamard+Magnitude | B=64, K=20, freeze |
| **A2** | Hash bits | ç„¡ hash / 32 / 64 / 128 | å…¶é¤˜åŒ baseline |
| **A3** | KNN vs MLP head | KNN / ç›´æ¥ç”¨åˆ†é¡å™¨ / hybrid | åŒä¸Š |

#### Tier 2: è¨“ç·´ç­–ç•¥ï¼ˆä¸­ç­‰å„ªå…ˆç´šï¼‰

| ID | è®Šé‡ | é¸é … | èªªæ˜ |
| ---- | ------ | ------ | ------ |
| **B1** | æ˜¯å¦ freeze towers | freeze / âš ï¸ **ä¸å¯è§£å‡** (OOM) | RTX 5080 16GB é™åˆ¶ |
| **B2** | Loss weights | (Î±, Î³, Î»â‚, Î»â‚‚) çµ„åˆ | Grid search: Î± âˆˆ {0.5, 1.0}, Î³ âˆˆ {0.05, 0.1} |
| **B3** | max_num_patches | 256 / âš ï¸ 512 éœ€ç›£æ§ | è©•ä¼°è§£æåº¦å½±éŸ¿ |
| **B4** | é¡åˆ¥ä¸å¹³è¡¡è™•ç† | ç„¡ / Focal Loss / Class Weights | COCO é¡åˆ¥åˆ†å¸ƒä¸å‡ |

#### Tier 3: KNN è¶…åƒæ•¸ï¼ˆæ¬¡è¦å„ªå…ˆç´šï¼‰

| ID | è®Šé‡ | é¸é … | èªªæ˜ |
| ---- | ------ | ------ | ------ |
| **C1** | K å€¼ | 5 / 10 / 20 / 50 | é„°å±…æ•¸é‡ |
| **C2** | è·é›¢å‡½æ•¸ | cosine(h) / hamming(sign(h)) / hybrid | æª¢ç´¢ç­–ç•¥ |
| **C3** | Voting ç­–ç•¥ | uniform / softmax / rank-based / threshold | åŠ æ¬Šæ–¹å¼ |
| **C4** | tau (temperature) | 0.03 / 0.07 / 0.2 | softmax å¹³æ»‘åº¦ |

### 7.3 å¯¦é©—æµç¨‹

#### éšæ®µ 1: Baseline é©—è­‰ï¼ˆ1-2 å¤©ï¼‰

1. å¯¦ä½œ SigLIP2-MLP baseline
2. å¯¦ä½œ SigLIP2-ZeroShot baseline
3. ç¢ºèªè³‡æ–™è™•ç† pipeline æ­£ç¢º
4. å»ºç«‹è©•ä¼°æµç¨‹

#### éšæ®µ 2: æ ¸å¿ƒæ¶æ§‹å¯¦é©—ï¼ˆ3-5 å¤©ï¼‰

1. å¯¦ä½œå®Œæ•´æ¶æ§‹
2. åŸ·è¡Œ Tier 1 ablations (A1-A3)
3. é¸å‡ºæœ€ä½³é…ç½®

#### éšæ®µ 3: è¨“ç·´ç­–ç•¥å„ªåŒ–ï¼ˆ3-5 å¤©ï¼‰

1. åŸ·è¡Œ Tier 2 ablations (B1-B4)
2. è¶…åƒæ•¸ grid search
3. å­¸ç¿’ç‡èª¿åº¦å¯¦é©—

#### éšæ®µ 4: KNN èª¿å„ªï¼ˆ2-3 å¤©ï¼‰

1. åŸ·è¡Œ Tier 3 ablations (C1-C4)
2. æª¢ç´¢æ•ˆç‡åˆ†æ
3. å¯è§£é‡‹æ€§å¯¦é©—

#### éšæ®µ 5: æœ€çµ‚è©•ä¼°èˆ‡åˆ†æï¼ˆ2-3 å¤©ï¼‰

1. Test set è©•ä¼°
2. éŒ¯èª¤åˆ†æ
3. è¦–è¦ºåŒ–å±•ç¤º
4. æ’°å¯«å ±å‘Š

---

## 8. è¶…åƒæ•¸é…ç½® (RTX 5080 å„ªåŒ–)

### 8.1 ç¡¬é«”è³‡è¨Šç¸½è¦½

```yaml
# å¯¦éš›ç¡¬é«”è¦æ ¼
hardware_info:
  gpu:
    model: "NVIDIA GeForce RTX 5080"
    vram_gb: 16  # âš ï¸ é—œéµé™åˆ¶
    cuda_version: "13.0"
    driver_version: "580.126.09"
    compute_capability: "8.9"  # Ada Lovelace
  
  cpu:
    cores: 32
    threads: 64  # å‡è¨­æ”¯æ´è¶…åŸ·è¡Œç·’
    model: "é«˜éšå·¥ä½œç«™è™•ç†å™¨"
  
  memory:
    ram_gb: 42
    swap_gb: 8  # å»ºè­°è¨­å®š
  
  storage:
    total_tb: 1.1
    ssd: true
```

### 8.2 è¨˜æ†¶é«”ä½”ç”¨ä¼°ç®—è¡¨ï¼ˆ16GB VRAMï¼‰

| çµ„ä»¶ | è¨˜æ†¶é«”ä½”ç”¨ | èªªæ˜ |
| ------ | ----------- | ------ |
| **SigLIP2-base (å‡çµ)** | ~2.5 GB | åƒ… forward passï¼Œç„¡ gradients |
| **Fusion MLP** | ~0.3 GB | å¯è¨“ç·´åƒæ•¸ |
| **Hash Layer** | ~0.1 GB | å¯è¨“ç·´åƒæ•¸ |
| **Classifier Head** | ~0.05 GB | å¯è¨“ç·´åƒæ•¸ |
| **Optimizer States (AdamW)** | ~1.2 GB | 2x å¯è¨“ç·´åƒæ•¸é‡ |
| **Batch Data (32, mixed precision)** | ~4.0 GB | Images + embeddings (FP16) |
| **Gradients** | ~0.5 GB | åƒ…å¯è¨“ç·´éƒ¨åˆ† |
| **CUDA Kernels & PyTorch** | ~0.5 GB | Framework overhead |
| **é ç•™ç·©è¡** | ~1.0 GB | å®‰å…¨é‚Šç•Œ |
| **ç¸½è¨ˆ** | **~10.2 GB** | âœ… åœ¨ 16GB å…§å®‰å…¨ (63% ä½¿ç”¨ç‡) |

### 8.3 å„ªåŒ–å¾Œçš„é…ç½®æ–‡ä»¶

```yaml
# configs/hardware/rtx5080_16gb.yaml

# ==========================================
# ç¡¬é«”å„ªåŒ–é…ç½® - RTX 5080 16GB å°ˆç”¨
# ==========================================

experiment:
  name: "baseline_rtx5080_16gb"
  version: "v2.1"
  seed: 42
  deterministic: false  # true æœƒæ…¢å¾ˆå¤š

# æ¨¡å‹æ¶æ§‹
model:
  siglip2_variant: "google/siglip2-base-patch16-256"  # âš ï¸ ä¸è¦ç”¨ largeï¼
  max_num_patches: 256  # ä¿å®ˆè¨­å®šï¼Œå¯å˜—è©¦ 512 ä½†éœ€ç›£æ§
  text_max_length: 64
  freeze_towers: true  # âš ï¸ å¿…é ˆç‚º trueï¼Œå¦å‰‡ OOMï¼
  
  # åˆ†è§£å±¤
  decomposer:
    eps: 1.0e-6
  
  # èåˆå±¤
  fusion:
    type: "hadamard_with_magnitude"  # æ–¹æ¡ˆ B
    mlp_dims: [1024, 512]  # è¼¸å…¥: 3*768+2 = 2306
    dropout: 0.1
    activation: "relu"
  
  # Hash å±¤
  hash:
    bits: 64  # 32=å¿«é€Ÿ, 64=å¹³è¡¡, 128=é«˜ç²¾åº¦(éœ€æ›´å¤šè¨˜æ†¶é«”)
    activation: "tanh"
  
  # åˆ†é¡é ­
  classifier:
    num_classes: 80  # COCO categories
    use_bias: true

# æå¤±å‡½æ•¸
loss:
  # BCE Loss (ä¸»è¦)
  bce_weight: 1.0
  use_focal_loss: false  # å¯é¸ï¼šè™•ç†é¡åˆ¥ä¸å¹³è¡¡
  focal_alpha: 0.25
  focal_gamma: 2.0
  
  # Cosine Alignment Loss
  cosine_weight: 1.0  # Î±
  
  # Hash Regularization
  hash_weight: 0.1  # Î³
  hash_reg:
    lambda_balance: 0.1  # Î»â‚
    lambda_decorr: 0.01  # Î»â‚‚

# è¨“ç·´é…ç½® (â­ RTX 5080 å„ªåŒ–)
training:
  # æ‰¹æ¬¡å¤§å° (é—œéµï¼)
  batch_size: 32  # âš ï¸ å¾ 64 é™åˆ° 32
  gradient_accumulation_steps: 2  # âš ï¸ å¿…é ˆä½¿ç”¨ï¼Œæ¨¡æ“¬ batch_size=64
  effective_batch_size: 64  # 32 * 2 = 64
  
  # Epoch èˆ‡é©—è­‰
  num_epochs: 30
  warmup_epochs: 2
  val_every_n_epochs: 1
  
  # æ¢¯åº¦ç®¡ç†
  gradient_clip_norm: 1.0
  max_grad_norm: 1.0
  
  # Early Stopping
  early_stopping_patience: 5
  save_top_k: 3
  monitor_metric: "val_mAP"  # æˆ– "val_f1_macro"

# Optimizer
optimizer:
  type: "adamw"
  lr: 2.0e-4  # âš ï¸ æ¯”åŸæœ¬ 3e-4 ç•¥å°ï¼ˆå›  effective batch size ä¸€æ¨£ï¼‰
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Scheduler
scheduler:
  type: "cosine_with_warmup"
  warmup_ratio: 0.1  # warmup_epochs / num_epochs
  min_lr: 1.0e-6
  cosine_cycles: 1

# DataLoader (â­ åˆ©ç”¨ 32 æ ¸å¿ƒ CPU)
dataloader:
  num_workers: 16  # âš ï¸ ä½ æœ‰ 32 æ ¸å¿ƒï¼Œå¯ä»¥ç”¨æ›´å¤š
  prefetch_factor: 3  # é è¼‰å…¥ 3 æ‰¹æ¬¡è³‡æ–™
  pin_memory: true  # åŠ é€Ÿ CPU->GPU å‚³è¼¸
  persistent_workers: true  # ä¿æŒ workers å­˜æ´»
  drop_last: true  # ä¸Ÿæ£„ä¸å®Œæ•´çš„æœ€å¾Œä¸€æ‰¹

# è¨˜æ†¶é«”å„ªåŒ– (â­ é—œéµè¨­å®š)
memory_optimization:
  # æ··åˆç²¾åº¦ (å¿…é ˆï¼)
  mixed_precision: true  # âš ï¸ ç¯€çœ 40% VRAM
  amp_dtype: "float16"  # æˆ– "bfloat16" (å¦‚æœæ”¯æ´)
  
  # Gradient Checkpointing (å¯é¸ï¼Œç¯€çœæ›´å¤šè¨˜æ†¶é«”)
  gradient_checkpointing: false  # å‡çµ towers æ™‚ä¸éœ€è¦
  
  # å¿«å–ç®¡ç†
  empty_cache_steps: 100  # æ¯ 100 æ­¥æ¸…ç†ä¸€æ¬¡ CUDA å¿«å–
  
  # VRAM ç›£æ§
  log_gpu_memory: true
  alert_vram_threshold_gb: 14.5  # è¶…é 14.5GB ç™¼å‡ºè­¦å‘Š

# KNN æ¨è«–é…ç½®
knn:
  K: 20  # number of neighbors
  distance_metric: "hamming"  # or "cosine"
  voting_strategy: "softmax"  # or "uniform", "rank_based"
  tau: 0.07  # temperature for softmax
  top_n_tags: 5  # output top N predictions
  
  # æ¨è«–æ™‚çš„æ‰¹æ¬¡å¤§å°ï¼ˆå¯ä»¥æ¯”è¨“ç·´å¤§ï¼‰
  inference_batch_size: 64

# æ—¥èªŒèˆ‡ç›£æ§
logging:
  log_every_n_steps: 50
  log_gradients: false  # åƒ…åœ¨ debug æ™‚å•Ÿç”¨
  log_weights: false
  
  # Weights & Biases
  use_wandb: true
  wandb_project: "siglip2-multimodal-hash"
  wandb_entity: "your-username"
  
  # TensorBoard
  use_tensorboard: true
  tensorboard_dir: "experiments/tensorboard"

# æª¢æŸ¥é»
checkpointing:
  save_dir: "experiments/checkpoints"
  save_every_n_epochs: 5
  save_last: true
  save_top_k: 3
  filename_format: "epoch={epoch:02d}-val_mAP={val_mAP:.4f}"

# è³‡æ–™å¢å¼· (å¯é¸)
augmentation:
  use_augmentation: false  # SigLIP2 å·²ç¶“å¾ˆå¼·ï¼Œå¯èƒ½ä¸éœ€è¦
  random_flip: false
  color_jitter: false
  random_crop: false
```

### 8.4 ç·Šæ€¥é™ç´šæ–¹æ¡ˆï¼ˆå¦‚æœé‚„æ˜¯ OOMï¼‰

```yaml
# configs/hardware/rtx5080_16gb_emergency.yaml
# ç•¶ baseline é…ç½®ä»ç„¶ OOM æ™‚ä½¿ç”¨

training:
  batch_size: 16  # âš ï¸ å¾ 32 é™åˆ° 16
  gradient_accumulation_steps: 4  # æ¨¡æ“¬ batch_size=64

model:
  max_num_patches: 196  # âš ï¸ å¾ 256 é™åˆ° 196 (14x14 patches)

memory_optimization:
  gradient_checkpointing: true  # âš ï¸ å•Ÿç”¨ï¼Œç¯€çœ 30% VRAM
  empty_cache_steps: 50  # æ›´é »ç¹æ¸…ç†
```

### 8.5 Grid Search é…ç½®ï¼ˆä¾›è‡ªå‹•åŒ–å¯¦é©—ï¼‰

```yaml
# configs/grid_search.yaml

grid_search:
  # Tier 1: æ ¸å¿ƒæ¶æ§‹
  hash_bits: [32, 64, 128]
  fusion_type: ["concat_only", "hadamard", "hadamard_with_magnitude"]
  
  # Tier 2: è¨“ç·´ç­–ç•¥
  cosine_weight: [0.5, 1.0, 2.0]
  hash_weight: [0.05, 0.1, 0.2]
  
  # Tier 3: KNN è¶…åƒæ•¸
  K_neighbors: [10, 20, 50]
  tau: [0.03, 0.07, 0.15]
  
  # è¨˜æ†¶é«”ç›¸é—œï¼ˆæ…ç”¨ï¼‰
  max_num_patches: [256]  # 512 é¢¨éšªå¤ªé«˜ï¼Œä¸å»ºè­° grid search
  batch_size: [32]  # å›ºå®šï¼Œä¸å»ºè­°è®Šå‹•

# ç¸½å¯¦é©—æ•¸ï¼š3*3 + 3*3 + 3*3 = 27 çµ„
# é ä¼°æ™‚é–“ï¼š27 * 17.5 å°æ™‚ = ~472 å°æ™‚ (åˆ†æ•£å¤š GPU åŸ·è¡Œ)
```

---

## 9. å¯¦ä½œç´°ç¯€ (è¨˜æ†¶é«”å„ªåŒ–)

### 9.1 é—œéµç¨‹å¼ç¢¼ç‰‡æ®µ

#### 9.1.1 æ–¹å‘/å¹…åº¦åˆ†è§£

```python
import torch
import torch.nn as nn

class DirectionMagnitudeDecomposer(nn.Module):
    def __init__(self, eps=1e-6):
        super().__init__()
        self.eps = eps
    
    def forward(self, v):
        """
        Args:
            v: (batch_size, dim) raw embedding
        Returns:
            direction: (batch_size, dim) unit vector
            magnitude: (batch_size, 1) log-norm
        """
        norm = torch.norm(v, p=2, dim=1, keepdim=True)  # (B, 1)
        direction = v / (norm + self.eps)  # (B, D)
        magnitude = torch.log(norm + self.eps)  # (B, 1)
        return direction, magnitude
```

#### 9.1.2 Hadamard èåˆ

```python
class HadamardFusion(nn.Module):
    def __init__(self, embed_dim, mlp_dims, dropout=0.1):
        super().__init__()
        # Input: [d_img, d_txt, p_dir, m_img, m_txt]
        input_dim = embed_dim * 3 + 2  # 3*768+2 for base
        
        layers = []
        prev_dim = input_dim
        for hidden_dim in mlp_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            prev_dim = hidden_dim
        
        self.mlp = nn.Sequential(*layers)
    
    def forward(self, d_img, d_txt, m_img, m_txt):
        """
        Args:
            d_img: (B, D) image direction
            d_txt: (B, D) text direction
            m_img: (B, 1) image magnitude
            m_txt: (B, 1) text magnitude
        Returns:
            z: (B, mlp_dims[-1]) fused embedding
        """
        p_dir = d_img * d_txt  # Hadamard product
        x = torch.cat([d_img, d_txt, p_dir, m_img, m_txt], dim=1)
        z = self.mlp(x)
        return z
```

#### 9.1.3 Hash å±¤èˆ‡æ­£å‰‡åŒ–

```python
class HashLayer(nn.Module):
    def __init__(self, input_dim, hash_bits, skip_hash=False):
        super().__init__()
        self.skip_hash = skip_hash
        
        if self.skip_hash:
            self.fc = nn.Identity()
            self.output_dim = input_dim
        else:
            self.fc = nn.Linear(input_dim, hash_bits)
            self.output_dim = hash_bits
    
    def forward(self, z):
        """Returns soft hash codes in [-1, 1] OR raw z if skip_hash"""
        if self.skip_hash:
            return z
        
        h = torch.tanh(self.fc(z))
        return h
    
    def binarize(self, h):
        """For inference: convert to hard binary {-1, 1}"""
        if self.skip_hash:
            return h
        return torch.sign(h)

def hash_regularization(h, lambda_balance=0.1, lambda_decorr=0.01):
    """
    Args:
        h: (batch_size, hash_bits) soft hash codes
    Returns:
        loss_hash: scalar tensor
    """
    # 1. Quantization loss
    loss_quant = torch.mean((torch.abs(h) - 1) ** 2)
    
    # 2. Bit balance loss
    bit_mean = torch.mean(h, dim=0)  # (hash_bits,)
    loss_balance = torch.mean(bit_mean ** 2)
    
    # 3. Bit decorrelation loss
    h_centered = h - torch.mean(h, dim=0, keepdim=True)
    cov = (h_centered.T @ h_centered) / h.size(0)  # (B, B)
    loss_decorr = (torch.sum(cov ** 2) - torch.trace(cov ** 2)) / (h.size(1) ** 2)
    
    loss_hash = loss_quant + lambda_balance * loss_balance + lambda_decorr * loss_decorr
    return loss_hash
```

#### 9.1.4 å®Œæ•´æ¨¡å‹

```python
class MultimodalHashKNN(nn.Module):
    def __init__(self, config):
        super().__init__()
        # SigLIP2 encoders - ä½¿ç”¨æ­£ç¢ºçš„è¼‰å…¥æ–¹å¼
        model_name = config.siglip2_variant
        self.image_processor = AutoImageProcessor.from_pretrained(model_name, use_fast=False)
        self.tokenizer = GemmaTokenizerFast.from_pretrained(model_name)
        self.siglip_model = AutoModel.from_pretrained(model_name, trust_remote_code=True)
        
        # âš ï¸ å¿…é ˆå‡çµ towersï¼ˆRTX 5080 16GB é™åˆ¶ï¼‰
        if config.freeze_towers:
            for param in self.siglip_model.parameters():
                param.requires_grad = False
            print("âœ“ SigLIP2 towers frozen (saving ~7.5GB VRAM)")
        
        # ç²å– embedding ç¶­åº¦
        if hasattr(self.siglip_model.config, "projection_dim"):
            self.embed_dim = self.siglip_model.config.projection_dim
        else:
            self.embed_dim = 768
        
        # Decomposer
        self.decomposer = DirectionMagnitudeDecomposer()
        self.fusion = HadamardFusion(embed_dim, config.mlp_dims, config.dropout)
        
        # Hash layer
        skip_hash = config.get("skip_hash", False)
        self.hash_layer = HashLayer(config.mlp_dims[-1], config.hash_bits, skip_hash=skip_hash)
        
        # Classifier head (for training) - ä½¿ç”¨ output_dim é©æ‡‰ skip_hash
        self.classifier = nn.Linear(self.hash_layer.output_dim, config.num_classes)
        
        self.config = config
    
    def forward(self, pixel_values, input_ids, attention_mask=None, return_components=False):
        # Encode
        outputs = self.siglip_model(
            pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask
        )
        v_img = outputs.image_embeds  # (B, D)
        v_txt = outputs.text_embeds   # (B, D)
        
        # Decompose
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        
        # Fuse
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        
        # Hash
        h = self.hash_layer(z)
        
        # Classify
        logits = self.classifier(h)
        
        if return_components:
            return {
                'logits': logits,
                'h': h,
                'd_img': d_img,
                'd_txt': d_txt,
                'm_img': m_img,
                'm_txt': m_txt,
                'z': z
            }
        else:
            return logits
    
    def get_hash(self, images, texts):
        """For inference: return hash codes"""
        with torch.no_grad():
            outputs = self.model(pixel_values=images, input_ids=texts)
            v_img = outputs.image_embeds
            v_txt = outputs.text_embeds
            d_img, m_img = self.decomposer(v_img)
            d_txt, m_txt = self.decomposer(v_txt)
            z = self.fusion(d_img, d_txt, m_img, m_txt)
            h = self.hash_layer(z)
        return h
```

### 9.2 è¨“ç·´è¿´åœˆï¼ˆâ­ å«è¨˜æ†¶é«”å„ªåŒ–ï¼‰

```python
import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler

def get_gpu_memory_info():
    """ç²å– GPU è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        max_allocated = torch.cuda.max_memory_allocated() / 1e9
        return {
            "allocated_gb": allocated,
            "reserved_gb": reserved,
            "max_allocated_gb": max_allocated,
            "free_gb": 16.0 - reserved
        }
    return None

def train_epoch(model, dataloader, optimizer, scheduler, config):
    """å„ªåŒ–çš„è¨“ç·´è¿´åœˆï¼ˆé‡å° RTX 5080 16GBï¼‰"""
    
    model.train()
    scaler = GradScaler()  # âš ï¸ æ··åˆç²¾åº¦å¿…é ˆ
    
    total_loss = 0
    total_loss_bce = 0
    total_loss_cos = 0
    total_loss_hash = 0
    
    accumulation_steps = config.training.gradient_accumulation_steps
    
    for batch_idx, batch in enumerate(dataloader):
        # ç§»åˆ° GPUï¼ˆnon_blocking åŠ é€Ÿï¼‰
        images = batch['images'].to('cuda', non_blocking=True)
        texts = batch['texts'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)  # (B, C) multi-hot
        
        # âš ï¸ æ··åˆç²¾åº¦å‰å‘å‚³æ’­
        with autocast(dtype=torch.float16):
            outputs = model(images, texts, return_components=True)
            logits = outputs['logits']
            h = outputs['h']
            d_img = outputs['d_img']
            d_txt = outputs['d_txt']
            
            # è¨ˆç®—å„é …æå¤±
            loss_bce = F.binary_cross_entropy_with_logits(logits, labels.float())
            loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
            loss_hash = hash_regularization(
                h, 
                config.loss.hash_reg.lambda_balance,
                config.loss.hash_reg.lambda_decorr
            )
            
            # çµ„åˆæå¤±
            loss = (
                config.loss.bce_weight * loss_bce + 
                config.loss.cosine_weight * loss_cos + 
                config.loss.hash_weight * loss_hash
            )
            loss = loss / accumulation_steps  # âš ï¸ æ¢¯åº¦ç´¯ç©
        
        # åå‘å‚³æ’­
        scaler.scale(loss).backward()
        
        # âš ï¸ æ¢¯åº¦ç´¯ç©ï¼šæ¯ N æ­¥æ›´æ–°ä¸€æ¬¡
        if (batch_idx + 1) % accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(
                model.parameters(), 
                config.training.gradient_clip_norm
            )
            
            # æ›´æ–°åƒæ•¸
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
        
        # ç´¯ç©æå¤±ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
        total_loss += loss.item() * accumulation_steps
        total_loss_bce += loss_bce.item()
        total_loss_cos += loss_cos.item()
        total_loss_hash += loss_hash.item()
        
        # âš ï¸ å®šæœŸç›£æ§è¨˜æ†¶é«”
        if batch_idx % 100 == 0:
            mem_info = get_gpu_memory_info()
            print(f"Batch {batch_idx}/{len(dataloader)}: "
                  f"Loss={loss.item():.4f}, "
                  f"GPU Memory: {mem_info['allocated_gb']:.2f}GB / 16GB "
                  f"({mem_info['allocated_gb']/16*100:.1f}%)")
            
            # âš ï¸ è­¦å‘Šæ©Ÿåˆ¶
            if mem_info['allocated_gb'] > config.memory_optimization.alert_vram_threshold_gb:
                print(f"âš ï¸  WARNING: GPU memory usage high! "
                      f"{mem_info['allocated_gb']:.2f}GB / 16GB")
        
        # âš ï¸ å®šæœŸæ¸…ç†å¿«å–
        if batch_idx % config.memory_optimization.empty_cache_steps == 0:
            torch.cuda.empty_cache()
    
    scheduler.step()
    
    # è¿”å›å¹³å‡æå¤±
    n_batches = len(dataloader)
    return {
        'total': total_loss / n_batches,
        'bce': total_loss_bce / n_batches,
        'cos': total_loss_cos / n_batches,
        'hash': total_loss_hash / n_batches
    }
```

### 9.3 é©—è­‰è¿´åœˆ

```python
from sklearn.metrics import (
    average_precision_score, f1_score, roc_auc_score,
    precision_score, recall_score, hamming_loss,
    coverage_error, label_ranking_loss, label_ranking_average_precision_score,
)

@torch.no_grad()
def validate(model, dataloader, config):
    """é©—è­‰æ¨¡å‹ï¼Œè¨ˆç®—å¤šæ¨™ç±¤åˆ†é¡å¸¸ç”¨æŒ‡æ¨™"""
    model.eval()
    
    total_loss = 0
    all_preds = []
    all_labels = []
    
    for batch in dataloader:
        images = batch['images'].to('cuda', non_blocking=True)
        texts = batch['texts'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        with autocast(dtype=torch.float16):
            outputs = model(images, texts, return_components=True)
            logits = outputs['logits']
            d_img, d_txt, h = outputs['d_img'], outputs['d_txt'], outputs['h']
            
            loss_bce = F.binary_cross_entropy_with_logits(logits, labels.float())
            loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
            loss_hash = hash_regularization(h, config.loss.hash_reg.lambda_balance,
                                           config.loss.hash_reg.lambda_decorr)
            loss = (config.loss.bce_weight * loss_bce + 
                    config.loss.cosine_weight * loss_cos + 
                    config.loss.hash_weight * loss_hash)
        
        total_loss += loss.item()
        all_preds.append(torch.sigmoid(logits).cpu().numpy())
        all_labels.append(labels.cpu().numpy())
    
    # åˆä½µçµæœ
    all_preds = np.concatenate(all_preds, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)
    pred_binary = (all_preds > 0.5).astype(int)
    
    # è¨ˆç®—æ‰€æœ‰æŒ‡æ¨™
    metrics = {
        'loss': total_loss / len(dataloader),
        # ä¸»è¦æŒ‡æ¨™
        'mAP': average_precision_score(all_labels, all_preds, average='macro'),
        'auc_macro': roc_auc_score(all_labels, all_preds, average='macro'),
        'auc_micro': roc_auc_score(all_labels, all_preds, average='micro'),
        # F1
        'f1_micro': f1_score(all_labels, pred_binary, average='micro', zero_division=0),
        'f1_macro': f1_score(all_labels, pred_binary, average='macro', zero_division=0),
        # Precision & Recall
        'precision_macro': precision_score(all_labels, pred_binary, average='macro', zero_division=0),
        'recall_macro': recall_score(all_labels, pred_binary, average='macro', zero_division=0),
        # å…¶ä»–
        'hamming_loss': hamming_loss(all_labels, pred_binary),
        'ranking_loss': label_ranking_loss(all_labels, all_preds),
        'lrap': label_ranking_average_precision_score(all_labels, all_preds),
        'mae': np.mean(np.abs(all_preds - all_labels)),
    }
    
    return metrics
```

### 9.4 å®Œæ•´è¨“ç·´è…³æœ¬

```python
# scripts/train.py
import torch
import hydra
from omegaconf import DictConfig
import wandb
from tqdm import tqdm

@hydra.main(config_path="../configs", config_name="hardware/rtx5080_16gb")
def main(config: DictConfig):
    # è¨­å®š seed
    torch.manual_seed(config.experiment.seed)
    
    # åˆå§‹åŒ– wandb
    if config.logging.use_wandb:
        wandb.init(
            project=config.logging.wandb_project,
            entity=config.logging.wandb_entity,
            config=dict(config),
            name=config.experiment.name
        )
    
    # å»ºç«‹æ¨¡å‹
    print("å»ºç«‹æ¨¡å‹...")
    model = MultimodalHashKNN(config.model).cuda()
    
    # é¡¯ç¤ºè¨˜æ†¶é«”è³‡è¨Š
    mem_info = get_gpu_memory_info()
    print(f"æ¨¡å‹è¼‰å…¥å¾Œ GPU è¨˜æ†¶é«”: {mem_info['allocated_gb']:.2f}GB / 16GB")
    
    # å»ºç«‹ DataLoader
    print("å»ºç«‹ DataLoader...")
    train_loader = create_dataloader(config, split='train')
    val_loader = create_dataloader(config, split='val')
    
    # å»ºç«‹ optimizer èˆ‡ scheduler
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.optimizer.lr,
        weight_decay=config.optimizer.weight_decay,
        betas=config.optimizer.betas
    )
    
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.training.num_epochs,
        eta_min=config.scheduler.min_lr
    )
    
    # è¨“ç·´è¿´åœˆ
    best_val_map = 0
    patience_counter = 0
    
    for epoch in range(config.training.num_epochs):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{config.training.num_epochs}")
        print(f"{'='*60}")
        
        # è¨“ç·´
        train_losses = train_epoch(model, train_loader, optimizer, scheduler, config)
        print(f"Train Loss: {train_losses['total']:.4f} "
              f"(BCE: {train_losses['bce']:.4f}, "
              f"Cos: {train_losses['cos']:.4f}, "
              f"Hash: {train_losses['hash']:.4f})")
        
        # é©—è­‰
        val_metrics = validate(model, val_loader, config)
        print(f"Val Loss: {val_metrics['loss']:.4f}, "
              f"mAP: {val_metrics['mAP']:.4f}, "
              f"F1-Micro: {val_metrics['f1_micro']:.4f}, "
              f"F1-Macro: {val_metrics['f1_macro']:.4f}")
        
        # è¨˜éŒ„åˆ° wandb
        if config.logging.use_wandb:
            wandb.log({
                'epoch': epoch,
                'train/loss': train_losses['total'],
                'train/loss_bce': train_losses['bce'],
                'train/loss_cos': train_losses['cos'],
                'train/loss_hash': train_losses['hash'],
                'val/loss': val_metrics['loss'],
                'val/mAP': val_metrics['mAP'],
                'val/f1_micro': val_metrics['f1_micro'],
                'val/f1_macro': val_metrics['f1_macro'],
                'lr': optimizer.param_groups[0]['lr']
            })
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['mAP'] > best_val_map:
            best_val_map = val_metrics['mAP']
            patience_counter = 0
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_mAP': val_metrics['mAP'],
                'config': dict(config)
            }
            torch.save(checkpoint, f"best_model_epoch{epoch}_mAP{val_metrics['mAP']:.4f}.pth")
            print(f"âœ“ å„²å­˜æœ€ä½³æ¨¡å‹ (mAP: {val_metrics['mAP']:.4f})")
        else:
            patience_counter += 1
        
        # Early stopping
        if patience_counter >= config.training.early_stopping_patience:
            print(f"Early stopping triggered after {epoch+1} epochs")
            break
    
    print("\nè¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³ Val mAP: {best_val_map:.4f}")

if __name__ == "__main__":
    main()
```

### 9.5 è¨˜æ†¶é«”ç®¡ç†å·¥å…·

```python
# utils/memory_monitor.py

import torch
import psutil
import GPUtil

class MemoryMonitor:
    """è¨˜æ†¶é«”ç›£æ§å·¥å…·"""
    
    def __init__(self, alert_threshold_gb=14.5):
        self.alert_threshold_gb = alert_threshold_gb
        self.peak_vram = 0
    
    def get_stats(self):
        """ç²å–å®Œæ•´è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = {}
        
        # GPU è¨˜æ†¶é«”
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            max_allocated = torch.cuda.max_memory_allocated() / 1e9
            
            stats['gpu'] = {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'max_allocated_gb': max_allocated,
                'free_gb': 16.0 - reserved,
                'utilization_%': allocated / 16.0 * 100
            }
            
            # æ›´æ–°å³°å€¼
            self.peak_vram = max(self.peak_vram, allocated)
            
            # æª¢æŸ¥æ˜¯å¦è¶…éé–¾å€¼
            if allocated > self.alert_threshold_gb:
                stats['gpu']['alert'] = True
        
        # CPU è¨˜æ†¶é«”
        ram = psutil.virtual_memory()
        stats['cpu'] = {
            'used_gb': ram.used / 1e9,
            'available_gb': ram.available / 1e9,
            'percent': ram.percent
        }
        
        return stats
    
    def print_stats(self, prefix=""):
        """åˆ—å°è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = self.get_stats()
        
        if 'gpu' in stats:
            gpu = stats['gpu']
            print(f"{prefix}GPU: {gpu['allocated_gb']:.2f}GB / 16GB "
                  f"({gpu['utilization_%']:.1f}%), "
                  f"Peak: {self.peak_vram:.2f}GB")
            
            if gpu.get('alert'):
                print(f"  âš ï¸  WARNING: VRAM usage high!")
        
        cpu = stats['cpu']
        print(f"{prefix}RAM: {cpu['used_gb']:.1f}GB / {42:.1f}GB "
              f"({cpu['percent']:.1f}%)")
    
    def reset_peak(self):
        """é‡ç½®å³°å€¼çµ±è¨ˆ"""
        torch.cuda.reset_peak_memory_stats()
        self.peak_vram = 0

# ä½¿ç”¨ç¯„ä¾‹
monitor = MemoryMonitor(alert_threshold_gb=14.5)

# è¨“ç·´å‰
monitor.print_stats("è¨“ç·´å‰ - ")

# è¨“ç·´ä¸­ï¼ˆå®šæœŸæª¢æŸ¥ï¼‰
for epoch in range(num_epochs):
    for batch_idx, batch in enumerate(train_loader):
        # ... è¨“ç·´ç¨‹å¼ç¢¼ ...
        
        if batch_idx % 100 == 0:
            monitor.print_stats(f"Epoch {epoch}, Batch {batch_idx} - ")
```

---

## 10. è¶…åƒæ•¸é…ç½® (å°æ‡‰ä½ çš„å°ˆæ¡ˆ)

### 10.1 ç¡¬é«”é…ç½®æª”æ¡ˆ

å»ºç«‹ `configs/hardware/rtx5080_16gb.yaml`:

```yaml
# configs/hardware/rtx5080_16gb.yaml
# RTX 5080 16GB ç¡¬é«”å„ªåŒ–é…ç½®

# ==========================================
# ç¡¬é«”è³‡è¨Š
# ==========================================
hardware_info:
  gpu:
    model: "NVIDIA GeForce RTX 5080"
    vram_gb: 16
    cuda_version: "12.4"  # âš ï¸ ä¿®æ­£ï¼šä½ çš„ç³»çµ±æ˜¯ CUDA 12.8 Nightly
    driver_version: "580.126.09"
    compute_capability: "8.9"
  
  cpu:
    cores: 32
    threads: 64
  
  memory:
    ram_gb: 42
  
  storage:
    total_tb: 1.1
    ssd: true

# ==========================================
# å°ˆæ¡ˆè·¯å¾‘
# ==========================================
paths:
  project_root: "~/Documents/Coding/github.com/natsuki221/AGCH-Improvement"
  data_root: "./data/coco"
  output_root: "./outputs"
  experiment_root: "./experiments"

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
model:
  siglip2_variant: "google/siglip2-base-patch16-256"
  max_num_patches: 256
  text_max_length: 64
  freeze_towers: true  # âš ï¸ å¿…é ˆç‚º true
  
  decomposer:
    eps: 1.0e-6
  
  fusion:
    type: "hadamard_with_magnitude"
    mlp_dims: [1024, 512]
    dropout: 0.1
    activation: "relu"
  
  hash:
    bits: 64
    activation: "tanh"
  
  classifier:
    num_classes: 80
    use_bias: true

# ==========================================
# æå¤±å‡½æ•¸
# ==========================================
loss:
  bce_weight: 1.0
  cosine_weight: 1.0
  hash_weight: 0.1
  
  hash_reg:
    lambda_balance: 0.1
    lambda_decorr: 0.01
  
  focal_loss: false
  focal_alpha: 0.25
  focal_gamma: 2.0

# ==========================================
# è¨“ç·´é…ç½®ï¼ˆâ­ RTX 5080 16GB å„ªåŒ–ï¼‰
# ==========================================
training:
  # æ‰¹æ¬¡å¤§å°
  batch_size: 32  # âš ï¸ é—œéµï¼šå¾ 64 é™åˆ° 32
  gradient_accumulation_steps: 2  # æ¨¡æ“¬ batch_size=64
  effective_batch_size: 64
  
  # Epoch
  num_epochs: 30
  warmup_epochs: 2
  val_every_n_epochs: 1
  
  # æ¢¯åº¦ç®¡ç†
  gradient_clip_norm: 1.0
  
  # Early Stopping
  early_stopping_patience: 5
  save_top_k: 3
  monitor_metric: "val_mAP"

# ==========================================
# Optimizer
# ==========================================
optimizer:
  type: "adamw"
  lr: 2.0e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

# ==========================================
# Scheduler
# ==========================================
scheduler:
  type: "cosine_with_warmup"
  warmup_ratio: 0.1
  min_lr: 1.0e-6

# ==========================================
# DataLoaderï¼ˆâ­ åˆ©ç”¨ 32 æ ¸å¿ƒï¼‰
# ==========================================
dataloader:
  num_workers: 16  # åˆ©ç”¨ä½ çš„ 32 æ ¸å¿ƒ
  prefetch_factor: 3
  pin_memory: true
  persistent_workers: true
  drop_last: true

# ==========================================
# è¨˜æ†¶é«”å„ªåŒ–ï¼ˆâ­ é—œéµï¼‰
# ==========================================
memory_optimization:
  mixed_precision: true  # âš ï¸ å¿…é ˆå•Ÿç”¨
  amp_dtype: "float16"
  gradient_checkpointing: false  # å‡çµ towers æ™‚ä¸éœ€è¦
  empty_cache_steps: 100
  log_gpu_memory: true
  alert_vram_threshold_gb: 14.5

# ==========================================
# KNN æ¨è«–
# ==========================================
knn:
  K: 20
  distance_metric: "hamming"
  voting_strategy: "softmax"
  tau: 0.07
  top_n_tags: 5
  inference_batch_size: 64

# ==========================================
# æ—¥èªŒèˆ‡ç›£æ§
# ==========================================
logging:
  log_every_n_steps: 50
  
  # Weights & Biases
  use_wandb: true
  wandb_project: "siglip2-multimodal-hash"
  wandb_entity: "natsuki221"  # ä½ çš„ wandb ä½¿ç”¨è€…åç¨±
  
  # TensorBoard
  use_tensorboard: true
  tensorboard_dir: "./experiments/tensorboard"

# ==========================================
# æª¢æŸ¥é»
# ==========================================
checkpointing:
  save_dir: "./outputs/checkpoints"
  save_every_n_epochs: 5
  save_last: true
  save_top_k: 3
  filename_format: "epoch={epoch:02d}-val_mAP={val_mAP:.4f}"

# ==========================================
# å…¶ä»–
# ==========================================
experiment:
  name: "baseline_rtx5080_16gb"
  seed: 42
  deterministic: false
```

### 10.2 Baseline å¯¦é©—é…ç½®

å»ºç«‹ `configs/experiments/baseline.yaml`:

```yaml
# configs/experiments/baseline.yaml
# Baseline å¯¦é©—é…ç½®

defaults:
  - /hardware/rtx5080_16gb  # ç¹¼æ‰¿ç¡¬é«”é…ç½®

# è¦†å¯«å¯¦é©—åç¨±
experiment:
  name: "baseline_siglip2_base_hash64_knn20"
  tags: ["baseline", "siglip2-base", "hash-64", "knn-20"]
  notes: "Baseline experiment with direction+magnitude decomposition"

# ç¢ºèªé—œéµåƒæ•¸
model:
  hash:
    bits: 64  # Baseline ä½¿ç”¨ 64 bits

knn:
  K: 20  # Baseline ä½¿ç”¨ 20 neighbors

# è¨“ç·´è¨­å®š
training:
  num_epochs: 30
  batch_size: 32
  gradient_accumulation_steps: 2
```

---

## 11. å¯¦ä½œç´°ç¯€ (å®Œæ•´ç¨‹å¼ç¢¼)

### 11.1 æ¨¡å‹å®šç¾©ï¼ˆ`src/siglip2_multimodal_hash/model.py`ï¼‰

```python
# src/siglip2_multimodal_hash/model.py

import torch
import torch.nn as nn
from transformers import Siglip2Model, Siglip2Processor
from typing import Optional, Dict

class DirectionMagnitudeDecomposer(nn.Module):
    """æ–¹å‘/å¹…åº¦åˆ†è§£æ¨¡çµ„"""
    
    def __init__(self, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
    
    def forward(self, v: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            v: (batch_size, dim) raw embedding
        Returns:
            direction: (batch_size, dim) unit vector
            magnitude: (batch_size, 1) log-norm
        """
        norm = torch.norm(v, p=2, dim=1, keepdim=True)  # (B, 1)
        direction = v / (norm + self.eps)  # (B, D)
        magnitude = torch.log(norm + self.eps)  # (B, 1)
        return direction, magnitude


class HadamardFusion(nn.Module):
    """Hadamard ä¹˜ç©èåˆæ¨¡çµ„"""
    
    def __init__(
        self,
        embed_dim: int,
        mlp_dims: list[int],
        dropout: float = 0.1,
        activation: str = "relu"
    ):
        super().__init__()
        
        # Input: [d_img, d_txt, p_dir, m_img, m_txt]
        input_dim = embed_dim * 3 + 2
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in mlp_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU() if activation == "relu" else nn.GELU(),
                nn.Dropout(dropout)
            ])
            prev_dim = hidden_dim
        
        self.mlp = nn.Sequential(*layers)
    
    def forward(
        self,
        d_img: torch.Tensor,
        d_txt: torch.Tensor,
        m_img: torch.Tensor,
        m_txt: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            d_img: (B, D) image direction
            d_txt: (B, D) text direction
            m_img: (B, 1) image magnitude
            m_txt: (B, 1) text magnitude
        Returns:
            z: (B, mlp_dims[-1]) fused embedding
        """
        p_dir = d_img * d_txt  # Hadamard product
        x = torch.cat([d_img, d_txt, p_dir, m_img, m_txt], dim=1)
        z = self.mlp(x)
        return z


class HashLayer(nn.Module):
    """Hash å±¤"""
    
    def __init__(self, input_dim: int, hash_bits: int):
        super().__init__()
        self.fc = nn.Linear(input_dim, hash_bits)
        self.hash_bits = hash_bits
    
    def forward(self, z: torch.Tensor) -> torch.Tensor:
        """Returns soft hash codes in [-1, 1]"""
        h = torch.tanh(self.fc(z))
        return h
    
    def binarize(self, h: torch.Tensor) -> torch.Tensor:
        """For inference: convert to hard binary {-1, 1}"""
        return torch.sign(h)


class MultimodalHashKNN(nn.Module):
    """å®Œæ•´æ¨¡å‹ï¼šSigLIP2 + æ–¹å‘/å¹…åº¦åˆ†è§£ + Hadamard èåˆ + Hash + KNN"""
    
    def __init__(self, config):
        super().__init__()
        
        # SigLIP2 encoders - ä½¿ç”¨æ­£ç¢ºçš„è¼‰å…¥æ–¹å¼
        model_name = config.model.siglip2_variant
        print(f"è¼‰å…¥ SigLIP2 æ¨¡å‹: {model_name}")
        self.image_processor = AutoImageProcessor.from_pretrained(model_name, use_fast=False)
        self.tokenizer = GemmaTokenizerFast.from_pretrained(model_name)
        self.siglip_model = AutoModel.from_pretrained(model_name, trust_remote_code=True)
        print(f"âœ“ SigLIP2 è¼‰å…¥æˆåŠŸ (Model: {type(self.siglip_model).__name__})")

        # âš ï¸ å¿…é ˆå‡çµ towersï¼ˆRTX 5080 16GB é™åˆ¶ï¼‰
        if config.model.freeze_towers:
            for param in self.siglip_model.parameters():
                param.requires_grad = False
            print("âœ“ SigLIP2 towers frozen (saving ~7.5GB VRAM)")

        # ç²å– embedding ç¶­åº¦
        if hasattr(self.siglip_model.config, "projection_dim"):
            self.embed_dim = self.siglip_model.config.projection_dim
        elif hasattr(self.siglip_model.config, "text_config"):
            self.embed_dim = self.siglip_model.config.text_config.hidden_size
        else:
            self.embed_dim = 768
        
        # Decomposer
        self.decomposer = DirectionMagnitudeDecomposer(
            eps=config.model.decomposer.eps
        )
        
        # Fusion
        self.fusion = HadamardFusion(
            embed_dim=self.embed_dim,
            mlp_dims=config.model.fusion.mlp_dims,
            dropout=config.model.fusion.dropout,
            activation=config.model.fusion.activation
        )
        
        # Hash layer
        self.hash_layer = HashLayer(
            input_dim=config.model.fusion.mlp_dims[-1],
            hash_bits=config.model.hash.bits
        )
        
        # Classifier head (for training)
        self.classifier = nn.Linear(
            config.model.hash.bits,
            config.model.classifier.num_classes,
            bias=config.model.classifier.use_bias
        )
        
        self.config = config
    
    def forward(
        self,
        pixel_values: torch.Tensor,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None,
        return_components: bool = False
    ) -> torch.Tensor | Dict[str, torch.Tensor]:
        """
        Args:
            pixel_values: (B, C, H, W) images
            input_ids: (B, L) text tokens
            attention_mask: (B, L) attention mask
            return_components: whether to return intermediate results
        
        Returns:
            logits or dict of components
        """
        # Encode
        outputs = self.model(
            pixel_values=pixel_values,
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        v_img = outputs.image_embeds  # (B, D)
        v_txt = outputs.text_embeds   # (B, D)
        
        # Decompose
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        
        # Fuse
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        
        # Hash
        h = self.hash_layer(z)
        
        # Classify
        logits = self.classifier(h)
        
        if return_components:
            return {
                'logits': logits,
                'h': h,
                'd_img': d_img,
                'd_txt': d_txt,
                'm_img': m_img,
                'm_txt': m_txt,
                'z': z,
                'v_img': v_img,
                'v_txt': v_txt
            }
        else:
            return logits
    
    @torch.no_grad()
    def get_hash(
        self,
        pixel_values: torch.Tensor,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """For inference: return hash codes"""
        outputs = self.model(
            pixel_values=pixel_values,
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        v_img = outputs.image_embeds
        v_txt = outputs.text_embeds
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        h = self.hash_layer(z)
        return h
```

### 11.2 è³‡æ–™è¼‰å…¥å™¨ï¼ˆ`src/siglip2_multimodal_hash/dataset.py`ï¼‰

```python
# src/siglip2_multimodal_hash/dataset.py

import torch
from torch.utils.data import Dataset
from pathlib import Path
from PIL import Image
import pickle
import random
from typing import Optional

class COCOMultiLabelDataset(Dataset):
    """COCO å¤šæ¨™ç±¤è³‡æ–™é›†"""
    
    def __init__(
        self,
        data_root: str | Path,
        split: str = "train2014",
        processor = None,
        max_num_patches: int = 256,
        text_max_length: int = 64,
        use_karpathy_split: bool = False,
        karpathy_split_type: str = "train"  # "train", "val", "test"
    ):
        """
        Args:
            data_root: COCO è³‡æ–™é›†æ ¹ç›®éŒ„ï¼ˆä¾‹å¦‚ ./data/cocoï¼‰
            split: "train2014" or "val2014"
            processor: SigLIP2Processor
            max_num_patches: æœ€å¤§ patch æ•¸é‡
            text_max_length: æ–‡å­—æœ€å¤§é•·åº¦
            use_karpathy_split: æ˜¯å¦ä½¿ç”¨ Karpathy split
            karpathy_split_type: Karpathy split é¡å‹
        """
        self.data_root = Path(data_root)
        self.split = split
        self.processor = processor
        self.max_num_patches = max_num_patches
        self.text_max_length = text_max_length
        
        # è¼‰å…¥ç´¢å¼•
        index_file = self.data_root / f"index_{split}.pkl"
        print(f"è¼‰å…¥ç´¢å¼•: {index_file}")
        
        with open(index_file, "rb") as f:
            self.index = pickle.load(f)
        
        # å¦‚æœä½¿ç”¨ Karpathy splitï¼Œéœ€è¦é€²ä¸€æ­¥ç¯©é¸
        if use_karpathy_split:
            self._filter_karpathy_split(karpathy_split_type)
        
        # å»ºç«‹é¡åˆ¥æ˜ å°„ï¼ˆcategory_id -> indexï¼‰
        self.cat_id_to_idx = {
            cat_id: idx
            for idx, cat_id in enumerate(sorted(self.index["categories"].keys()))
        }
        self.num_classes = len(self.cat_id_to_idx)
        
        # å»ºç«‹å½±åƒ ID åˆ—è¡¨
        self.image_ids = list(self.index["images"].keys())
        
        print(f"âœ“ è¼‰å…¥ {len(self.image_ids)} å¼µå½±åƒ")
        print(f"âœ“ {self.num_classes} å€‹é¡åˆ¥")
    
    def _filter_karpathy_split(self, split_type: str):
        """æ ¹æ“š Karpathy split ç¯©é¸å½±åƒ"""
        import json
        
        karpathy_file = self.data_root / "karpathy_split.json"
        if not karpathy_file.exists():
            raise FileNotFoundError(
                f"Karpathy split file not found: {karpathy_file}\n"
                "è«‹åŸ·è¡Œ: python scripts/download_karpathy_split.py"
            )
        
        with open(karpathy_file) as f:
            karpathy_data = json.load(f)
        
        # å»ºç«‹ image_id -> split æ˜ å°„
        id_to_split = {}
        for item in karpathy_data["images"]:
            # COCO å½±åƒ ID æ ¼å¼ï¼šCOCO_train2014_000000123456
            filename = item["filename"]
            img_id = int(filename.split("_")[-1].split(".")[0])
            id_to_split[img_id] = item.get("split", "unknown")
        
        # ç¯©é¸å½±åƒ
        filtered_images = {
            img_id: img_info
            for img_id, img_info in self.index["images"].items()
            if id_to_split.get(img_id) == split_type
        }
        
        self.index["images"] = filtered_images
        print(f"âœ“ Karpathy {split_type} split: {len(filtered_images)} å¼µå½±åƒ")
    
    def __len__(self) -> int:
        return len(self.image_ids)
    
    def __getitem__(self, idx: int) -> dict:
        img_id = self.image_ids[idx]
        img_info = self.index["images"][img_id]
        
        # è¼‰å…¥å½±åƒ
        img_path = self.data_root / "images" / self.split / img_info["file_name"]
        image = Image.open(img_path).convert("RGB")
        
        # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ captionï¼ˆè¨“ç·´æ™‚å¢å¼·ï¼‰
        caption = random.choice(img_info["captions"])
        
        # å»ºç«‹ multi-hot label
        labels = torch.zeros(self.num_classes, dtype=torch.float32)
        for cat_id in img_info["categories"]:
            labels[self.cat_id_to_idx[cat_id]] = 1.0
        
        # ä½¿ç”¨ processor è™•ç†å½±åƒèˆ‡æ–‡å­—
        inputs = self.processor(
            text=[caption],
            images=image,
            return_tensors="pt",
            padding="max_length",
            max_length=self.text_max_length,
            truncation=True
        )
        
        # ç§»é™¤ batch ç¶­åº¦ï¼ˆå› ç‚º DataLoader æœƒè‡ªå‹• batchï¼‰
        return {
            'pixel_values': inputs['pixel_values'].squeeze(0),
            'input_ids': inputs['input_ids'].squeeze(0),
            'attention_mask': inputs['attention_mask'].squeeze(0),
            'labels': labels,
            'image_id': img_id,
            'caption': caption
        }


def create_dataloader(config, split: str = "train"):
    """å»ºç«‹ DataLoader"""
    from torch.utils.data import DataLoader
    from transformers import Siglip2Processor
    
    # è¼‰å…¥ processor
    processor = Siglip2Processor.from_pretrained(
        config.model.siglip2_variant
    )
    
    # æ±ºå®šä½¿ç”¨å“ªå€‹ COCO split
    if split == "train":
        coco_split = "train2014"
        shuffle = True
    else:
        coco_split = "val2014"
        shuffle = False
    
    # å»ºç«‹ dataset
    dataset = COCOMultiLabelDataset(
        data_root=config.paths.data_root,
        split=coco_split,
        processor=processor,
        max_num_patches=config.model.max_num_patches,
        text_max_length=config.model.text_max_length
    )
    
    # å»ºç«‹ dataloader
    dataloader = DataLoader(
        dataset,
        batch_size=config.training.batch_size,
        shuffle=shuffle,
        num_workers=config.dataloader.num_workers,
        pin_memory=config.dataloader.pin_memory,
        prefetch_factor=config.dataloader.prefetch_factor,
        persistent_workers=config.dataloader.persistent_workers,
        drop_last=config.dataloader.drop_last if split == "train" else False
    )
    
    return dataloader
```

### 11.3 æå¤±å‡½æ•¸ï¼ˆ`src/siglip2_multimodal_hash/losses.py`ï¼‰

```python
# src/siglip2_multimodal_hash/losses.py

import torch
import torch.nn as nn
import torch.nn.functional as F

def hash_regularization(
    h: torch.Tensor,
    lambda_balance: float = 0.1,
    lambda_decorr: float = 0.01
) -> torch.Tensor:
    """
    Hash æ­£å‰‡åŒ–æå¤±ï¼ˆä¸‰é …çµ„åˆï¼‰
    
    Args:
        h: (batch_size, hash_bits) soft hash codes
        lambda_balance: bit balance æ¬Šé‡
        lambda_decorr: bit decorrelation æ¬Šé‡
    
    Returns:
        loss_hash: scalar tensor
    """
    # 1. Quantization lossï¼ˆæ¨å‘ Â±1ï¼‰
    loss_quant = torch.mean((torch.abs(h) - 1) ** 2)
    
    # 2. Bit balance lossï¼ˆé¿å…æ‰€æœ‰ bit åå‘åŒä¸€æ¥µï¼‰
    bit_mean = torch.mean(h, dim=0)  # (hash_bits,)
    loss_balance = torch.mean(bit_mean ** 2)
    
    # 3. Bit decorrelation lossï¼ˆé¼“å‹µ bit ç¨ç«‹ï¼‰
    h_centered = h - torch.mean(h, dim=0, keepdim=True)
    cov = (h_centered.T @ h_centered) / h.size(0)  # (B, B)
    loss_decorr = (torch.sum(cov ** 2) - torch.trace(cov ** 2)) / (h.size(1) ** 2)
    
    # çµ„åˆ
    loss_hash = loss_quant + lambda_balance * loss_balance + lambda_decorr * loss_decorr
    
    return loss_hash


def compute_total_loss(outputs: dict, labels: torch.Tensor, config) -> dict:
    """
    è¨ˆç®—ç¸½æå¤±
    
    Args:
        outputs: æ¨¡å‹è¼¸å‡ºï¼ˆåŒ…å« logits, h, d_img, d_txt ç­‰ï¼‰
        labels: (B, C) multi-hot labels
        config: é…ç½®ç‰©ä»¶
    
    Returns:
        total_loss: ç¸½æå¤±
        loss_dict: å„é …æå¤±çš„å­—å…¸
    """
    logits = outputs['logits']
    h = outputs['h']
    d_img = outputs['d_img']
    d_txt = outputs['d_txt']
    
    # 1. BCE Lossï¼ˆä¸»è¦ç›£ç£è¨Šè™Ÿï¼‰
    loss_bce = F.binary_cross_entropy_with_logits(logits, labels)
    
    # 2. Cosine Alignment Loss
    loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
    
    # 3. Hash Regularization
    loss_hash = hash_regularization(
        h,
        lambda_balance=config.loss.hash_reg.lambda_balance,
        lambda_decorr=config.loss.hash_reg.lambda_decorr
    )
    
    # çµ„åˆç¸½æå¤±
    total_loss = (
        config.loss.bce_weight * loss_bce +
        config.loss.cosine_weight * loss_cos +
        config.loss.hash_weight * loss_hash
    )
    
    # è¿”å›æå¤±å­—å…¸ï¼ˆç”¨æ–¼ loggingï¼‰
    loss_dict = {
        'total': total_loss.item(),
        'bce': loss_bce.item(),
        'cos': loss_cos.item(),
        'hash': loss_hash.item()
    }
    
    return total_loss, loss_dict


class FocalLoss(nn.Module):
    """Focal Lossï¼ˆè™•ç†é¡åˆ¥ä¸å¹³è¡¡ï¼Œå¯é¸ï¼‰"""
    
    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """
        Args:
            logits: (B, C) raw predictions
            labels: (B, C) multi-hot labels
        """
        probs = torch.sigmoid(logits)
        
        # è¨ˆç®— focal weight
        pt = torch.where(labels == 1, probs, 1 - probs)
        focal_weight = (1 - pt) ** self.gamma
        
        # BCE loss with focal weight
        bce = F.binary_cross_entropy_with_logits(logits, labels, reduction='none')
        focal_loss = self.alpha * focal_weight * bce
        
        return focal_loss.mean()
```

### 11.4 ä¸»è¨“ç·´è…³æœ¬ï¼ˆ`scripts/train.py`ï¼‰

```python
# scripts/train.py

import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from pathlib import Path
import hydra
from omegaconf import DictConfig, OmegaConf
import wandb
from tqdm import tqdm
import sys

# åŠ å…¥ src åˆ° Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from siglip2_multimodal_hash.model import MultimodalHashKNN
from siglip2_multimodal_hash.dataset import create_dataloader
from siglip2_multimodal_hash.losses import compute_total_loss
from siglip2_multimodal_hash.utils import (
    get_gpu_memory_info,
    MemoryMonitor,
    set_seed
)


def train_epoch(
    model: MultimodalHashKNN,
    dataloader,
    optimizer,
    scheduler,
    scaler: GradScaler,
    config: DictConfig,
    epoch: int
) -> dict:
    """è¨“ç·´ä¸€å€‹ epoch"""
    
    model.train()
    total_losses = {'total': 0, 'bce': 0, 'cos': 0, 'hash': 0}
    
    accumulation_steps = config.training.gradient_accumulation_steps
    memory_monitor = MemoryMonitor(config.memory_optimization.alert_vram_threshold_gb)
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}")
    
    for batch_idx, batch in enumerate(pbar):
        # ç§»åˆ° GPU
        pixel_values = batch['pixel_values'].to('cuda', non_blocking=True)
        input_ids = batch['input_ids'].to('cuda', non_blocking=True)
        attention_mask = batch['attention_mask'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        # âš ï¸ æ··åˆç²¾åº¦å‰å‘å‚³æ’­
        with autocast(dtype=torch.float16):
            outputs = model(
                pixel_values=pixel_values,
                input_ids=input_ids,
                attention_mask=attention_mask,
                return_components=True
            )
            
            # è¨ˆç®—æå¤±
            loss_dict = compute_total_loss(outputs, labels, config.loss)
            loss = loss_dict["total"]
            loss = loss / accumulation_steps  # æ¢¯åº¦ç´¯ç©
        
        # åå‘å‚³æ’­
        scaler.scale(loss).backward()
        
        # âš ï¸ æ¢¯åº¦ç´¯ç©
        if (batch_idx + 1) % accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(
                model.parameters(),
                config.training.gradient_clip_norm
            )
            
            # æ›´æ–°åƒæ•¸
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
        
        # ç´¯ç©æå¤±
        for key in total_losses:
            total_losses[key] += loss_dict[key]
        
        # æ›´æ–°é€²åº¦æ¢
        pbar.set_postfix({
            'loss': loss_dict['total'],
            'bce': loss_dict['bce'],
            'mem': f"{memory_monitor.get_stats()['gpu']['allocated_gb']:.1f}GB"
        })
        
        # âš ï¸ å®šæœŸç›£æ§è¨˜æ†¶é«”
        if batch_idx % config.logging.log_every_n_steps == 0:
            if config.memory_optimization.log_gpu_memory:
                memory_monitor.print_stats(f"Batch {batch_idx} - ")
        
        # âš ï¸ å®šæœŸæ¸…ç†å¿«å–
        if batch_idx % config.memory_optimization.empty_cache_steps == 0:
            torch.cuda.empty_cache()
    
    # æ›´æ–°å­¸ç¿’ç‡
    scheduler.step()
    
    # è¿”å›å¹³å‡æå¤±
    n_batches = len(dataloader)
    return {k: v / n_batches for k, v in total_losses.items()}


@torch.no_grad()
def validate(
    model: MultimodalHashKNN,
    dataloader,
    config: DictConfig
) -> dict:
    """é©—è­‰"""
    
    model.eval()
    total_losses = {'total': 0, 'bce': 0, 'cos': 0, 'hash': 0}
    all_logits = []
    all_labels = []
    
    pbar = tqdm(dataloader, desc="Validating")
    
    for batch in pbar:
        pixel_values = batch['pixel_values'].to('cuda', non_blocking=True)
        input_ids = batch['input_ids'].to('cuda', non_blocking=True)
        attention_mask = batch['attention_mask'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        with autocast(dtype=torch.float16):
            outputs = model(
                pixel_values=pixel_values,
                input_ids=input_ids,
                attention_mask=attention_mask,
                return_components=True
            )
            
            loss, loss_dict = compute_total_loss(outputs, labels, config)
        
        # ç´¯ç©
        for key in total_losses:
            total_losses[key] += loss_dict[key]
        
        all_logits.append(outputs['logits'].cpu())
        all_labels.append(labels.cpu())
    
    # è¨ˆç®—æŒ‡æ¨™
    from sklearn.metrics import average_precision_score, f1_score
    
    all_logits = torch.cat(all_logits, dim=0)
    all_labels = torch.cat(all_labels, dim=0)
    
    y_true = all_labels.numpy()
    y_scores = torch.sigmoid(all_logits).numpy()
    y_pred = (y_scores > 0.5).astype(int)
    
    metrics = {
        'loss': total_losses['total'] / len(dataloader),
        'mAP': average_precision_score(y_true, y_scores, average='macro'),
        'f1_micro': f1_score(y_true, y_pred, average='micro'),
        'f1_macro': f1_score(y_true, y_pred, average='macro'),
    }
    
    return metrics


@hydra.main(version_base=None, config_path="../configs/hardware", config_name="rtx5080_16gb")
def main(config: DictConfig):
    """ä¸»è¨“ç·´å‡½æ•¸"""
    
    # é¡¯ç¤ºé…ç½®
    print("="*60)
    print("è¨“ç·´é…ç½®")
    print("="*60)
    print(OmegaConf.to_yaml(config))
    print("="*60)
    
    # è¨­å®š seed
    set_seed(config.experiment.seed)
    
    # åˆå§‹åŒ– wandb
    if config.logging.use_wandb:
        wandb.init(
            project=config.logging.wandb_project,
            entity=config.logging.wandb_entity,
            config=OmegaConf.to_container(config, resolve=True),
            name=config.experiment.name
        )
    
    # å»ºç«‹æ¨¡å‹
    print("\nå»ºç«‹æ¨¡å‹...")
    model = MultimodalHashKNN(config).cuda()
    
    # é¡¯ç¤ºè¨˜æ†¶é«”è³‡è¨Š
    mem_info = get_gpu_memory_info()
    print(f"æ¨¡å‹è¼‰å…¥å¾Œ GPU è¨˜æ†¶é«”: {mem_info['allocated_gb']:.2f}GB / 16GB")
    
    # å»ºç«‹ DataLoader
    print("\nå»ºç«‹ DataLoader...")
    train_loader = create_dataloader(config, split='train')
    val_loader = create_dataloader(config, split='val')
    
    # å»ºç«‹ optimizer èˆ‡ scheduler
    print("\nå»ºç«‹ optimizer èˆ‡ scheduler...")
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.optimizer.lr,
        weight_decay=config.optimizer.weight_decay,
        betas=config.optimizer.betas
    )
    
    from transformers import get_cosine_schedule_with_warmup
    
    num_training_steps = len(train_loader) * config.training.num_epochs
    num_warmup_steps = int(num_training_steps * config.scheduler.warmup_ratio)
    
    scheduler = get_cosine_schedule_with_warmup(
        optimizer,
        num_warmup_steps=num_warmup_steps,
        num_training_steps=num_training_steps,
        num_cycles=1
    )
    
    # æ··åˆç²¾åº¦ scaler
    scaler = GradScaler()
    
    # è¨“ç·´è¿´åœˆ
    print("\né–‹å§‹è¨“ç·´...")
    print("="*60)
    
    best_val_map = 0
    patience_counter = 0
    
    for epoch in range(config.training.num_epochs):
        print(f"\nEpoch {epoch+1}/{config.training.num_epochs}")
        print("-"*60)
        
        # è¨“ç·´
        train_losses = train_epoch(
            model, train_loader, optimizer, scheduler, scaler, config, epoch
        )
        
        print(f"Train - Loss: {train_losses['total']:.4f} "
              f"(BCE: {train_losses['bce']:.4f}, "
              f"Cos: {train_losses['cos']:.4f}, "
              f"Hash: {train_losses['hash']:.4f})")
        
        # é©—è­‰
        if (epoch + 1) % config.training.val_every_n_epochs == 0:
            val_metrics = validate(model, val_loader, config)
            
            print(f"Val   - Loss: {val_metrics['loss']:.4f}, "
                  f"mAP: {val_metrics['mAP']:.4f}, "
                  f"F1-Micro: {val_metrics['f1_micro']:.4f}, "
                  f"F1-Macro: {val_metrics['f1_macro']:.4f}")
            
            # è¨˜éŒ„åˆ° wandb
            if config.logging.use_wandb:
                wandb.log({
                    'epoch': epoch,
                    'train/loss': train_losses['total'],
                    'train/loss_bce': train_losses['bce'],
                    'train/loss_cos': train_losses['cos'],
                    'train/loss_hash': train_losses['hash'],
                    'val/loss': val_metrics['loss'],
                    'val/mAP': val_metrics['mAP'],
                    'val/f1_micro': val_metrics['f1_micro'],
                    'val/f1_macro': val_metrics['f1_macro'],
                    'lr': optimizer.param_groups[0]['lr']
                })
            
            # å„²å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['mAP'] > best_val_map:
                best_val_map = val_metrics['mAP']
                patience_counter = 0
                
                # å„²å­˜ checkpoint
                checkpoint_dir = Path(config.checkpointing.save_dir)
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                checkpoint_path = checkpoint_dir / f"best_model_epoch{epoch+1}_mAP{val_metrics['mAP']:.4f}.pth"
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'val_mAP': val_metrics['mAP'],
                    'config': OmegaConf.to_container(config, resolve=True)
                }, checkpoint_path)
                
                print(f"âœ“ å„²å­˜æœ€ä½³æ¨¡å‹: {checkpoint_path}")
            else:
                patience_counter += 1
            
            # Early stopping
            if patience_counter >= config.training.early_stopping_patience:
                print(f"\nEarly stopping triggered after {epoch+1} epochs")
                break
    
    print("\n" + "="*60)
    print("è¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³ Val mAP: {best_val_map:.4f}")
    print("="*60)
    
    if config.logging.use_wandb:
        wandb.finish()


if __name__ == "__main__":
    main()
```

### 11.5 å·¥å…·å‡½æ•¸ï¼ˆ`src/siglip2_multimodal_hash/utils.py`ï¼‰

```python
# src/siglip2_multimodal_hash/utils.py

import torch
import random
import numpy as np
from typing import Dict

def set_seed(seed: int = 42):
    """è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡ç¾æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # ä»¥ä¸‹è¨­å®šæœƒæ¸›æ…¢è¨“ç·´ï¼Œä½†ä¿è­‰å¯é‡ç¾
    # torch.backends.cudnn.deterministic = True
    # torch.backends.cudnn.benchmark = False


def get_gpu_memory_info() -> Dict[str, float]:
    """ç²å– GPU è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        max_allocated = torch.cuda.max_memory_allocated() / 1e9
        
        return {
            "allocated_gb": allocated,
            "reserved_gb": reserved,
            "max_allocated_gb": max_allocated,
            "free_gb": 16.0 - reserved
        }
    return {}


class MemoryMonitor:
    """è¨˜æ†¶é«”ç›£æ§å·¥å…·"""
    
    def __init__(self, alert_threshold_gb: float = 14.5):
        self.alert_threshold_gb = alert_threshold_gb
        self.peak_vram = 0
    
    def get_stats(self) -> dict:
        """ç²å–å®Œæ•´è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = {}
        
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            max_allocated = torch.cuda.max_memory_allocated() / 1e9
            
            stats['gpu'] = {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'max_allocated_gb': max_allocated,
                'free_gb': 16.0 - reserved,
                'utilization_%': allocated / 16.0 * 100
            }
            
            self.peak_vram = max(self.peak_vram, allocated)
            
            if allocated > self.alert_threshold_gb:
                stats['gpu']['alert'] = True
        
        return stats
    
    def print_stats(self, prefix: str = ""):
        """åˆ—å°è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = self.get_stats()
        
        if 'gpu' in stats:
            gpu = stats['gpu']
            print(f"{prefix}GPU: {gpu['allocated_gb']:.2f}GB / 16GB "
                  f"({gpu['utilization_%']:.1f}%), "
                  f"Peak: {self.peak_vram:.2f}GB")
            
            if gpu.get('alert'):
                print(f"  âš ï¸  WARNING: VRAM usage high!")
    
    def reset_peak(self):
        """é‡ç½®å³°å€¼çµ±è¨ˆ"""
        torch.cuda.reset_peak_memory_stats()
        self.peak_vram = 0
```

---

## 12. è©•ä¼°æŒ‡æ¨™

æœ¬å°ˆæ¡ˆæ¡ç”¨å¤šæ¨™ç±¤åˆ†é¡ç ”ç©¶å¸¸ç”¨çš„è©•ä¼°æŒ‡æ¨™ï¼Œä»¥å°é½Šç›¸é—œé ˜åŸŸçš„å­¸è¡“æ¨™æº–ã€‚

### 12.1 ä¸»è¦æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | æ–¹å‘ |
| ------ | ------ | ------ |
| **mAP** | Mean Average Precisionï¼Œå„é¡åˆ¥ AP çš„å¹³å‡å€¼ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **AUC-ROC (Macro)** | ROC æ›²ç·šä¸‹é¢ç©ï¼Œå„é¡åˆ¥å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **AUC-ROC (Micro)** | ROC æ›²ç·šä¸‹é¢ç©ï¼Œå…¨å±€å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **F1-Macro** | F1 åˆ†æ•¸ï¼Œå„é¡åˆ¥å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **F1-Micro** | F1 åˆ†æ•¸ï¼Œå…¨å±€å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |

### 12.2 Precision & Recall

| æŒ‡æ¨™ | èªªæ˜ | æ–¹å‘ |
| ------ | ------ | ------ |
| **Precision-Macro** | ç²¾ç¢ºç‡ï¼Œå„é¡åˆ¥å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Precision-Micro** | ç²¾ç¢ºç‡ï¼Œå…¨å±€å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Recall-Macro** | å¬å›ç‡ï¼Œå„é¡åˆ¥å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Recall-Micro** | å¬å›ç‡ï¼Œå…¨å±€å¹³å‡ | â†‘ è¶Šé«˜è¶Šå¥½ |

### 12.3 Ranking æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | æ–¹å‘ |
| ------ | ------ | ------ |
| **LRAP** | Label Ranking Average Precision | â†‘ è¶Šé«˜è¶Šå¥½ |
| **Ranking Loss** | æ’åºæå¤±ï¼Œå¹³å‡æ’åºéŒ¯èª¤ç‡ | â†“ è¶Šä½è¶Šå¥½ |
| **Coverage Error** | å¹³å‡éœ€è¦åŒ…å«å¤šå°‘æ¨™ç±¤æ‰èƒ½æ¶µè“‹æ‰€æœ‰çœŸå¯¦æ¨™ç±¤ | â†“ è¶Šä½è¶Šå¥½ |

### 12.4 å…¶ä»–æŒ‡æ¨™

| æŒ‡æ¨™ | èªªæ˜ | æ–¹å‘ |
| ------ | ------ | ------ |
| **Hamming Loss** | æ¼¢æ˜æå¤±ï¼Œé æ¸¬éŒ¯èª¤çš„æ¨™ç±¤æ¯”ä¾‹ | â†“ è¶Šä½è¶Šå¥½ |
| **MAE** | Mean Absolute Errorï¼Œé æ¸¬æ©Ÿç‡èˆ‡çœŸå¯¦æ¨™ç±¤çš„å¹³å‡å·®è· | â†“ è¶Šä½è¶Šå¥½ |

### 12.5 è¨ˆç®—å¯¦ä¾‹

```python
from sklearn.metrics import (
    average_precision_score,
    f1_score,
    roc_auc_score,
    precision_score,
    recall_score,
    hamming_loss,
    coverage_error,
    label_ranking_loss,
    label_ranking_average_precision_score,
)
import numpy as np

def compute_all_metrics(y_true, y_pred_proba, threshold=0.5):
    """
    è¨ˆç®—æ‰€æœ‰å¤šæ¨™ç±¤åˆ†é¡æŒ‡æ¨™
    
    Args:
        y_true: (N, C) çœŸå¯¦æ¨™ç±¤ (binary)
        y_pred_proba: (N, C) é æ¸¬æ©Ÿç‡
        threshold: äºŒå…ƒåŒ–é–¾å€¼
    """
    y_pred = (y_pred_proba > threshold).astype(int)
    
    metrics = {
        # ä¸»è¦æŒ‡æ¨™
        'mAP': average_precision_score(y_true, y_pred_proba, average='macro'),
        'auc_macro': roc_auc_score(y_true, y_pred_proba, average='macro'),
        'auc_micro': roc_auc_score(y_true, y_pred_proba, average='micro'),
        
        # F1
        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        'f1_micro': f1_score(y_true, y_pred, average='micro', zero_division=0),
        
        # Precision & Recall
        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
        
        # Ranking
        'lrap': label_ranking_average_precision_score(y_true, y_pred_proba),
        'ranking_loss': label_ranking_loss(y_true, y_pred_proba),
        'coverage_error': coverage_error(y_true, y_pred_proba),
        
        # å…¶ä»–
        'hamming_loss': hamming_loss(y_true, y_pred),
        'mae': np.mean(np.abs(y_pred_proba - y_true)),
    }
    return metrics
```

### 12.6 è«–æ–‡å ±å‘Šæ ¼å¼

å»ºè­°åœ¨è«–æ–‡ä¸­ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å ±å‘Š 5-Fold CV çµæœï¼š

```plaintext
mAP:        0.68 Â± 0.01
AUC-Macro:  0.72 Â± 0.01  
F1-Macro:   0.54 Â± 0.02
Precision:  0.65 Â± 0.01
Recall:     0.48 Â± 0.02
```

---

## 13. ç¡¬é«”ç‰¹å®šå„ªåŒ–

### 13.1 è¨˜æ†¶é«”ä½¿ç”¨æª¢æŸ¥æ¸…å–®

åœ¨é–‹å§‹è¨“ç·´å‰ï¼Œç¢ºèªä»¥ä¸‹æ‰€æœ‰é …ç›®ï¼š

```bash
# åŸ·è¡Œæª¢æŸ¥è…³æœ¬
cat > scripts/check_memory_config.py << 'EOF'
#!/usr/bin/env python3
import yaml
from pathlib import Path

def check_config():
    config_file = Path("configs/hardware/rtx5080_16gb.yaml")
    
    if not config_file.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return False
    
    with open(config_file) as f:
        config = yaml.safe_load(f)
    
    checks = {
        "âœ… Mixed precision enabled": config['memory_optimization']['mixed_precision'],
        "âœ… Batch size <= 32": config['training']['batch_size'] <= 32,
        "âœ… Towers frozen": config['model']['freeze_towers'],
        "âœ… Gradient accumulation >= 2": config['training']['gradient_accumulation_steps'] >= 2,
        "âœ… Not using SigLIP-large": 'base' in config['model']['siglip2_variant'],
        "âœ… num_workers optimized": config['dataloader']['num_workers'] >= 8,
    }
    
    print("è¨˜æ†¶é«”å„ªåŒ–é…ç½®æª¢æŸ¥:")
    for check, passed in checks.items():
        symbol = "âœ…" if passed else "âŒ"
        print(f"  {symbol} {check.replace('âœ…', '').replace('âŒ', '')}")
    
    if all(checks.values()):
        print("\nâœ… æ‰€æœ‰æª¢æŸ¥é€šéï¼å¯ä»¥å®‰å…¨è¨“ç·´ã€‚")
        return True
    else:
        print("\nâš ï¸  éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œå»ºè­°ä¿®æ­£å¾Œå†è¨“ç·´ã€‚")
        return False

if __name__ == "__main__":
    check_config()
EOF

chmod +x scripts/check_memory_config.py
python scripts/check_memory_config.py
```

---

## 14. åƒè€ƒæ–‡ç»

### æ ¸å¿ƒæ–¹æ³•

1. **SigLIP 2**: Jiasen Lu, et al. "SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features". arXiv:2502.14786, 2025.

2. **MS-COCO Dataset**: Tsung-Yi Lin, et al. "Microsoft COCO: Common Objects in Context". ECCV 2014.

3. **MS-COCO Captions**: Xinlei Chen, et al. "Microsoft COCO Captions: Data Collection and Evaluation Server". arXiv:1504.00325, 2015.

### Hash æ–¹æ³•

1. **Deep Supervised Discrete Hashing**: Qi Li, et al. "Deep Supervised Discrete Hashing". NeurIPS 2017.

2. **HashNet**: Zhangjie Cao, et al. "HashNet: Deep Learning to Hash by Continuation". ICCV 2017.

3. **Learning to Hash Survey**: Jun Wang, et al. "Learning to Hash for Indexing Big Data - A Survey". Proceedings of the IEEE, 2015.

### å¤šæ¨¡æ…‹èåˆ

1. **MCB**: Akira Fukui, et al. "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding". EMNLP 2016.

2. **MUTAN**: Hedi Ben-younes, et al. "MUTAN: Multimodal Tucker Fusion for Visual Question Answering". ICCV 2017.

### KNN èˆ‡ Multi-label

1. **Ranking-based KNN**: Derek Hoiem, et al. "A Ranking-based KNN Approach for Multi-label Classification". AISTATS 2012.

### è¨“ç·´æŠ€å·§

1. **Focal Loss**: Tsung-Yi Lin, et al. "Focal Loss for Dense Object Detection". ICCV 2017.

2. **Mixed Precision Training**: Paulius Micikevicius, et al. "Mixed Precision Training". ICLR 2018.

---

## 15. é™„éŒ„

### é™„éŒ„ A: å¿«é€Ÿå•Ÿå‹•æŒ‡ä»¤ï¼ˆâ­ å°æ‡‰ä½ çš„å°ˆæ¡ˆï¼‰

```bash
# ==========================================
# 0. åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„
# ==========================================
cd ~/Documents/Coding/github.com/natsuki221/AGCH-Improvement

# ==========================================
# 1. å•Ÿå‹•è™›æ“¬ç’°å¢ƒï¼ˆå¦‚æœä½¿ç”¨ conda baseï¼‰
# ==========================================
# ä½ ç›®å‰åœ¨ (AGCH-Improvement) (base)ï¼Œæ‡‰è©²å·²ç¶“å•Ÿå‹•

# ==========================================
# 2. é©—è­‰ç’°å¢ƒ
# ==========================================
python scripts/verify_setup.py

# ==========================================
# 3. å»ºç«‹è³‡æ–™é›†ç´¢å¼•ï¼ˆå¦‚æœé‚„æ²’å»ºç«‹ï¼‰
# ==========================================
python scripts/create_dataset_index.py

# ==========================================
# 4. ä¸‹è¼‰ Karpathy split
# ==========================================
python scripts/download_karpathy_split.py

# ==========================================
# 5. æ¸¬è©¦ SigLIP2 è¼‰å…¥
# ==========================================
python scripts/test_siglip2.py

# ==========================================
# 6. åˆ†æè³‡æ–™é›†çµ±è¨ˆ
# ==========================================
python scripts/analyze_dataset.py

# ==========================================
# 7. æª¢æŸ¥è¨˜æ†¶é«”é…ç½®
# ==========================================
python scripts/check_memory_config.py

# ==========================================
# 8. é–‹å§‹è¨“ç·´ï¼ˆBaselineï¼‰
# ==========================================
python scripts/train.py \
  --config-name rtx5080_16gb \
  experiment.name=baseline_run1

# ==========================================
# 9. ç›£æ§è¨“ç·´ï¼ˆå¦é–‹çµ‚ç«¯ï¼‰
# ==========================================
watch -n 1 nvidia-smi

# ==========================================
# 10. æŸ¥çœ‹ wandb è¨“ç·´æ›²ç·š
# ==========================================
# é–‹å•Ÿç€è¦½å™¨: https://wandb.ai/natsuki221/siglip2-multimodal-hash
```

### é™„éŒ„ B: ç›®å‰å°ˆæ¡ˆç‹€æ…‹æª¢æŸ¥æ¸…å–®

> **æ›´æ–°æ—¥æœŸ**: 2026-02-02

#### âœ… å·²å®Œæˆ

**åŸºç¤å»ºè¨­**

- [x] å°ˆæ¡ˆç›®éŒ„çµæ§‹å»ºç«‹
- [x] `.gitignore` è¨­å®š
- [x] `pyproject.toml` é…ç½®ï¼ˆå« CUDA 12.8 Nightlyï¼‰
- [x] `requirements.txt` ç”Ÿæˆ
- [x] `uv.lock` ä¾è³´é–å®š
- [x] è™›æ“¬ç’°å¢ƒè¨­å®š (`.venv/`)

**è³‡æ–™é›†**

- [x] COCO 2014 è³‡æ–™é›†ä¸‹è¼‰ (`data/coco/images/`)
- [x] COCO æ¨™è¨»ä¸‹è¼‰ (`data/coco/annotations/`)
- [x] å»ºç«‹è³‡æ–™é›†ç´¢å¼• (`index_train2014.pkl`, `index_val2014.pkl`)
- [x] å»ºç«‹ 5-Fold åˆ‡åˆ† (`5fold_split.json`)

**é…ç½®æª”æ¡ˆ**

- [x] ç¡¬é«”é…ç½® (`configs/hardware/rtx5080_16gb.yaml`)
- [x] å¯¦é©—é…ç½® (`configs/experiments/baseline.yaml`)
- [x] CV å¯¦é©—é…ç½® (`configs/experiments/cv_experiment.yaml`)
- [x] Grid Search é…ç½® (`configs/experiments/grid_search.yaml`)
- [x] Ablation é…ç½® (`configs/experiments/ablation_*.yaml`)

**æ¨¡å‹ç¨‹å¼ç¢¼**

- [x] æ¨¡å‹å®šç¾© (`src/siglip2_multimodal_hash/model.py`)
- [x] è³‡æ–™è¼‰å…¥å™¨ (`src/siglip2_multimodal_hash/dataset.py`)
- [x] æå¤±å‡½æ•¸ (`src/siglip2_multimodal_hash/losses.py`)
- [x] å·¥å…·å‡½æ•¸ (`src/siglip2_multimodal_hash/utils.py`)
- [x] KNN æ¨¡çµ„ (`src/siglip2_multimodal_hash/knn.py`)

**è¨“ç·´èˆ‡è©•ä¼°è…³æœ¬**

- [x] ä¸»è¨“ç·´è…³æœ¬ (`scripts/train.py`)
- [x] è©•ä¼°è…³æœ¬ (`scripts/evaluate.py`)
- [x] KNN ç´¢å¼•å»ºç«‹ (`scripts/build_knn_index.py`)
- [x] 5-Fold CV è‡ªå‹•åŒ– (`scripts/run_5fold_cv.sh`)
- [x] çµæœèšåˆ (`scripts/aggregate_cv_results.py`)
- [x] Hold-out æ¸¬è©¦ (`scripts/test_on_holdout.py`)
- [x] K-Fold åˆ‡åˆ†ç”Ÿæˆ (`scripts/create_kfold_split.py`)

**è¼”åŠ©è…³æœ¬**

- [x] è³‡æ–™é›†åˆ†æ (`scripts/analyze_dataset.py`)
- [x] ç’°å¢ƒé©—è­‰ (`scripts/verify_setup.py`)
- [x] SigLIP2 æ¸¬è©¦ (`scripts/test_siglip2.py`)
- [x] è³‡æ–™é›†ç´¢å¼•å»ºç«‹ (`scripts/create_dataset_index.py`)
- [x] è¨“ç·´ç›£æ§ (`scripts/monitor_training.sh`)

#### âš ï¸ å¾…å®Œæˆ

**ç’°å¢ƒä¾è³´**

- [ ] å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬ (`faiss-gpu`)

**è³‡æ–™æº–å‚™**

- [ ] ä¸‹è¼‰ Karpathy split (`karpathy_split.json`)

**è¨“ç·´åŸ·è¡Œ**

- [ ] åŸ·è¡Œç’°å¢ƒé©—è­‰ (`python scripts/verify_setup.py`)
- [ ] åŸ·è¡Œç¬¬ä¸€è¼ª baseline è¨“ç·´
- [ ] åŸ·è¡Œ 5-Fold CV å®Œæ•´è¨“ç·´

### é™„éŒ„ C: ä¸‹ä¸€æ­¥æ“ä½œé †åº

```bash
# æ­¥é©Ÿ 1: å‡ç´š FAISSï¼ˆæ“‡ä¸€ï¼‰
conda install -c pytorch -c nvidia faiss-gpu
# æˆ–å¾æºç¢¼ç·¨è­¯ï¼ˆè¦‹ 2.4 ç¯€ï¼‰

# æ­¥é©Ÿ 2: å»ºç«‹è³‡æ–™é›†ç´¢å¼•
python scripts/create_dataset_index.py
python scripts/download_karpathy_split.py

# æ­¥é©Ÿ 3: å»ºç«‹é…ç½®ç›®éŒ„èˆ‡æª”æ¡ˆ
mkdir -p configs/{hardware,experiments}

# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ configs/hardware/rtx5080_16gb.yaml
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ configs/experiments/baseline.yaml

# æ­¥é©Ÿ 4: å»ºç«‹æ¨¡å‹ç¨‹å¼ç¢¼
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ src/siglip2_multimodal_hash/*.py

# æ­¥é©Ÿ 5: å»ºç«‹è¨“ç·´è…³æœ¬
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ scripts/train.py

# æ­¥é©Ÿ 6: é©—è­‰ç’°å¢ƒ
python scripts/verify_setup.py
python scripts/check_memory_config.py

# æ­¥é©Ÿ 7: é–‹å§‹è¨“ç·´ï¼
python scripts/train.py
```

---

## çµèª

æœ¬å¯¦é©—è¨ˆç•«å·²å®Œå…¨é‡å°ä½ çš„ **AGCH-Improvement å°ˆæ¡ˆ**é€²è¡Œå„ªåŒ–ï¼š

### âœ… ä¸»è¦ç‰¹é»

1. **å®Œå…¨åŒ¹é…ä½ çš„å°ˆæ¡ˆçµæ§‹** - æ‰€æœ‰è·¯å¾‘ã€æª”æ¡ˆåç¨±éƒ½å°æ‡‰
2. **CUDA 12.8 Nightly æ­£ç¢ºé…ç½®** - ä¸æ˜¯ 13.0
3. **PyTorch 2.6.0+cu124** - å°æ‡‰ä½ çš„ pyproject.toml
4. **RTX 5080 16GB å„ªåŒ–** - batch_size=32, æ··åˆç²¾åº¦, æ¢¯åº¦ç´¯ç©
5. **å¯ç«‹å³ä½¿ç”¨çš„ç¨‹å¼ç¢¼** - æ‰€æœ‰è…³æœ¬éƒ½æ˜¯å®Œæ•´ä¸”å¯åŸ·è¡Œçš„
6. **æ•´åˆç¾æœ‰è…³æœ¬** - ä½¿ç”¨ä½ å·²å»ºç«‹çš„ scripts/

### ğŸ“Š é æœŸæ•ˆèƒ½

- è¨“ç·´é€Ÿåº¦: ~1.8 iter/s
- æ¯ epoch: ~35 åˆ†é˜
- å®Œæ•´è¨“ç·´: **~17.5 å°æ™‚**
- VRAM ä½¿ç”¨: **~10.2 GB / 16 GB**

### ğŸ¯ ç«‹å³é–‹å§‹

1. å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬
2. å»ºç«‹è³‡æ–™é›†ç´¢å¼•
3. è¤‡è£½é…ç½®æª”æ¡ˆèˆ‡æ¨¡å‹ç¨‹å¼ç¢¼
4. åŸ·è¡Œç¬¬ä¸€è¼ªè¨“ç·´

ç¥å¯¦é©—é †åˆ©ï¼ğŸš€

---

## 16. äº”æŠ˜äº¤å‰é©—è­‰ (5-Fold CV)

> **æœ¬ç« æ•´åˆè‡ª v2.3 ç‰ˆæœ¬**ï¼Œæä¾›å®Œæ•´çš„äº”æŠ˜äº¤å‰é©—è­‰å¯¦ä½œæŒ‡å—ã€‚

### 16.1 ç‚ºä»€éº¼åš 5-Fold CVï¼Ÿ

åœ¨å­¸è¡“è«–æ–‡ä¸­ï¼Œå–®æ¬¡å¯¦é©—çš„çµæœå®¹æ˜“å—åˆ°è³‡æ–™åˆ‡åˆ†ï¼ˆData Splitï¼‰çš„éš¨æ©Ÿæ€§å½±éŸ¿ã€‚æ¡ç”¨ **5-Fold Cross-Validation** å¯ä»¥ï¼š

1. **é©—è­‰æ³›åŒ–èƒ½åŠ›**: è­‰æ˜æ¨¡å‹æ•ˆèƒ½ä¸æ˜¯å› ç‚ºå‰›å¥½åˆ†åˆ°äº†ç°¡å–®çš„é©—è­‰é›†
2. **æå‡æ•¸æ“šåˆ©ç”¨ç‡**: é™¤äº† Test Set å¤–ï¼Œæ‰€æœ‰æ•¸æ“šéƒ½åƒèˆ‡éè¨“ç·´èˆ‡è©•ä¼°
3. **å¢åŠ è«–æ–‡èªªæœåŠ›**: æä¾› `Mean Â± Std` çš„çµæœï¼Œæ˜¯é ‚æœƒè«–æ–‡çš„æ¨™æº–é…ç½®
4. **æª¢æ¸¬éæ“¬åˆ**: å¦‚æœ 5 æŠ˜çµæœå·®ç•°å¾ˆå¤§ï¼Œèªªæ˜æ¨¡å‹ä¸ç©©å®š

### 16.2 èˆ‡å–®æ¬¡è¨“ç·´çš„å°æ¯”

| æŒ‡æ¨™ | å–®æ¬¡è¨“ç·´ (v2.2) | äº”æŠ˜äº¤å‰é©—è­‰ (v2.3) |
| ------ | ---------------- | --------------------- |
| **è¨“ç·´æ¬¡æ•¸** | 1 æ¬¡ | 5 æ¬¡ |
| **ç¸½æ™‚é•·** | ~17.5 å°æ™‚ | **~20-26 å°æ™‚** |
| **çµæœå½¢å¼** | mAP: 0.72 | **mAP: 0.72 Â± 0.01** |
| **è«–æ–‡åƒ¹å€¼** | ä¸­ç­‰ | **é«˜ï¼ˆé ‚æœƒæ¨™æº–ï¼‰** |
| **ç¡¬ç¢Ÿéœ€æ±‚** | ~5 GB | ~15-25 GBï¼ˆ5 å€‹æ¨¡å‹ï¼‰ |

### 16.3 è³‡æ–™åˆ‡åˆ†ç­–ç•¥ï¼ˆé»ƒé‡‘æ³•å‰‡ï¼‰

**çµ•å°ä¸å¯æ±™æŸ“ Karpathy Test Setï¼**

```plaintext
åŸå§‹ COCO 2014 è³‡æ–™é›†
â”œâ”€â”€ train2014: 82,783 å¼µ
â””â”€â”€ val2014: 40,504 å¼µ
    ç¸½è¨ˆ: 123,287 å¼µ

ç¶“é Karpathy split é‡æ–°çµ„ç¹”ï¼š
â”œâ”€â”€ train: 113,287 å¼µ      â† è¨“ç·´ä¸»é«”
â”œâ”€â”€ val: 5,000 å¼µ          â† åŸå§‹é©—è­‰é›†
â””â”€â”€ test: 5,000 å¼µ         â† âš ï¸ çµ•å°éš”é›¢ï¼

äº”æŠ˜åˆ‡åˆ†é‚è¼¯ï¼š
Step 1: é–å®š Test Set (5,000 å¼µ) â†’ å®Œå…¨éš”é›¢
Step 2: Dev Pool = train + val (~118,287 å¼µ)
Step 3: 5-Fold åˆ‡åˆ†ï¼ˆæ¯æŠ˜ ~23,657 å¼µé©—è­‰ï¼‰

Fold 0: Train (~94,630 å¼µ) | Val (~23,657 å¼µ)
Fold 1: Train (~94,630 å¼µ) | Val (~23,657 å¼µ)
Fold 2: Train (~94,630 å¼µ) | Val (~23,657 å¼µ)
Fold 3: Train (~94,630 å¼µ) | Val (~23,657 å¼µ)
Fold 4: Train (~94,630 å¼µ) | Val (~23,657 å¼µ)
```

#### 16.3.1 è³‡æ–™æµå‘åœ–

```mermaid
flowchart TD
    A[COCO 2014<br/>123,287 å¼µ] --> B{Karpathy Split}
    
    B --> C[Train<br/>113,287 å¼µ]
    B --> D[Val<br/>5,000 å¼µ]
    B --> E[Test<br/>5,000 å¼µ<br/>âš ï¸ å®Œå…¨éš”é›¢]
    
    C --> F[Dev Pool<br/>118,287 å¼µ]
    D --> F
    
    F --> G{5-Fold Split<br/>random_state=42}
    
    G --> H[Fold 0<br/>Train: 94,630<br/>Val: 23,657]
    G --> I[Fold 1<br/>Train: 94,630<br/>Val: 23,657]
    G --> J[Fold 2<br/>Train: 94,630<br/>Val: 23,657]
    G --> K[Fold 3<br/>Train: 94,630<br/>Val: 23,657]
    G --> L[Fold 4<br/>Train: 94,630<br/>Val: 23,657]
    
    H --> M[Model 0<br/>mAP: 0.71]
    I --> N[Model 1<br/>mAP: 0.73]
    J --> O[Model 2<br/>mAP: 0.72]
    K --> P[Model 3<br/>mAP: 0.71]
    L --> Q[Model 4<br/>mAP: 0.74]
    
    M --> R[èšåˆçµæœ<br/>Mean: 0.72<br/>Std: 0.01]
    N --> R
    O --> R
    P --> R
    Q --> R
    
    R --> S[æœ€çµ‚æ¸¬è©¦<br/>åœ¨ Test Set<br/>5,000 å¼µ]
    E --> S
    
    S --> T[è«–æ–‡å ±å‘Š<br/>mAP: 0.72 Â± 0.01<br/>Test mAP: 0.73]
    
    style E fill:#ffcccc
    style F fill:#ccffcc
    style R fill:#ccccff
    style T fill:#ffffcc
```

### 16.4 CV å„ªåŒ–è¨“ç·´åƒæ•¸

ç”±æ–¼è¨“ç·´é‡è®Šç‚ºåŸæœ¬çš„ 5 å€ï¼Œéœ€è¦é€²è¡Œæ™‚é–“ç®¡ç†ï¼š

| åƒæ•¸ | åŸè¨ˆç•« (v2.2) | **CV å„ªåŒ–ç‰ˆ (v2.3)** | åŸå›  |
| ------ | -------------- | --------------------- | ------ |
| **Epochs** | 30 | **20** | è³‡æ–™é‡è®Šå¤§ï¼Œæ¯ Epoch è¿­ä»£æ¬¡æ•¸å¢åŠ  |
| **Early Stopping** | Patience = 5 | **Patience = 3** | ç¯€çœç„¡æ•ˆé‹ç®—æ™‚é–“ |
| **Save Top K** | 3 | **1** | ç¯€çœç¡¬ç¢Ÿç©ºé–“ |
| **Warmup Epochs** | 2 | **1** | å¿«é€Ÿé€²å…¥ç©©å®šè¨“ç·´ |

### 16.5 ç”Ÿæˆ 5-Fold Split

```python
#!/usr/bin/env python3
# scripts/create_kfold_split.py

import json
import numpy as np
from pathlib import Path
from sklearn.model_selection import KFold

DATA_ROOT = Path("./data/coco")
KARPATHY_PATH = DATA_ROOT / "karpathy_split.json"
OUTPUT_PATH = DATA_ROOT / "5fold_split.json"

def create_folds():
    with open(KARPATHY_PATH) as f:
        data = json.load(f)
    
    dev_pool = []
    test_pool = []
    
    for img in data['images']:
        filename = img['filename']
        img_id = int(filename.split("_")[-1].split(".")[0])
        split_type = img.get('split', 'unknown')
        
        if split_type == 'test':
            test_pool.append(img_id)
        elif split_type in ['train', 'val']:
            dev_pool.append(img_id)
    
    # 5-Fold åˆ‡åˆ†
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    dev_pool_np = np.array(dev_pool)
    
    folds_data = {}
    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(dev_pool_np)):
        folds_data[f"fold_{fold_idx}"] = {
            "train": dev_pool_np[train_idx].tolist(),
            "val": dev_pool_np[val_idx].tolist()
        }
        print(f" - fold_{fold_idx}: Train={len(train_idx):,}, Val={len(val_idx):,}")
    
    folds_data["test_set"] = {
        "image_ids": test_pool,
        "note": "Hold-out test set, DO NOT USE during training!"
    }
    
    with open(OUTPUT_PATH, 'w') as f:
        json.dump(folds_data, f, indent=2)
    
    print(f"âœ“ å·²å„²å­˜è‡³: {OUTPUT_PATH}")

if __name__ == "__main__":
    create_folds()
```

### 16.6 CV å¯¦é©—é…ç½®

```yaml
# configs/experiments/cv_experiment.yaml

defaults:
  - /hardware/rtx5080_16gb

experiment:
  name: "cv_baseline"
  tags: ["5-fold-cv", "siglip2-base", "hash-64"]
  seed: 42

k_fold:
  enabled: true
  num_folds: 5
  current_fold: 0  # ç”± run_5fold_cv.sh è¦†å¯«

training:
  batch_size: 32
  gradient_accumulation_steps: 2
  num_epochs: 20          # å¾ 30 é™åˆ° 20
  warmup_epochs: 1        # å¾ 2 é™åˆ° 1
  early_stopping_patience: 3  # å¾ 5 é™åˆ° 3

checkpointing:
  save_top_k: 1           # åªå„²å­˜æœ€ä½³
  save_optimizer: false   # ä¸å„²å­˜ optimizerï¼ˆç¯€çœç©ºé–“ï¼‰
```

### 16.7 è‡ªå‹•åŒ–åŸ·è¡Œè…³æœ¬

```bash
#!/bin/bash
# scripts/run_5fold_cv.sh

set -e
EXP_NAME="siglip2_cv_run1"
CONFIG_NAME="cv_experiment"

echo "ğŸš€ é–‹å§‹ 5-Fold Cross-Validation"

# ç¢ºä¿ split å­˜åœ¨
[ ! -f "data/coco/5fold_split.json" ] && python scripts/create_kfold_split.py

START_TIME=$(date +%s)

for i in {0..4}; do
    echo "â–¶ï¸  æ­£åœ¨åŸ·è¡Œ Fold $i / 4"
    
    python scripts/train.py \
        --config-name $CONFIG_NAME \
        experiment.name="${EXP_NAME}_fold${i}" \
        k_fold.enabled=true \
        k_fold.current_fold=$i
    
    echo "âœ… Fold $i å®Œæˆ"
    sleep 10  # é‡‹æ”¾ GPU
done

# èšåˆçµæœ
python scripts/aggregate_cv_results.py --exp_prefix "${EXP_NAME}_fold"

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
echo "âœ… 5-Fold CV å®Œæˆï¼ç¸½è€—æ™‚: $((DURATION/3600))h $((DURATION%3600/60))m"
```

### 16.8 çµæœèšåˆ

```python
#!/usr/bin/env python3
# scripts/aggregate_cv_results.py
# èšåˆ 5-Fold CV çµæœï¼Œæ”¯æ´æ‰€æœ‰å¤šæ¨™ç±¤åˆ†é¡è©•ä¼°æŒ‡æ¨™

import argparse
import glob
import torch
import numpy as np
from pathlib import Path
import json
import re

# è¿½è¹¤çš„æŒ‡æ¨™
METRICS = {
    "mAP": ("mAP (â†‘)", True),
    "auc_macro": ("AUC-Macro (â†‘)", True),
    "f1_macro": ("F1-Macro (â†‘)", True),
    "precision_macro": ("Precision (â†‘)", True),
    "recall_macro": ("Recall (â†‘)", True),
    "hamming_loss": ("Hamming Loss (â†“)", False),
    "mae": ("MAE (â†“)", False),
}

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--exp_prefix", type=str, required=True)
    parser.add_argument("--results_dir", type=str, default="outputs/checkpoints")
    args = parser.parse_args()
    
    pattern = f"{args.results_dir}/{args.exp_prefix}*/*.pth"
    files = sorted(glob.glob(pattern))
    
    metrics_by_fold = {m: {} for m in METRICS.keys()}
    
    for f in files:
        ckpt = torch.load(f, map_location="cpu", weights_only=False)
        fold_name = Path(f).parent.name
        
        # å–å¾—å®Œæ•´æŒ‡æ¨™ï¼ˆv3.1 æ ¼å¼ï¼‰
        val_metrics = ckpt.get('val_metrics', {'mAP': ckpt.get('val_mAP')})
        
        match = re.search(r'fold(\d+)', fold_name)
        if match and val_metrics.get('mAP'):
            fold_idx = int(match.group(1))
            for m in METRICS.keys():
                if m in val_metrics:
                    metrics_by_fold[m][fold_idx] = val_metrics[m]
            
            print(f" - Fold {fold_idx}: mAP={val_metrics['mAP']:.4f}")
    
    # è¨ˆç®—çµ±è¨ˆé‡
    print("\n" + "=" * 60)
    print("ğŸ† 5-Fold Cross-Validation æœ€çµ‚çµæœ")
    print("=" * 60)
    
    for m_key, (m_name, _) in METRICS.items():
        values = list(metrics_by_fold[m_key].values())
        if values:
            mean, std = np.mean(values), np.std(values, ddof=1)
            print(f"{m_name:<20} {mean:.4f} Â± {std:.4f}")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
```

### 16.9 åŸ·è¡Œæª¢æ ¸é»

```bash
# 1. ç”Ÿæˆ 5-Fold Split
python scripts/create_kfold_split.py

# 2. è©¦è·‘å–®å€‹ Foldï¼ˆ1 epochï¼‰
python scripts/train.py \
    --config-name cv_experiment \
    k_fold.enabled=true \
    k_fold.current_fold=0 \
    training.num_epochs=1

# é©—è­‰è¼¸å‡ºï¼š
# - GPU è¨˜æ†¶é«”: ~10-11 GB âœ“
# - æ¯å€‹ epoch: ~13-15 åˆ†é˜ âœ“
# - Loss æ­£å¸¸ä¸‹é™ âœ“

# 3. ä½¿ç”¨ tmux åŸ·è¡Œå®Œæ•´ 5-Fold
tmux new -s cv_training
chmod +x scripts/run_5fold_cv.sh
./scripts/run_5fold_cv.sh

# åˆ†é›¢: Ctrl+B, D
# é‡é€£: tmux attach -t cv_training
```

### 16.10 é æœŸç”¢å‡º

```plaintext
outputs/checkpoints/
â”œâ”€â”€ siglip2_cv_run1_fold0/
â”‚   â””â”€â”€ best_model_mAP0.7123.pth  (~500 MB)
â”œâ”€â”€ siglip2_cv_run1_fold1/
â”‚   â””â”€â”€ best_model_mAP0.7245.pth
â”œâ”€â”€ siglip2_cv_run1_fold2/
â”‚   â””â”€â”€ best_model_mAP0.7189.pth
â”œâ”€â”€ siglip2_cv_run1_fold3/
â”‚   â””â”€â”€ best_model_mAP0.7098.pth
â”œâ”€â”€ siglip2_cv_run1_fold4/
â”‚   â””â”€â”€ best_model_mAP0.7311.pth
â””â”€â”€ cv_results_summary.json

è«–æ–‡å ±å‘Šæ ¼å¼ï¼š
============================================================
5-Fold Cross-Validation Results
Method: SigLIP2-base + Hash(64) + KNN(20)
Dataset: MS-COCO (Dev Pool: 118,287 images)

Validation Results (5-Fold CV):
  mAP (macro): 0.72 Â± 0.01
  F1 (micro):  0.74 Â± 0.01
  F1 (macro):  0.65 Â± 0.02
============================================================
```

### 16.11 å¸¸è¦‹æ•…éšœæ’é™¤

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
| ------ | ------ | --------- |
| `KeyError: 'fold_0'` | æœªç”Ÿæˆ 5-Fold split | `python scripts/create_kfold_split.py` |
| `FileNotFoundError` | å½±åƒè·¯å¾‘ä¸åŒ¹é… | æª¢æŸ¥ karpathy_split.json ç‰ˆæœ¬ |
| OOM | VRAM ä¸è¶³ | é™ä½ batch_size åˆ° 16ï¼Œæ¢¯åº¦ç´¯ç©æ”¹ç‚º 4 |
| è¨“ç·´é€Ÿåº¦æ…¢ | DataLoader ç“¶é ¸ | å¢åŠ  num_workers åˆ° 20 |

---

## 17. æ¶ˆèå¯¦é©—èˆ‡ Hash+KNN ç­–ç•¥è©•ä¼°

### 17.1 èƒŒæ™¯èˆ‡å‹•æ©Ÿ

åœ¨ v3.4 ä¹‹å‰çš„å¯¦é©—ä¸­ï¼Œæˆ‘å€‘è§€å¯Ÿåˆ° SigLIP2-MLP Baseline (mAP 0.8384) é¡¯è‘—å„ªæ–¼ AGCH æ”¹é€²ç‰ˆ (mAP 0.6787)ã€‚é€™è¡¨æ˜ AGCH æ¶æ§‹ä¸­çš„æŸäº›çµ„ä»¶ï¼ˆDirection/Magnitude åˆ†è§£ã€Hadamard èåˆã€Hash å±¤ã€KNN æ¨è«–ï¼‰å¯èƒ½ä¸åƒ…æœªèƒ½æå‡æ•ˆèƒ½ï¼Œåè€Œé€ æˆäº†è³‡è¨Šæå¤±ã€‚

ç‚ºäº†é‡æ¸…å„çµ„ä»¶çš„è²¢ç»ä¸¦æ±ºå®šæ˜¯å¦ç¹¼çºŒæ¡ç”¨æœ¬ç­–ç•¥ï¼Œæˆ‘å€‘è¨­è¨ˆäº†ä¸€ç³»åˆ—ç³»çµ±åŒ–çš„æ¶ˆèå¯¦é©—ã€‚

### 17.2 æ¶ˆèå¯¦é©—è¨­è¨ˆ

#### 17.2.1 AB-1: ç„¡ Hash å±¤æ•ˆèƒ½è©•ä¼°

- **ç›®æ¨™**: è©•ä¼°å°‡é«˜ç¶­ç‰¹å¾µå£“ç¸®è‡³ binary hash codes æ‰€é€ æˆçš„æ•ˆèƒ½æå¤±ã€‚
- **è¨­å®š**: ç§»é™¤ Hash Layerï¼Œç›´æ¥ä½¿ç”¨ Fusion å±¤è¼¸å‡ºçš„é«˜ç¶­æµ®é»æ•¸å‘é‡é€²è¡Œåˆ†é¡ã€‚
- **é…ç½®**: `configs/experiments/ablation_no_hash.yaml`
- **é—œéµåƒæ•¸**: `model.hash.skip_hash=true`

#### 17.2.2 AB-2: ç„¡åˆ†è§£ (Decomposition) è©•ä¼°

- **ç›®æ¨™**: è©•ä¼°å°‡ Embedding åˆ†è§£ç‚ºæ–¹å‘èˆ‡å¹…åº¦çš„ç­–ç•¥æ˜¯å¦æœ‰æ•ˆã€‚
- **è¨­å®š**: ç§»é™¤ DirectionMagnitudeDecomposerï¼Œç›´æ¥å°‡ SigLIP2 çš„åŸå§‹ Embedding æ‹¼æ¥é€å…¥åˆ†é¡å™¨ã€‚
- **é æœŸ**: è‹¥æ•ˆèƒ½æå‡ï¼Œè¡¨ç¤ºåˆ†è§£éç¨‹ç ´å£äº†åŸå§‹èªç¾©ç©ºé–“çš„å®Œæ•´æ€§ã€‚

#### 17.2.3 AB-3: åƒ… BCE Loss è©•ä¼°

- **ç›®æ¨™**: æ¸¬è©¦é¡å¤–çš„ Cosine Alignment Loss èˆ‡ Hash Regularization Loss æ˜¯å¦å¹²æ“¾äº†ä¸»ä»»å‹™å­¸ç¿’ã€‚
- **è¨­å®š**: å°‡ `cosine_weight` èˆ‡ `hash_weight` è¨­ç‚º 0ï¼Œåƒ…ä¿ç•™ Binary Cross-Entropy Lossã€‚
- **é…ç½®**: `configs/experiments/ablation_bce_only.yaml`

#### 17.2.4 AB-4: Hash Bits é•·åº¦è©•ä¼°

- **ç›®æ¨™**: å°‹æ‰¾è³‡è¨Šå£“ç¸®èˆ‡æª¢ç´¢æ•ˆç‡çš„æœ€ä½³å¹³è¡¡é»ã€‚
- **è®Šé«”**: 32 bits, 64 bits (Baseline), 128 bits, 256 bitsã€‚
- **åˆ†æ**: éš¨è‘— bits å¢åŠ ï¼ŒmAP æ‡‰ä¸Šå‡ï¼Œä½†æª¢ç´¢é€Ÿåº¦ä¸‹é™ä¸”å„²å­˜ç©ºé–“å¢åŠ ã€‚

### 17.3 åŸ·è¡ŒæŒ‡å—

ä½¿ç”¨è‡ªå‹•åŒ–è…³æœ¬æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰æ¶ˆèå¯¦é©—ï¼š

```bash
# åŸ·è¡Œæ‰€æœ‰æ¶ˆèå¯¦é©— (AB-1, AB-3, AB-4)
./scripts/run_ablation.sh
```

æˆ–å–®ç¨åŸ·è¡Œç‰¹å®šå¯¦é©—ï¼š

```bash
# åŸ·è¡Œ AB-1 (ç„¡ Hash)
python scripts/train.py --config-name experiments/ablation_no_hash

# åŸ·è¡Œ AB-3 (åƒ… BCE)
python scripts/train.py --config-name experiments/ablation_bce_only
```

### 17.4 é æœŸæ±ºç­–è·¯å¾‘

å¯¦é©—çµæœå°‡æ±ºå®šå¾ŒçºŒå„ªåŒ–æ–¹å‘ï¼š

| è§€å¯Ÿçµæœ | æ½›åœ¨å«ç¾© | å»ºè­°è¡Œå‹• |
| :--- | :--- | :--- |
| **ç§»é™¤ Hash å±¤å¾Œ mAP å¤§å¹…å›å‡** | Hash å£“ç¸®é€ æˆä¸»è¦ç“¶é ¸ | æ”¾æ£„ Hash+KNNï¼Œæ”¹ç”¨ç´”å‘é‡æª¢ç´¢æˆ–å‚³çµ±åˆ†é¡ |
| **ç§»é™¤åˆ†è§£å¾Œæ•ˆèƒ½æå‡** | åˆ†è§£ç­–ç•¥ä¸é©åˆ SigLIP2 | å›æ­¸æ¨™æº– Embedding æ‹¼æ¥ç­–ç•¥ |
| **åƒ…ç”¨ BCE æ•ˆæœæœ€ä½³** | å¤šå·¥ Loss å°è‡´å„ªåŒ–è¡çª | ç°¡åŒ– Loss Functionï¼Œå°ˆæ³¨æ–¼åˆ†é¡æº–ç¢ºåº¦ |
| **å¢åŠ  Bits é¡¯è‘—æå‡ mAP** | ç›®å‰ 64 bits å®¹é‡ä¸è¶³ | å¢åŠ  Hash Bits è‡³ 128 æˆ– 256 |
