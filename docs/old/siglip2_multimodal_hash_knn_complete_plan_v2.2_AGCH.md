# å¤šæ¨¡æ…‹åœ–æ–‡å¤šæ¨™ç±¤åˆ†é¡å®Œæ•´å¯¦é©—è¨ˆç•«

# SigLIP 2 + æ–¹å‘/å¹…åº¦åˆ†è§£ + Hadamard èåˆ + Hash + KNN

> **ç‰ˆæœ¬**: v2.2 (AGCH-Improvement å°ˆæ¡ˆå„ªåŒ–ç‰ˆ)  
> **æ—¥æœŸ**: 2026-01-30  
> **å°ˆæ¡ˆ**: AGCH-Improvement  
> **ç¡¬é«”**: RTX 5080 16GB | 32-core CPU | 42GB RAM | **CUDA 12.4**  
> **ç’°å¢ƒ**: Python 3.11+ | PyTorch 2.6.0+cu124 | uv å¥—ä»¶ç®¡ç†  
> **ç›®æ¨™**: åœ¨ MS-COCO è³‡æ–™é›†ä¸Šå¯¦ç¾é«˜æ•ˆèƒ½çš„åœ–æ–‡å¤šæ¨™ç±¤åˆ†é¡ç³»çµ±

---

## ğŸ“‹ æ›´æ–°æ—¥èªŒ (v2.2)

### åŸºæ–¼å¯¦éš›å°ˆæ¡ˆæ¶æ§‹çš„èª¿æ•´

- âœ… **CUDA ç‰ˆæœ¬ä¿®æ­£**: 13.0 â†’ **12.4**ï¼ˆå°æ‡‰ä½ çš„ç³»çµ±ï¼‰
- âœ… **PyTorch é…ç½®**: å·²è¨­å®š pytorch-cu124 index
- âœ… **å°ˆæ¡ˆçµæ§‹æ•´åˆ**: å®Œå…¨å°æ‡‰ `AGCH-Improvement` å°ˆæ¡ˆ
- âœ… **è…³æœ¬å°é½Š**: æ‰€æœ‰ç¨‹å¼ç¢¼åŒ¹é…ä½ ç¾æœ‰çš„ scripts/
- âœ… **FAISS å‡ç´šæŒ‡å¼•**: faiss-cpu â†’ faiss-gpu
- âœ… **è³‡æ–™é›†è·¯å¾‘**: å°æ‡‰ä½ çš„ `data/coco/` çµæ§‹
- âœ… **Python ç‰ˆæœ¬**: 3.11+ (ç¬¦åˆ pyproject.toml)

### é‡å° RTX 5080 16GB çš„æ ¸å¿ƒå„ªåŒ–ï¼ˆç¶­æŒï¼‰

- âœ… Batch size: 64 â†’ **32**
- âœ… æ··åˆç²¾åº¦: **å¿…é ˆå•Ÿç”¨**
- âœ… æ¢¯åº¦ç´¯ç©: **2 æ­¥**
- âœ… è¨˜æ†¶é«”ç›£æ§: å¯¦æ™‚è¿½è¹¤
- âœ… DataLoader: åˆ©ç”¨ 32 æ ¸å¿ƒï¼ˆnum_workers=16ï¼‰

---

## ç›®éŒ„

1. [å°ˆæ¡ˆçµæ§‹](#1-å°ˆæ¡ˆçµæ§‹)
2. [ç’°å¢ƒé…ç½®](#2-ç’°å¢ƒé…ç½®)
3. [å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³](#3-å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³)
4. [è³‡æ–™é›†å”è­°](#4-è³‡æ–™é›†å”è­°)
5. [æ¨¡å‹æ¶æ§‹](#5-æ¨¡å‹æ¶æ§‹)
6. [ç†è«–åŸºç¤èˆ‡æ•¸å­¸å…¬å¼](#6-ç†è«–åŸºç¤èˆ‡æ•¸å­¸å…¬å¼)
7. [æå¤±å‡½æ•¸è¨­è¨ˆ](#7-æå¤±å‡½æ•¸è¨­è¨ˆ)
8. [æ¨è«–ç­–ç•¥](#8-æ¨è«–ç­–ç•¥)
9. [å¯¦é©—è¨­è¨ˆ](#9-å¯¦é©—è¨­è¨ˆ)
10. [è¶…åƒæ•¸é…ç½®](#10-è¶…åƒæ•¸é…ç½®)
11. [å¯¦ä½œç´°ç¯€](#11-å¯¦ä½œç´°ç¯€)
12. [è©•ä¼°æŒ‡æ¨™](#12-è©•ä¼°æŒ‡æ¨™)
13. [ç¡¬é«”ç‰¹å®šå„ªåŒ–](#13-ç¡¬é«”ç‰¹å®šå„ªåŒ–)
14. [åƒè€ƒæ–‡ç»](#14-åƒè€ƒæ–‡ç»)
15. [é™„éŒ„](#15-é™„éŒ„)

---

## 1) å°ˆæ¡ˆçµæ§‹

### 1.1 ç›®å‰çš„ç›®éŒ„æ¨¹

```
AGCH-Improvement/
â”œâ”€â”€ configs/                    # é…ç½®æª”æ¡ˆç›®éŒ„
â”‚   â”œâ”€â”€ experiments/           # å¯¦é©—é…ç½®ï¼ˆå¾…å»ºç«‹ï¼‰
â”‚   â””â”€â”€ hardware/              # ç¡¬é«”é…ç½®ï¼ˆå¾…å»ºç«‹ï¼‰
â”‚
â”œâ”€â”€ data/                      # è³‡æ–™é›†ç›®éŒ„
â”‚   â””â”€â”€ coco/                  # âœ… å·²ä¸‹è¼‰
â”‚       â”œâ”€â”€ annotations/       # COCO æ¨™è¨»
â”‚       â”‚   â”œâ”€â”€ captions_train2014.json
â”‚       â”‚   â”œâ”€â”€ captions_val2014.json
â”‚       â”‚   â”œâ”€â”€ instances_train2014.json
â”‚       â”‚   â”œâ”€â”€ instances_val2014.json
â”‚       â”‚   â”œâ”€â”€ person_keypoints_train2014.json
â”‚       â”‚   â””â”€â”€ person_keypoints_val2014.json
â”‚       â”œâ”€â”€ images/            # COCO å½±åƒ
â”‚       â”‚   â”œâ”€â”€ train2014/     # 82,783 å¼µè¨“ç·´å½±åƒ
â”‚       â”‚   â””â”€â”€ val2014/       # 40,504 å¼µé©—è­‰å½±åƒ
â”‚       â”œâ”€â”€ index_train2014.pkl  # å¾…å»ºç«‹ï¼ˆä½¿ç”¨ scripts/create_dataset_index.pyï¼‰
â”‚       â”œâ”€â”€ index_val2014.pkl    # å¾…å»ºç«‹
â”‚       â””â”€â”€ karpathy_split.json  # å¾…ä¸‹è¼‰ï¼ˆä½¿ç”¨ scripts/download_karpathy_split.pyï¼‰
â”‚
â”œâ”€â”€ experiments/               # å¯¦é©—çµæœèˆ‡æ—¥èªŒï¼ˆå¾…ä½¿ç”¨ï¼‰
â”‚   â”œâ”€â”€ baseline_rtx5080/     # å¯¦é©—è¼¸å‡ºç›®éŒ„
â”‚   â”œâ”€â”€ tensorboard/          # TensorBoard æ—¥èªŒ
â”‚   â””â”€â”€ wandb/                # W&B æ—¥èªŒ
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooksï¼ˆæ¢ç´¢æ€§åˆ†æï¼‰
â”‚
â”œâ”€â”€ outputs/                  # æ¨¡å‹è¼¸å‡º
â”‚   â””â”€â”€ checkpoints/          # è¨“ç·´æª¢æŸ¥é»
â”‚
â”œâ”€â”€ scripts/                  # âœ… å·²å»ºç«‹çš„è…³æœ¬
â”‚   â”œâ”€â”€ analyze_dataset.py        # è³‡æ–™é›†çµ±è¨ˆåˆ†æ
â”‚   â”œâ”€â”€ create_dataset_index.py   # å»ºç«‹å¿«é€Ÿç´¢å¼•
â”‚   â”œâ”€â”€ download_coco.sh          # COCO ä¸‹è¼‰è…³æœ¬
â”‚   â”œâ”€â”€ download_karpathy_split.py # Karpathy split ä¸‹è¼‰
â”‚   â”œâ”€â”€ test_siglip2.py           # SigLIP2 æ¸¬è©¦
â”‚   â”œâ”€â”€ verify_setup.py           # ç’°å¢ƒé©—è­‰
â”‚   â”œâ”€â”€ train.py                  # å¾…å»ºç«‹ï¼šä¸»è¨“ç·´è…³æœ¬
â”‚   â”œâ”€â”€ evaluate.py               # å¾…å»ºç«‹ï¼šè©•ä¼°è…³æœ¬
â”‚   â””â”€â”€ build_knn_index.py        # å¾…å»ºç«‹ï¼šå»ºç«‹ KNN ç´¢å¼•
â”‚
â”œâ”€â”€ src/                      # ä¸»è¦åŸå§‹ç¢¼
â”‚   â””â”€â”€ siglip2_multimodal_hash/
â”‚       â”œâ”€â”€ __init__.py       # âœ… å·²å»ºç«‹
â”‚       â”œâ”€â”€ model.py          # å¾…å»ºç«‹ï¼šæ¨¡å‹å®šç¾©
â”‚       â”œâ”€â”€ dataset.py        # å¾…å»ºç«‹ï¼šè³‡æ–™è¼‰å…¥å™¨
â”‚       â”œâ”€â”€ losses.py         # å¾…å»ºç«‹ï¼šæå¤±å‡½æ•¸
â”‚       â”œâ”€â”€ utils.py          # å¾…å»ºç«‹ï¼šå·¥å…·å‡½æ•¸
â”‚       â””â”€â”€ knn.py            # å¾…å»ºç«‹ï¼šKNN æª¢ç´¢
â”‚
â”œâ”€â”€ tests/                    # å–®å…ƒæ¸¬è©¦ï¼ˆå¾…å»ºç«‹ï¼‰
â”‚
â”œâ”€â”€ .gitignore               # âœ… å·²è¨­å®š
â”œâ”€â”€ README.md                # âœ… å·²å»ºç«‹
â”œâ”€â”€ pyproject.toml           # âœ… å·²è¨­å®šï¼ˆå« CUDA 12.4 é…ç½®ï¼‰
â”œâ”€â”€ requirements.txt         # âœ… å·²ç”Ÿæˆï¼ˆuv pip freezeï¼‰
â””â”€â”€ uv.lock                  # âœ… uv ä¾è³´é–å®šæª”æ¡ˆ
```

### 1.2 å¾…å»ºç«‹çš„æª”æ¡ˆæ¸…å–®

#### é…ç½®æª”æ¡ˆ

```bash
# å»ºç«‹é…ç½®ç›®éŒ„çµæ§‹
mkdir -p configs/{experiments,hardware}

# æ ¸å¿ƒé…ç½®æª”æ¡ˆï¼ˆä¸‹æ–‡æœƒæä¾›å…§å®¹ï¼‰
configs/hardware/rtx5080_16gb.yaml          # RTX 5080 ç¡¬é«”é…ç½®
configs/experiments/baseline.yaml           # Baseline å¯¦é©—é…ç½®
configs/experiments/ablation_fusion.yaml    # Fusion ç­–ç•¥ ablation
configs/experiments/ablation_hash.yaml      # Hash bits ablation
```

#### åŸå§‹ç¢¼

```bash
# æ ¸å¿ƒæ¨¡å‹æª”æ¡ˆï¼ˆä¸‹æ–‡æœƒæä¾›å®Œæ•´å¯¦ä½œï¼‰
src/siglip2_multimodal_hash/model.py        # æ¨¡å‹å®šç¾©
src/siglip2_multimodal_hash/dataset.py      # è³‡æ–™è¼‰å…¥å™¨
src/siglip2_multimodal_hash/losses.py       # æå¤±å‡½æ•¸
src/siglip2_multimodal_hash/utils.py        # å·¥å…·å‡½æ•¸
src/siglip2_multimodal_hash/knn.py          # KNN æª¢ç´¢
```

#### è¨“ç·´èˆ‡è©•ä¼°è…³æœ¬

```bash
# ä¸»è¦è…³æœ¬ï¼ˆä¸‹æ–‡æœƒæä¾›å®Œæ•´å¯¦ä½œï¼‰
scripts/train.py                            # è¨“ç·´è…³æœ¬
scripts/evaluate.py                         # è©•ä¼°è…³æœ¬
scripts/build_knn_index.py                  # å»ºç«‹ KNN ç´¢å¼•
scripts/monitor_training.sh                 # GPU ç›£æ§è…³æœ¬
```

---

## 2) ç’°å¢ƒé…ç½®

### 2.1 ç•¶å‰ç’°å¢ƒç‹€æ…‹

```bash
# æª¢æŸ¥ç•¶å‰ç’°å¢ƒ
python --version
# Python 3.12.8 (ä½ çš„ requirements.txt é¡¯ç¤º)

torch --version
# 2.6.0+cu124 (âœ… æ­£ç¢ºçš„ CUDA 12.4 ç‰ˆæœ¬)

nvidia-smi
# Driver: 580.126.09, CUDA: 13.0 (runtime æ”¯æ´ 12.4)
```

### 2.2 pyproject.toml é…ç½®æª¢æŸ¥

ä½ çš„ `pyproject.toml` å·²æ­£ç¢ºé…ç½®ï¼š

```toml
# âœ… æ­£ç¢ºï¼šCUDA 12.4 ç‰ˆæœ¬
[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu124", marker = "sys_platform == 'linux'" },
]
torchvision = [
  { index = "pytorch-cu124", marker = "sys_platform == 'linux'" },
]
```

### 2.3 å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬

ä½ ç•¶å‰ä½¿ç”¨ `faiss-cpu`ï¼Œéœ€è¦å‡ç´šåˆ° GPU ç‰ˆæœ¬ï¼š

```bash
# æ–¹æ³• 1: ä½¿ç”¨ condaï¼ˆæ¨è–¦ï¼‰
conda install -c pytorch -c nvidia faiss-gpu

# æ–¹æ³• 2: å¾æºç¢¼ç·¨è­¯ï¼ˆå¦‚æœ conda å¤±æ•—ï¼‰
# è¦‹ä¸‹æ–‡ 2.4 ç¯€

# é©—è­‰
python -c "import faiss; print(f'FAISS version: {faiss.__version__}')"
python -c "import faiss; print(f'GPU support: {hasattr(faiss, \"index_gpu_to_cpu\")}')"
```

### 2.4 FAISS-GPU å¾æºç¢¼ç·¨è­¯ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰

```bash
# å®‰è£ä¾è³´
sudo apt-get update
sudo apt-get install cmake libopenblas-dev

# ä¸‹è¼‰ FAISS
cd ~/Downloads
git clone https://github.com/facebookresearch/faiss.git
cd faiss

# é…ç½®ï¼ˆé‡å° RTX 5080 Ada Lovelaceï¼Œcompute capability 8.9ï¼‰
cmake -B build \
  -DFAISS_ENABLE_GPU=ON \
  -DFAISS_ENABLE_PYTHON=ON \
  -DCMAKE_BUILD_TYPE=Release \
  -DCMAKE_CUDA_ARCHITECTURES=89 \
  -DCMAKE_CUDA_COMPILER=/usr/local/cuda-12.4/bin/nvcc \
  .

# ç·¨è­¯ï¼ˆåˆ©ç”¨ 32 æ ¸å¿ƒï¼‰
make -C build -j32

# å®‰è£
cd build/faiss/python
pip install .

# é©—è­‰
python -c "import faiss; print('FAISS-GPU installed successfully')"
```

### 2.5 ç’°å¢ƒé©—è­‰

```bash
# åŸ·è¡Œä½ å·²æœ‰çš„é©—è­‰è…³æœ¬
cd ~/Documents/Coding/github.com/natsuki221/AGCH-Improvement
python scripts/verify_setup.py
```

**é æœŸè¼¸å‡º**:

```
============================================================
ç’°å¢ƒé©—è­‰
============================================================

[1/5] æª¢æŸ¥ Python ç‰ˆæœ¬...
âœ“ Python 3.12.8

[2/5] æª¢æŸ¥ CUDA...
âœ“ CUDA 12.4
  GPU: NVIDIA GeForce RTX 5080
  VRAM: 16.3 GB

[3/5] æª¢æŸ¥ Python å¥—ä»¶...
âœ“ torch                2.6.0+cu124
âœ“ transformers         5.0.0
âœ“ faiss                1.13.2  # âš ï¸ éœ€ç¢ºèªæ˜¯å¦ç‚º GPU ç‰ˆæœ¬
âœ“ pycocotools          2.0.11

[4/5] æª¢æŸ¥è³‡æ–™é›†...
âœ“ ./data/coco/images/train2014 (82,783 å¼µå½±åƒ)
âœ“ ./data/coco/images/val2014 (40,504 å¼µå½±åƒ)
âœ“ ./data/coco/annotations/instances_train2014.json (145.6 MB)
âœ“ ./data/coco/annotations/captions_train2014.json (78.2 MB)
âœ— ./data/coco/index_train2014.pkl ä¸å­˜åœ¨  # âš ï¸ éœ€å»ºç«‹

[5/5] æª¢æŸ¥ SigLIP2 æ¨¡å‹...
æ­£åœ¨æ¸¬è©¦ SigLIP2 æ¨¡å‹è¼‰å…¥...
âœ“ SigLIP2 æ¨¡å‹è¼‰å…¥æˆåŠŸ
  åƒæ•¸é‡: 87.1M

============================================================
âš ï¸  éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œè«‹ä¿®æ­£å¾Œå†è©¦ã€‚
============================================================
```

### 2.6 å»ºç«‹è³‡æ–™é›†ç´¢å¼•

```bash
# åŸ·è¡Œä½ å·²æœ‰çš„ç´¢å¼•å»ºç«‹è…³æœ¬
python scripts/create_dataset_index.py

# é æœŸè¼¸å‡ºï¼š
# æ­£åœ¨è™•ç† train2014...
# Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82783/82783 [01:23<00:00, 991.32it/s]
# âœ“ ç´¢å¼•å·²å„²å­˜: data/coco/index_train2014.pkl
#   - å½±åƒæ•¸é‡: 82,783
#   - é¡åˆ¥æ•¸é‡: 80
# 
# æ­£åœ¨è™•ç† val2014...
# Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40504/40504 [00:41<00:00, 978.15it/s]
# âœ“ ç´¢å¼•å·²å„²å­˜: data/coco/index_val2014.pkl
#   - å½±åƒæ•¸é‡: 40,504
#   - é¡åˆ¥æ•¸é‡: 80
# 
# âœ“ æ‰€æœ‰ç´¢å¼•å»ºç«‹å®Œæˆï¼

# ä¸‹è¼‰ Karpathy split
python scripts/download_karpathy_split.py
```

---

## 3) å•é¡Œå®šç¾©èˆ‡æ ¸å¿ƒæ€æƒ³

### 3.1 ä»»å‹™å®šç¾©

- **è¼¸å…¥**: åœ–ç‰‡ `image` + å°æ‡‰æ–‡å­—æ•˜è¿° `caption`
- **è¼¸å‡º**: `C` å€‹ tags çš„ multi-hot å‘é‡ $y \in \{0,1\}^C$
- **è³‡æ–™é›†**: MS-COCO (80 å€‹ç‰©ä»¶é¡åˆ¥)

### 3.2 æ ¸å¿ƒå‰µæ–°é»

æœ¬ç ”ç©¶æå‡ºä¸€å€‹çµåˆç›£ç£å¼å­¸ç¿’èˆ‡è¿‘é„°æª¢ç´¢çš„æ··åˆæ¶æ§‹ï¼š

1. **æ–¹å‘/å¹…åº¦åˆ†è§£ (æ–¹æ¡ˆ B)**
   - å°‡ embedding åˆ†è§£ç‚ºã€Œæ–¹å‘ã€ï¼ˆèªæ„ï¼‰èˆ‡ã€Œå¹…åº¦ã€ï¼ˆç½®ä¿¡åº¦ï¼‰
   - ç†è«–å‹•æ©Ÿï¼šä¿ç•™å‘é‡çš„å¼·åº¦è³‡è¨Šï¼Œé¿å… L2 æ­£è¦åŒ–éæ—©æ¶ˆé™¤ç½®ä¿¡åº¦è¨Šè™Ÿ

2. **Hadamard ä¹˜ç©èåˆ**
   - æ•æ‰è·¨æ¨¡æ…‹çš„ dimension-wise å…±ç¾æ¨¡å¼ (co-activation pattern)
   - åƒè€ƒ VQA é ˜åŸŸçš„ MCB/MUTAN æ–¹æ³•

3. **å¯å­¸ç¿’ Hash å±¤**
   - åˆ©æ–¼é«˜æ•ˆè¿‘é„°æª¢ç´¢ (Hamming space)
   - æ”¯æ´å¤§è¦æ¨¡è³‡æ–™åº«çš„å¿«é€Ÿæª¢ç´¢

4. **KNN åŠ æ¬ŠæŠ•ç¥¨**
   - çµåˆç›£ç£å¼èˆ‡éåƒæ•¸å¼åˆ†é¡çš„å„ªå‹¢
   - æä¾›å¯è§£é‡‹æ€§ï¼ˆå¯è¦–è¦ºåŒ–é„°å±…æ¨£æœ¬ï¼‰

---

## 4) è³‡æ–™é›†å”è­°

### 4.1 MS-COCO åŸºæœ¬è³‡è¨Šï¼ˆä½ å·²ä¸‹è¼‰ï¼‰

- **ç‰ˆæœ¬**: COCO 2014 (train2014 + val2014) âœ…
- **å½±åƒæ•¸é‡**:
  - è¨“ç·´é›†: 82,783 å¼µ âœ…
  - é©—è­‰é›†: 40,504 å¼µ âœ…
- **ç‰©ä»¶é¡åˆ¥**: 80 å€‹ (detection annotations) âœ…
- **Captions**: æ¯å¼µåœ–ç‰‡æœ‰ 5 å€‹äººå·¥æ¨™è¨»çš„ captions âœ…

### 4.2 å¯¦é©—åˆ‡åˆ†å”è­°

æ¡ç”¨ **Karpathy split**ï¼ˆå½±åƒæª¢ç´¢èˆ‡ captioning ç¤¾ç¾¤æ¨™æº–ï¼‰ï¼š

| Split | å½±åƒæ•¸é‡ | ç”¨é€” | ç‹€æ…‹ |
| ------- | --------- | ------ | ------ |
| Train | 113,287 | æ¨¡å‹è¨“ç·´ | âš ï¸ å¾…ä¸‹è¼‰ karpathy_split.json |
| Val | 5,000 | è¶…åƒæ•¸èª¿æ•´ã€early stopping | åŒä¸Š |
| Test | 5,000 | æœ€çµ‚è©•ä¼° | åŒä¸Š |

**ä¸‹è¼‰ Karpathy split**:

```bash
python scripts/download_karpathy_split.py
```

### 4.3 è³‡æ–™é›†è·¯å¾‘å°æ‡‰

```python
# åœ¨ä½ çš„å°ˆæ¡ˆä¸­ä½¿ç”¨ä»¥ä¸‹è·¯å¾‘
DATA_ROOT = Path("./data/coco")  # å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ data/coco/

# å½±åƒè·¯å¾‘
TRAIN_IMG_DIR = DATA_ROOT / "images/train2014"
VAL_IMG_DIR = DATA_ROOT / "images/val2014"

# æ¨™è¨»è·¯å¾‘
TRAIN_ANNO = DATA_ROOT / "annotations/instances_train2014.json"
TRAIN_CAP = DATA_ROOT / "annotations/captions_train2014.json"

# ç´¢å¼•è·¯å¾‘
TRAIN_INDEX = DATA_ROOT / "index_train2014.pkl"
VAL_INDEX = DATA_ROOT / "index_val2014.pkl"

# Karpathy split
KARPATHY_SPLIT = DATA_ROOT / "karpathy_split.json"
```

---

## 5) æ¨¡å‹æ¶æ§‹

### 5.1 ç¸½é«”æå¤±å‡½æ•¸

$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{bce}} + \alpha \mathcal{L}_{\text{cos}} + \gamma \mathcal{L}_{\text{hash}}
$$

**æ³¨æ„**: ç§»é™¤ Euclidean lossï¼ˆå› å…¶èˆ‡ cosine é«˜åº¦è€¦åˆï¼‰

### 5.2 Binary Cross-Entropy Loss (ä¸»è¦ç›£ç£è¨Šè™Ÿ)

$$
\mathcal{L}_{\text{bce}} = -\frac{1}{C} \sum_{c=1}^C \left[ y_c \log \hat{y}_c + (1-y_c) \log(1-\hat{y}_c) \right]
$$

å…¶ä¸­ï¼š
$$
\hat{y}_c = \sigma(\text{logit}_c), \quad \text{logit}_c = (W_{\text{cls}} h + b_{\text{cls}})_c
$$

**é¡åˆ¥ä¸å¹³è¡¡è™•ç†**:

- è€ƒæ…®ä½¿ç”¨ **Focal Loss** æˆ– **class-balanced weights**
- COCO 80 é¡åˆ¥åˆ†å¸ƒä¸å‡ï¼ˆperson å‡ºç¾é »ç‡é é«˜æ–¼ toothbrushï¼‰

### 5.3 Cosine Alignment Loss

$$
\mathcal{L}_{\text{cos}} = 1 - \cos(d_{img}, d_{txt}) = 1 - \frac{d_{img}^\top d_{txt}}{\|d_{img}\|_2 \|d_{txt}\|_2}
$$

ç”±æ–¼ $d$ å·²æ˜¯ unit vectorï¼š
$$
\mathcal{L}_{\text{cos}} = 1 - d_{img}^\top d_{txt}
$$

**ç‰©ç†æ„ç¾©**: é¼“å‹µé…å°çš„åœ–æ–‡åœ¨æ–¹å‘ç©ºé–“ä¸­å°é½Š

### 5.4 Hash Regularization (ä¸‰é …çµ„åˆ)

#### 5.4.1 Quantization Loss (æ¨å‘ Â±1)

$$
\mathcal{L}_{\text{quant}} = \frac{1}{B} \sum_{i=1}^B (|h_i| - 1)^2
$$

#### 5.4.2 Bit Balance Loss (é¿å…æ‰€æœ‰ bit åå‘åŒä¸€æ¥µ)

$$
\mathcal{L}_{\text{balance}} = \frac{1}{B} \sum_{i=1}^B \left( \frac{1}{N} \sum_{n=1}^N h_{n,i} \right)^2
$$

å…¶ä¸­ $N$ æ˜¯ batch sizeï¼Œ$h_{n,i}$ æ˜¯ç¬¬ $n$ å€‹æ¨£æœ¬çš„ç¬¬ $i$ å€‹ bitã€‚

**ç‰©ç†æ„ç¾©**: å¸Œæœ›æ¯å€‹ bit åœ¨ batch ä¸­çš„å‡å€¼æ¥è¿‘ 0ï¼ˆä¸€åŠ +1ï¼Œä¸€åŠ -1ï¼‰

#### 5.4.3 Bit Decorrelation Loss (é¼“å‹µ bit ç¨ç«‹)

$$
\mathcal{L}_{\text{decorr}} = \frac{1}{B^2} \sum_{i \neq j} (\text{Cov}(h_i, h_j))^2
$$

ç°¡åŒ–å¯¦ä½œï¼ˆä½¿ç”¨ Frobenius normï¼‰:
$$
\mathcal{L}_{\text{decorr}} = \|\text{Cov}(H)\|_F^2 - \text{trace}(\text{Cov}(H)^2)
$$

**ç¸½ hash loss**:
$$
\mathcal{L}_{\text{hash}} = \mathcal{L}_{\text{quant}} + \lambda_1 \mathcal{L}_{\text{balance}} + \lambda_2 \mathcal{L}_{\text{decorr}}
$$

---

## 6) æ¨è«–ç­–ç•¥

### 6.1 å»ºç«‹ Hash Index

```python
import faiss
import numpy as np

# 1. æå–è¨“ç·´é›†çš„ hash codes
train_hashes = []  # List of np.ndarray, shape (B,)
train_labels = []  # List of np.ndarray, shape (C,)

for batch in train_loader:
    with torch.no_grad():
        h = model.get_hash(batch)  # shape: (batch_size, B)
        train_hashes.append(h.cpu().numpy())
        train_labels.append(batch['labels'].cpu().numpy())

train_hashes = np.vstack(train_hashes)  # (N_train, B)
train_labels = np.vstack(train_labels)  # (N_train, C)

# 2. äºŒå€¼åŒ–ï¼ˆhard binaryï¼‰
train_binary = (train_hashes > 0).astype(np.uint8)  # {0, 1}^B

# 3. å»ºç«‹ FAISS binary index
index = faiss.IndexBinaryFlat(B)  # Hamming distance index
index.add(train_binary)
```

### 6.2 KNN æª¢ç´¢èˆ‡æŠ•ç¥¨

```python
def predict_tags(query_hash, index, train_labels, K=20, tau=0.07, top_n=5):
    """
    Args:
        query_hash: (B,) torch.Tensor or np.ndarray
        index: faiss.IndexBinaryFlat
        train_labels: (N_train, C) np.ndarray
        K: number of neighbors
        tau: temperature for softmax
        top_n: number of tags to return
    
    Returns:
        predicted_tags: (top_n,) np.ndarray (tag indices)
        scores: (top_n,) np.ndarray (confidence scores)
    """
    # 1. äºŒå€¼åŒ– query
    query_binary = (query_hash > 0).astype(np.uint8).reshape(1, -1)
    
    # 2. KNN æœå°‹ï¼ˆè¿”å› Hamming distancesï¼‰
    distances, indices = index.search(query_binary, K)  # (1, K)
    distances = distances[0]  # (K,)
    indices = indices[0]  # (K,)
    
    # 3. è½‰æ›ç‚º similarityï¼ˆHamming -> cosine-likeï¼‰
    similarities = 1 - distances / B  # [0, 1] range
    
    # 4. Softmax weighting
    weights = np.exp(similarities / tau)
    weights = weights / weights.sum()
    
    # 5. åŠ æ¬ŠæŠ•ç¥¨
    neighbor_labels = train_labels[indices]  # (K, C)
    tag_scores = (weights[:, None] * neighbor_labels).sum(axis=0)  # (C,)
    
    # 6. Top-N
    top_indices = np.argsort(tag_scores)[-top_n:][::-1]
    top_scores = tag_scores[top_indices]
    
    return top_indices, top_scores
```

---

## 7) å¯¦é©—è¨­è¨ˆ

### 7.1 Baseline æ–¹æ³•å°æ¯”

| æ–¹æ³• | æè¿° | ç”¨é€” |
| ------ | ------ | ------ |
| **SigLIP2-MLP** | ç›´æ¥ç”¨ MLP åˆ†é¡å™¨ on `[v_img, v_txt]`ï¼ˆç„¡ decomposition, ç„¡ hash, ç„¡ KNNï¼‰ | è­‰æ˜ hash+KNN çš„å¿…è¦æ€§ |
| **SigLIP2-ZeroShot** | è¨ˆç®— image embedding èˆ‡æ¯å€‹ tag prototypeï¼ˆå¾ tag name ç·¨ç¢¼ï¼‰çš„ cosine similarityï¼Œå– Top-N | è­‰æ˜ç›£ç£å¼è¨“ç·´çš„åƒ¹å€¼ |
| **æ–¹æ¡ˆ A (Direction only)** | æ‹¿æ‰ magnitude åˆ†æ”¯ï¼ˆåƒ…ç”¨ `[d_img, d_txt, p_dir]`ï¼‰ | è­‰æ˜æ–¹æ¡ˆ B çš„åƒ¹å€¼ |
| **Ours-Full** | å®Œæ•´æ¶æ§‹ï¼ˆæ–¹æ¡ˆ B + Hadamard + Hash + KNNï¼‰ | ä¸»è¦æ–¹æ³• |

### 7.2 ç³»çµ±åŒ– Ablation Study

#### Tier 1: æ ¸å¿ƒæ¶æ§‹é¸æ“‡ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰

| ID | è®Šé‡ | é¸é … | å›ºå®šåƒæ•¸ |
| ---- | ------ | ------ | ---------- |
| **A1** | Fusion ç­–ç•¥ | concat / +Hadamard / +Hadamard+Magnitude | B=64, K=20, freeze |
| **A2** | Hash bits | ç„¡ hash / 32 / 64 / 128 | å…¶é¤˜åŒ baseline |
| **A3** | KNN vs MLP head | KNN / ç›´æ¥ç”¨åˆ†é¡å™¨ / hybrid | åŒä¸Š |

#### Tier 2: è¨“ç·´ç­–ç•¥ï¼ˆä¸­ç­‰å„ªå…ˆç´šï¼‰

| ID | è®Šé‡ | é¸é … | èªªæ˜ |
| ---- | ------ | ------ | ------ |
| **B1** | æ˜¯å¦ freeze towers | freeze / âš ï¸ **ä¸å¯è§£å‡** (OOM) | RTX 5080 16GB é™åˆ¶ |
| **B2** | Loss weights | (Î±, Î³, Î»â‚, Î»â‚‚) çµ„åˆ | Grid search: Î± âˆˆ {0.5, 1.0}, Î³ âˆˆ {0.05, 0.1} |
| **B3** | max_num_patches | 256 / âš ï¸ 512 éœ€ç›£æ§ | è©•ä¼°è§£æåº¦å½±éŸ¿ |
| **B4** | é¡åˆ¥ä¸å¹³è¡¡è™•ç† | ç„¡ / Focal Loss / Class Weights | COCO é¡åˆ¥åˆ†å¸ƒä¸å‡ |

#### Tier 3: KNN è¶…åƒæ•¸ï¼ˆæ¬¡è¦å„ªå…ˆç´šï¼‰

| ID | è®Šé‡ | é¸é … | èªªæ˜ |
| ---- | ------ | ------ | ------ |
| **C1** | K å€¼ | 5 / 10 / 20 / 50 | é„°å±…æ•¸é‡ |
| **C2** | è·é›¢å‡½æ•¸ | cosine(h) / hamming(sign(h)) / hybrid | æª¢ç´¢ç­–ç•¥ |
| **C3** | Voting ç­–ç•¥ | uniform / softmax / rank-based / threshold | åŠ æ¬Šæ–¹å¼ |
| **C4** | tau (temperature) | 0.03 / 0.07 / 0.2 | softmax å¹³æ»‘åº¦ |

### 7.3 å¯¦é©—æµç¨‹

#### éšæ®µ 1: Baseline é©—è­‰ï¼ˆ1-2 å¤©ï¼‰

1. å¯¦ä½œ SigLIP2-MLP baseline
2. å¯¦ä½œ SigLIP2-ZeroShot baseline
3. ç¢ºèªè³‡æ–™è™•ç† pipeline æ­£ç¢º
4. å»ºç«‹è©•ä¼°æµç¨‹

#### éšæ®µ 2: æ ¸å¿ƒæ¶æ§‹å¯¦é©—ï¼ˆ3-5 å¤©ï¼‰

1. å¯¦ä½œå®Œæ•´æ¶æ§‹
2. åŸ·è¡Œ Tier 1 ablations (A1-A3)
3. é¸å‡ºæœ€ä½³é…ç½®

#### éšæ®µ 3: è¨“ç·´ç­–ç•¥å„ªåŒ–ï¼ˆ3-5 å¤©ï¼‰

1. åŸ·è¡Œ Tier 2 ablations (B1-B4)
2. è¶…åƒæ•¸ grid search
3. å­¸ç¿’ç‡èª¿åº¦å¯¦é©—

#### éšæ®µ 4: KNN èª¿å„ªï¼ˆ2-3 å¤©ï¼‰

1. åŸ·è¡Œ Tier 3 ablations (C1-C4)
2. æª¢ç´¢æ•ˆç‡åˆ†æ
3. å¯è§£é‡‹æ€§å¯¦é©—

#### éšæ®µ 5: æœ€çµ‚è©•ä¼°èˆ‡åˆ†æï¼ˆ2-3 å¤©ï¼‰

1. Test set è©•ä¼°
2. éŒ¯èª¤åˆ†æ
3. è¦–è¦ºåŒ–å±•ç¤º
4. æ’°å¯«å ±å‘Š

---

## 8) è¶…åƒæ•¸é…ç½® (â­ RTX 5080 å„ªåŒ–)

### 8.1 ç¡¬é«”è³‡è¨Šç¸½è¦½

```yaml
# å¯¦éš›ç¡¬é«”è¦æ ¼
hardware_info:
  gpu:
    model: "NVIDIA GeForce RTX 5080"
    vram_gb: 16  # âš ï¸ é—œéµé™åˆ¶
    cuda_version: "13.0"
    driver_version: "580.126.09"
    compute_capability: "8.9"  # Ada Lovelace
  
  cpu:
    cores: 32
    threads: 64  # å‡è¨­æ”¯æ´è¶…åŸ·è¡Œç·’
    model: "é«˜éšå·¥ä½œç«™è™•ç†å™¨"
  
  memory:
    ram_gb: 42
    swap_gb: 8  # å»ºè­°è¨­å®š
  
  storage:
    total_tb: 1.1
    ssd: true
```

### 8.2 è¨˜æ†¶é«”ä½”ç”¨ä¼°ç®—è¡¨ï¼ˆ16GB VRAMï¼‰

| çµ„ä»¶ | è¨˜æ†¶é«”ä½”ç”¨ | èªªæ˜ |
| ------ | ----------- | ------ |
| **SigLIP2-base (å‡çµ)** | ~2.5 GB | åƒ… forward passï¼Œç„¡ gradients |
| **Fusion MLP** | ~0.3 GB | å¯è¨“ç·´åƒæ•¸ |
| **Hash Layer** | ~0.1 GB | å¯è¨“ç·´åƒæ•¸ |
| **Classifier Head** | ~0.05 GB | å¯è¨“ç·´åƒæ•¸ |
| **Optimizer States (AdamW)** | ~1.2 GB | 2x å¯è¨“ç·´åƒæ•¸é‡ |
| **Batch Data (32, mixed precision)** | ~4.0 GB | Images + embeddings (FP16) |
| **Gradients** | ~0.5 GB | åƒ…å¯è¨“ç·´éƒ¨åˆ† |
| **CUDA Kernels & PyTorch** | ~0.5 GB | Framework overhead |
| **é ç•™ç·©è¡** | ~1.0 GB | å®‰å…¨é‚Šç•Œ |
| **ç¸½è¨ˆ** | **~10.2 GB** | âœ… åœ¨ 16GB å…§å®‰å…¨ (63% ä½¿ç”¨ç‡) |

### 8.3 å„ªåŒ–å¾Œçš„é…ç½®æ–‡ä»¶

```yaml
# configs/hardware/rtx5080_16gb.yaml

# ==========================================
# ç¡¬é«”å„ªåŒ–é…ç½® - RTX 5080 16GB å°ˆç”¨
# ==========================================

experiment:
  name: "baseline_rtx5080_16gb"
  version: "v2.1"
  seed: 42
  deterministic: false  # true æœƒæ…¢å¾ˆå¤š

# æ¨¡å‹æ¶æ§‹
model:
  siglip2_variant: "google/siglip2-base-patch16-256"  # âš ï¸ ä¸è¦ç”¨ largeï¼
  max_num_patches: 256  # ä¿å®ˆè¨­å®šï¼Œå¯å˜—è©¦ 512 ä½†éœ€ç›£æ§
  text_max_length: 64
  freeze_towers: true  # âš ï¸ å¿…é ˆç‚º trueï¼Œå¦å‰‡ OOMï¼
  
  # åˆ†è§£å±¤
  decomposer:
    eps: 1.0e-6
  
  # èåˆå±¤
  fusion:
    type: "hadamard_with_magnitude"  # æ–¹æ¡ˆ B
    mlp_dims: [1024, 512]  # è¼¸å…¥: 3*768+2 = 2306
    dropout: 0.1
    activation: "relu"
  
  # Hash å±¤
  hash:
    bits: 64  # 32=å¿«é€Ÿ, 64=å¹³è¡¡, 128=é«˜ç²¾åº¦(éœ€æ›´å¤šè¨˜æ†¶é«”)
    activation: "tanh"
  
  # åˆ†é¡é ­
  classifier:
    num_classes: 80  # COCO categories
    use_bias: true

# æå¤±å‡½æ•¸
loss:
  # BCE Loss (ä¸»è¦)
  bce_weight: 1.0
  use_focal_loss: false  # å¯é¸ï¼šè™•ç†é¡åˆ¥ä¸å¹³è¡¡
  focal_alpha: 0.25
  focal_gamma: 2.0
  
  # Cosine Alignment Loss
  cosine_weight: 1.0  # Î±
  
  # Hash Regularization
  hash_weight: 0.1  # Î³
  hash_reg:
    lambda_balance: 0.1  # Î»â‚
    lambda_decorr: 0.01  # Î»â‚‚

# è¨“ç·´é…ç½® (â­ RTX 5080 å„ªåŒ–)
training:
  # æ‰¹æ¬¡å¤§å° (é—œéµï¼)
  batch_size: 32  # âš ï¸ å¾ 64 é™åˆ° 32
  gradient_accumulation_steps: 2  # âš ï¸ å¿…é ˆä½¿ç”¨ï¼Œæ¨¡æ“¬ batch_size=64
  effective_batch_size: 64  # 32 * 2 = 64
  
  # Epoch èˆ‡é©—è­‰
  num_epochs: 30
  warmup_epochs: 2
  val_every_n_epochs: 1
  
  # æ¢¯åº¦ç®¡ç†
  gradient_clip_norm: 1.0
  max_grad_norm: 1.0
  
  # Early Stopping
  early_stopping_patience: 5
  save_top_k: 3
  monitor_metric: "val_mAP"  # æˆ– "val_f1_macro"

# Optimizer
optimizer:
  type: "adamw"
  lr: 2.0e-4  # âš ï¸ æ¯”åŸæœ¬ 3e-4 ç•¥å°ï¼ˆå›  effective batch size ä¸€æ¨£ï¼‰
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Scheduler
scheduler:
  type: "cosine_with_warmup"
  warmup_ratio: 0.1  # warmup_epochs / num_epochs
  min_lr: 1.0e-6
  cosine_cycles: 1

# DataLoader (â­ åˆ©ç”¨ 32 æ ¸å¿ƒ CPU)
dataloader:
  num_workers: 16  # âš ï¸ ä½ æœ‰ 32 æ ¸å¿ƒï¼Œå¯ä»¥ç”¨æ›´å¤š
  prefetch_factor: 3  # é è¼‰å…¥ 3 æ‰¹æ¬¡è³‡æ–™
  pin_memory: true  # åŠ é€Ÿ CPU->GPU å‚³è¼¸
  persistent_workers: true  # ä¿æŒ workers å­˜æ´»
  drop_last: true  # ä¸Ÿæ£„ä¸å®Œæ•´çš„æœ€å¾Œä¸€æ‰¹

# è¨˜æ†¶é«”å„ªåŒ– (â­ é—œéµè¨­å®š)
memory_optimization:
  # æ··åˆç²¾åº¦ (å¿…é ˆï¼)
  mixed_precision: true  # âš ï¸ ç¯€çœ 40% VRAM
  amp_dtype: "float16"  # æˆ– "bfloat16" (å¦‚æœæ”¯æ´)
  
  # Gradient Checkpointing (å¯é¸ï¼Œç¯€çœæ›´å¤šè¨˜æ†¶é«”)
  gradient_checkpointing: false  # å‡çµ towers æ™‚ä¸éœ€è¦
  
  # å¿«å–ç®¡ç†
  empty_cache_steps: 100  # æ¯ 100 æ­¥æ¸…ç†ä¸€æ¬¡ CUDA å¿«å–
  
  # VRAM ç›£æ§
  log_gpu_memory: true
  alert_vram_threshold_gb: 14.5  # è¶…é 14.5GB ç™¼å‡ºè­¦å‘Š

# KNN æ¨è«–é…ç½®
knn:
  K: 20  # number of neighbors
  distance_metric: "hamming"  # or "cosine"
  voting_strategy: "softmax"  # or "uniform", "rank_based"
  tau: 0.07  # temperature for softmax
  top_n_tags: 5  # output top N predictions
  
  # æ¨è«–æ™‚çš„æ‰¹æ¬¡å¤§å°ï¼ˆå¯ä»¥æ¯”è¨“ç·´å¤§ï¼‰
  inference_batch_size: 64

# æ—¥èªŒèˆ‡ç›£æ§
logging:
  log_every_n_steps: 50
  log_gradients: false  # åƒ…åœ¨ debug æ™‚å•Ÿç”¨
  log_weights: false
  
  # Weights & Biases
  use_wandb: true
  wandb_project: "siglip2-multimodal-hash"
  wandb_entity: "your-username"
  
  # TensorBoard
  use_tensorboard: true
  tensorboard_dir: "experiments/tensorboard"

# æª¢æŸ¥é»
checkpointing:
  save_dir: "experiments/checkpoints"
  save_every_n_epochs: 5
  save_last: true
  save_top_k: 3
  filename_format: "epoch={epoch:02d}-val_mAP={val_mAP:.4f}"

# è³‡æ–™å¢å¼· (å¯é¸)
augmentation:
  use_augmentation: false  # SigLIP2 å·²ç¶“å¾ˆå¼·ï¼Œå¯èƒ½ä¸éœ€è¦
  random_flip: false
  color_jitter: false
  random_crop: false
```

### 8.4 ç·Šæ€¥é™ç´šæ–¹æ¡ˆï¼ˆå¦‚æœé‚„æ˜¯ OOMï¼‰

```yaml
# configs/hardware/rtx5080_16gb_emergency.yaml
# ç•¶ baseline é…ç½®ä»ç„¶ OOM æ™‚ä½¿ç”¨

training:
  batch_size: 16  # âš ï¸ å¾ 32 é™åˆ° 16
  gradient_accumulation_steps: 4  # æ¨¡æ“¬ batch_size=64

model:
  max_num_patches: 196  # âš ï¸ å¾ 256 é™åˆ° 196 (14x14 patches)

memory_optimization:
  gradient_checkpointing: true  # âš ï¸ å•Ÿç”¨ï¼Œç¯€çœ 30% VRAM
  empty_cache_steps: 50  # æ›´é »ç¹æ¸…ç†
```

### 8.5 Grid Search é…ç½®ï¼ˆä¾›è‡ªå‹•åŒ–å¯¦é©—ï¼‰

```yaml
# configs/grid_search.yaml

grid_search:
  # Tier 1: æ ¸å¿ƒæ¶æ§‹
  hash_bits: [32, 64, 128]
  fusion_type: ["concat_only", "hadamard", "hadamard_with_magnitude"]
  
  # Tier 2: è¨“ç·´ç­–ç•¥
  cosine_weight: [0.5, 1.0, 2.0]
  hash_weight: [0.05, 0.1, 0.2]
  
  # Tier 3: KNN è¶…åƒæ•¸
  K_neighbors: [10, 20, 50]
  tau: [0.03, 0.07, 0.15]
  
  # è¨˜æ†¶é«”ç›¸é—œï¼ˆæ…ç”¨ï¼‰
  max_num_patches: [256]  # 512 é¢¨éšªå¤ªé«˜ï¼Œä¸å»ºè­° grid search
  batch_size: [32]  # å›ºå®šï¼Œä¸å»ºè­°è®Šå‹•

# ç¸½å¯¦é©—æ•¸ï¼š3*3 + 3*3 + 3*3 = 27 çµ„
# é ä¼°æ™‚é–“ï¼š27 * 17.5 å°æ™‚ = ~472 å°æ™‚ (åˆ†æ•£å¤š GPU åŸ·è¡Œ)
```

---

## 9) å¯¦ä½œç´°ç¯€ (â­ å«è¨˜æ†¶é«”å„ªåŒ–)

### 9.1 é—œéµç¨‹å¼ç¢¼ç‰‡æ®µ

#### 9.1.1 æ–¹å‘/å¹…åº¦åˆ†è§£

```python
import torch
import torch.nn as nn

class DirectionMagnitudeDecomposer(nn.Module):
    def __init__(self, eps=1e-6):
        super().__init__()
        self.eps = eps
    
    def forward(self, v):
        """
        Args:
            v: (batch_size, dim) raw embedding
        Returns:
            direction: (batch_size, dim) unit vector
            magnitude: (batch_size, 1) log-norm
        """
        norm = torch.norm(v, p=2, dim=1, keepdim=True)  # (B, 1)
        direction = v / (norm + self.eps)  # (B, D)
        magnitude = torch.log(norm + self.eps)  # (B, 1)
        return direction, magnitude
```

#### 9.1.2 Hadamard èåˆ

```python
class HadamardFusion(nn.Module):
    def __init__(self, embed_dim, mlp_dims, dropout=0.1):
        super().__init__()
        # Input: [d_img, d_txt, p_dir, m_img, m_txt]
        input_dim = embed_dim * 3 + 2  # 3*768+2 for base
        
        layers = []
        prev_dim = input_dim
        for hidden_dim in mlp_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout)
            ])
            prev_dim = hidden_dim
        
        self.mlp = nn.Sequential(*layers)
    
    def forward(self, d_img, d_txt, m_img, m_txt):
        """
        Args:
            d_img: (B, D) image direction
            d_txt: (B, D) text direction
            m_img: (B, 1) image magnitude
            m_txt: (B, 1) text magnitude
        Returns:
            z: (B, mlp_dims[-1]) fused embedding
        """
        p_dir = d_img * d_txt  # Hadamard product
        x = torch.cat([d_img, d_txt, p_dir, m_img, m_txt], dim=1)
        z = self.mlp(x)
        return z
```

#### 9.1.3 Hash å±¤èˆ‡æ­£å‰‡åŒ–

```python
class HashLayer(nn.Module):
    def __init__(self, input_dim, hash_bits):
        super().__init__()
        self.fc = nn.Linear(input_dim, hash_bits)
        self.hash_bits = hash_bits
    
    def forward(self, z):
        """Returns soft hash codes in [-1, 1]"""
        h = torch.tanh(self.fc(z))
        return h
    
    def binarize(self, h):
        """For inference: convert to hard binary {-1, 1}"""
        return torch.sign(h)

def hash_regularization(h, lambda_balance=0.1, lambda_decorr=0.01):
    """
    Args:
        h: (batch_size, hash_bits) soft hash codes
    Returns:
        loss_hash: scalar tensor
    """
    # 1. Quantization loss
    loss_quant = torch.mean((torch.abs(h) - 1) ** 2)
    
    # 2. Bit balance loss
    bit_mean = torch.mean(h, dim=0)  # (hash_bits,)
    loss_balance = torch.mean(bit_mean ** 2)
    
    # 3. Bit decorrelation loss
    h_centered = h - torch.mean(h, dim=0, keepdim=True)
    cov = (h_centered.T @ h_centered) / h.size(0)  # (B, B)
    loss_decorr = (torch.sum(cov ** 2) - torch.trace(cov ** 2)) / (h.size(1) ** 2)
    
    loss_hash = loss_quant + lambda_balance * loss_balance + lambda_decorr * loss_decorr
    return loss_hash
```

#### 9.1.4 å®Œæ•´æ¨¡å‹

```python
class MultimodalHashKNN(nn.Module):
    def __init__(self, config):
        super().__init__()
        # SigLIP2 encoders
        self.processor = Siglip2Processor.from_pretrained(config.siglip2_variant)
        self.model = Siglip2Model.from_pretrained(config.siglip2_variant)
        
        # âš ï¸ å¿…é ˆå‡çµ towersï¼ˆRTX 5080 16GB é™åˆ¶ï¼‰
        if config.freeze_towers:
            for param in self.model.parameters():
                param.requires_grad = False
            print("âœ“ SigLIP2 towers frozen (saving ~7.5GB VRAM)")
        
        # Decomposer
        self.decomposer = DirectionMagnitudeDecomposer()
        
        # Fusion
        embed_dim = self.model.config.projection_dim  # 768 for base
        self.fusion = HadamardFusion(embed_dim, config.mlp_dims, config.dropout)
        
        # Hash layer
        self.hash_layer = HashLayer(config.mlp_dims[-1], config.hash_bits)
        
        # Classifier head (for training)
        self.classifier = nn.Linear(config.hash_bits, config.num_classes)
        
        self.config = config
    
    def forward(self, images, texts, return_components=False):
        # Encode
        outputs = self.model(pixel_values=images, input_ids=texts)
        v_img = outputs.image_embeds  # (B, D)
        v_txt = outputs.text_embeds   # (B, D)
        
        # Decompose
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        
        # Fuse
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        
        # Hash
        h = self.hash_layer(z)
        
        # Classify
        logits = self.classifier(h)
        
        if return_components:
            return {
                'logits': logits,
                'h': h,
                'd_img': d_img,
                'd_txt': d_txt,
                'm_img': m_img,
                'm_txt': m_txt,
                'z': z
            }
        else:
            return logits
    
    def get_hash(self, images, texts):
        """For inference: return hash codes"""
        with torch.no_grad():
            outputs = self.model(pixel_values=images, input_ids=texts)
            v_img = outputs.image_embeds
            v_txt = outputs.text_embeds
            d_img, m_img = self.decomposer(v_img)
            d_txt, m_txt = self.decomposer(v_txt)
            z = self.fusion(d_img, d_txt, m_img, m_txt)
            h = self.hash_layer(z)
        return h
```

### 9.2 è¨“ç·´è¿´åœˆï¼ˆâ­ å«è¨˜æ†¶é«”å„ªåŒ–ï¼‰

```python
import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler

def get_gpu_memory_info():
    """ç²å– GPU è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        max_allocated = torch.cuda.max_memory_allocated() / 1e9
        return {
            "allocated_gb": allocated,
            "reserved_gb": reserved,
            "max_allocated_gb": max_allocated,
            "free_gb": 16.0 - reserved
        }
    return None

def train_epoch(model, dataloader, optimizer, scheduler, config):
    """å„ªåŒ–çš„è¨“ç·´è¿´åœˆï¼ˆé‡å° RTX 5080 16GBï¼‰"""
    
    model.train()
    scaler = GradScaler()  # âš ï¸ æ··åˆç²¾åº¦å¿…é ˆ
    
    total_loss = 0
    total_loss_bce = 0
    total_loss_cos = 0
    total_loss_hash = 0
    
    accumulation_steps = config.training.gradient_accumulation_steps
    
    for batch_idx, batch in enumerate(dataloader):
        # ç§»åˆ° GPUï¼ˆnon_blocking åŠ é€Ÿï¼‰
        images = batch['images'].to('cuda', non_blocking=True)
        texts = batch['texts'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)  # (B, C) multi-hot
        
        # âš ï¸ æ··åˆç²¾åº¦å‰å‘å‚³æ’­
        with autocast(dtype=torch.float16):
            outputs = model(images, texts, return_components=True)
            logits = outputs['logits']
            h = outputs['h']
            d_img = outputs['d_img']
            d_txt = outputs['d_txt']
            
            # è¨ˆç®—å„é …æå¤±
            loss_bce = F.binary_cross_entropy_with_logits(logits, labels.float())
            loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
            loss_hash = hash_regularization(
                h, 
                config.loss.hash_reg.lambda_balance,
                config.loss.hash_reg.lambda_decorr
            )
            
            # çµ„åˆæå¤±
            loss = (
                config.loss.bce_weight * loss_bce + 
                config.loss.cosine_weight * loss_cos + 
                config.loss.hash_weight * loss_hash
            )
            loss = loss / accumulation_steps  # âš ï¸ æ¢¯åº¦ç´¯ç©
        
        # åå‘å‚³æ’­
        scaler.scale(loss).backward()
        
        # âš ï¸ æ¢¯åº¦ç´¯ç©ï¼šæ¯ N æ­¥æ›´æ–°ä¸€æ¬¡
        if (batch_idx + 1) % accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(
                model.parameters(), 
                config.training.gradient_clip_norm
            )
            
            # æ›´æ–°åƒæ•¸
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
        
        # ç´¯ç©æå¤±ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
        total_loss += loss.item() * accumulation_steps
        total_loss_bce += loss_bce.item()
        total_loss_cos += loss_cos.item()
        total_loss_hash += loss_hash.item()
        
        # âš ï¸ å®šæœŸç›£æ§è¨˜æ†¶é«”
        if batch_idx % 100 == 0:
            mem_info = get_gpu_memory_info()
            print(f"Batch {batch_idx}/{len(dataloader)}: "
                  f"Loss={loss.item():.4f}, "
                  f"GPU Memory: {mem_info['allocated_gb']:.2f}GB / 16GB "
                  f"({mem_info['allocated_gb']/16*100:.1f}%)")
            
            # âš ï¸ è­¦å‘Šæ©Ÿåˆ¶
            if mem_info['allocated_gb'] > config.memory_optimization.alert_vram_threshold_gb:
                print(f"âš ï¸  WARNING: GPU memory usage high! "
                      f"{mem_info['allocated_gb']:.2f}GB / 16GB")
        
        # âš ï¸ å®šæœŸæ¸…ç†å¿«å–
        if batch_idx % config.memory_optimization.empty_cache_steps == 0:
            torch.cuda.empty_cache()
    
    scheduler.step()
    
    # è¿”å›å¹³å‡æå¤±
    n_batches = len(dataloader)
    return {
        'total': total_loss / n_batches,
        'bce': total_loss_bce / n_batches,
        'cos': total_loss_cos / n_batches,
        'hash': total_loss_hash / n_batches
    }
```

### 9.3 é©—è­‰è¿´åœˆ

```python
@torch.no_grad()
def validate(model, dataloader, config):
    """é©—è­‰è¿´åœˆ"""
    model.eval()
    
    total_loss = 0
    all_logits = []
    all_labels = []
    
    for batch in dataloader:
        images = batch['images'].to('cuda', non_blocking=True)
        texts = batch['texts'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        # âš ï¸ æ··åˆç²¾åº¦æ¨è«–
        with autocast(dtype=torch.float16):
            outputs = model(images, texts, return_components=True)
            logits = outputs['logits']
            d_img = outputs['d_img']
            d_txt = outputs['d_txt']
            h = outputs['h']
            
            # è¨ˆç®—æå¤±
            loss_bce = F.binary_cross_entropy_with_logits(logits, labels.float())
            loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
            loss_hash = hash_regularization(h, config.loss.hash_reg.lambda_balance,
                                           config.loss.hash_reg.lambda_decorr)
            
            loss = (config.loss.bce_weight * loss_bce + 
                    config.loss.cosine_weight * loss_cos + 
                    config.loss.hash_weight * loss_hash)
        
        total_loss += loss.item()
        all_logits.append(logits.cpu())
        all_labels.append(labels.cpu())
    
    # åˆä½µæ‰€æœ‰çµæœ
    all_logits = torch.cat(all_logits, dim=0)
    all_labels = torch.cat(all_labels, dim=0)
    
    # è¨ˆç®—æŒ‡æ¨™
    from sklearn.metrics import average_precision_score, f1_score
    
    y_true = all_labels.numpy()
    y_scores = torch.sigmoid(all_logits).numpy()
    y_pred = (y_scores > 0.5).astype(int)
    
    metrics = {
        'loss': total_loss / len(dataloader),
        'mAP': average_precision_score(y_true, y_scores, average='macro'),
        'f1_micro': f1_score(y_true, y_pred, average='micro'),
        'f1_macro': f1_score(y_true, y_pred, average='macro'),
    }
    
    return metrics
```

### 9.4 å®Œæ•´è¨“ç·´è…³æœ¬

```python
# scripts/train.py
import torch
import hydra
from omegaconf import DictConfig
import wandb
from tqdm import tqdm

@hydra.main(config_path="../configs", config_name="hardware/rtx5080_16gb")
def main(config: DictConfig):
    # è¨­å®š seed
    torch.manual_seed(config.experiment.seed)
    
    # åˆå§‹åŒ– wandb
    if config.logging.use_wandb:
        wandb.init(
            project=config.logging.wandb_project,
            entity=config.logging.wandb_entity,
            config=dict(config),
            name=config.experiment.name
        )
    
    # å»ºç«‹æ¨¡å‹
    print("å»ºç«‹æ¨¡å‹...")
    model = MultimodalHashKNN(config.model).cuda()
    
    # é¡¯ç¤ºè¨˜æ†¶é«”è³‡è¨Š
    mem_info = get_gpu_memory_info()
    print(f"æ¨¡å‹è¼‰å…¥å¾Œ GPU è¨˜æ†¶é«”: {mem_info['allocated_gb']:.2f}GB / 16GB")
    
    # å»ºç«‹ DataLoader
    print("å»ºç«‹ DataLoader...")
    train_loader = create_dataloader(config, split='train')
    val_loader = create_dataloader(config, split='val')
    
    # å»ºç«‹ optimizer èˆ‡ scheduler
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.optimizer.lr,
        weight_decay=config.optimizer.weight_decay,
        betas=config.optimizer.betas
    )
    
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.training.num_epochs,
        eta_min=config.scheduler.min_lr
    )
    
    # è¨“ç·´è¿´åœˆ
    best_val_map = 0
    patience_counter = 0
    
    for epoch in range(config.training.num_epochs):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{config.training.num_epochs}")
        print(f"{'='*60}")
        
        # è¨“ç·´
        train_losses = train_epoch(model, train_loader, optimizer, scheduler, config)
        print(f"Train Loss: {train_losses['total']:.4f} "
              f"(BCE: {train_losses['bce']:.4f}, "
              f"Cos: {train_losses['cos']:.4f}, "
              f"Hash: {train_losses['hash']:.4f})")
        
        # é©—è­‰
        val_metrics = validate(model, val_loader, config)
        print(f"Val Loss: {val_metrics['loss']:.4f}, "
              f"mAP: {val_metrics['mAP']:.4f}, "
              f"F1-Micro: {val_metrics['f1_micro']:.4f}, "
              f"F1-Macro: {val_metrics['f1_macro']:.4f}")
        
        # è¨˜éŒ„åˆ° wandb
        if config.logging.use_wandb:
            wandb.log({
                'epoch': epoch,
                'train/loss': train_losses['total'],
                'train/loss_bce': train_losses['bce'],
                'train/loss_cos': train_losses['cos'],
                'train/loss_hash': train_losses['hash'],
                'val/loss': val_metrics['loss'],
                'val/mAP': val_metrics['mAP'],
                'val/f1_micro': val_metrics['f1_micro'],
                'val/f1_macro': val_metrics['f1_macro'],
                'lr': optimizer.param_groups[0]['lr']
            })
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['mAP'] > best_val_map:
            best_val_map = val_metrics['mAP']
            patience_counter = 0
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_mAP': val_metrics['mAP'],
                'config': dict(config)
            }
            torch.save(checkpoint, f"best_model_epoch{epoch}_mAP{val_metrics['mAP']:.4f}.pth")
            print(f"âœ“ å„²å­˜æœ€ä½³æ¨¡å‹ (mAP: {val_metrics['mAP']:.4f})")
        else:
            patience_counter += 1
        
        # Early stopping
        if patience_counter >= config.training.early_stopping_patience:
            print(f"Early stopping triggered after {epoch+1} epochs")
            break
    
    print("\nè¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³ Val mAP: {best_val_map:.4f}")

if __name__ == "__main__":
    main()
```

### 9.5 è¨˜æ†¶é«”ç®¡ç†å·¥å…·

```python
# utils/memory_monitor.py

import torch
import psutil
import GPUtil

class MemoryMonitor:
    """è¨˜æ†¶é«”ç›£æ§å·¥å…·"""
    
    def __init__(self, alert_threshold_gb=14.5):
        self.alert_threshold_gb = alert_threshold_gb
        self.peak_vram = 0
    
    def get_stats(self):
        """ç²å–å®Œæ•´è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = {}
        
        # GPU è¨˜æ†¶é«”
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            max_allocated = torch.cuda.max_memory_allocated() / 1e9
            
            stats['gpu'] = {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'max_allocated_gb': max_allocated,
                'free_gb': 16.0 - reserved,
                'utilization_%': allocated / 16.0 * 100
            }
            
            # æ›´æ–°å³°å€¼
            self.peak_vram = max(self.peak_vram, allocated)
            
            # æª¢æŸ¥æ˜¯å¦è¶…éé–¾å€¼
            if allocated > self.alert_threshold_gb:
                stats['gpu']['alert'] = True
        
        # CPU è¨˜æ†¶é«”
        ram = psutil.virtual_memory()
        stats['cpu'] = {
            'used_gb': ram.used / 1e9,
            'available_gb': ram.available / 1e9,
            'percent': ram.percent
        }
        
        return stats
    
    def print_stats(self, prefix=""):
        """åˆ—å°è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = self.get_stats()
        
        if 'gpu' in stats:
            gpu = stats['gpu']
            print(f"{prefix}GPU: {gpu['allocated_gb']:.2f}GB / 16GB "
                  f"({gpu['utilization_%']:.1f}%), "
                  f"Peak: {self.peak_vram:.2f}GB")
            
            if gpu.get('alert'):
                print(f"  âš ï¸  WARNING: VRAM usage high!")
        
        cpu = stats['cpu']
        print(f"{prefix}RAM: {cpu['used_gb']:.1f}GB / {42:.1f}GB "
              f"({cpu['percent']:.1f}%)")
    
    def reset_peak(self):
        """é‡ç½®å³°å€¼çµ±è¨ˆ"""
        torch.cuda.reset_peak_memory_stats()
        self.peak_vram = 0

# ä½¿ç”¨ç¯„ä¾‹
monitor = MemoryMonitor(alert_threshold_gb=14.5)

# è¨“ç·´å‰
monitor.print_stats("è¨“ç·´å‰ - ")

# è¨“ç·´ä¸­ï¼ˆå®šæœŸæª¢æŸ¥ï¼‰
for epoch in range(num_epochs):
    for batch_idx, batch in enumerate(train_loader):
        # ... è¨“ç·´ç¨‹å¼ç¢¼ ...
        
        if batch_idx % 100 == 0:
            monitor.print_stats(f"Epoch {epoch}, Batch {batch_idx} - ")
```

---

## 10) è¶…åƒæ•¸é…ç½®ï¼ˆâ­ å°æ‡‰ä½ çš„å°ˆæ¡ˆï¼‰

### 10.1 ç¡¬é«”é…ç½®æª”æ¡ˆ

å»ºç«‹ `configs/hardware/rtx5080_16gb.yaml`:

```yaml
# configs/hardware/rtx5080_16gb.yaml
# RTX 5080 16GB ç¡¬é«”å„ªåŒ–é…ç½®

# ==========================================
# ç¡¬é«”è³‡è¨Š
# ==========================================
hardware_info:
  gpu:
    model: "NVIDIA GeForce RTX 5080"
    vram_gb: 16
    cuda_version: "12.4"  # âš ï¸ ä¿®æ­£ï¼šä½ çš„ç³»çµ±æ˜¯ CUDA 12.4
    driver_version: "580.126.09"
    compute_capability: "8.9"
  
  cpu:
    cores: 32
    threads: 64
  
  memory:
    ram_gb: 42
  
  storage:
    total_tb: 1.1
    ssd: true

# ==========================================
# å°ˆæ¡ˆè·¯å¾‘
# ==========================================
paths:
  project_root: "~/Documents/Coding/github.com/natsuki221/AGCH-Improvement"
  data_root: "./data/coco"
  output_root: "./outputs"
  experiment_root: "./experiments"

# ==========================================
# æ¨¡å‹é…ç½®
# ==========================================
model:
  siglip2_variant: "google/siglip2-base-patch16-256"
  max_num_patches: 256
  text_max_length: 64
  freeze_towers: true  # âš ï¸ å¿…é ˆç‚º true
  
  decomposer:
    eps: 1.0e-6
  
  fusion:
    type: "hadamard_with_magnitude"
    mlp_dims: [1024, 512]
    dropout: 0.1
    activation: "relu"
  
  hash:
    bits: 64
    activation: "tanh"
  
  classifier:
    num_classes: 80
    use_bias: true

# ==========================================
# æå¤±å‡½æ•¸
# ==========================================
loss:
  bce_weight: 1.0
  cosine_weight: 1.0
  hash_weight: 0.1
  
  hash_reg:
    lambda_balance: 0.1
    lambda_decorr: 0.01
  
  focal_loss: false
  focal_alpha: 0.25
  focal_gamma: 2.0

# ==========================================
# è¨“ç·´é…ç½®ï¼ˆâ­ RTX 5080 16GB å„ªåŒ–ï¼‰
# ==========================================
training:
  # æ‰¹æ¬¡å¤§å°
  batch_size: 32  # âš ï¸ é—œéµï¼šå¾ 64 é™åˆ° 32
  gradient_accumulation_steps: 2  # æ¨¡æ“¬ batch_size=64
  effective_batch_size: 64
  
  # Epoch
  num_epochs: 30
  warmup_epochs: 2
  val_every_n_epochs: 1
  
  # æ¢¯åº¦ç®¡ç†
  gradient_clip_norm: 1.0
  
  # Early Stopping
  early_stopping_patience: 5
  save_top_k: 3
  monitor_metric: "val_mAP"

# ==========================================
# Optimizer
# ==========================================
optimizer:
  type: "adamw"
  lr: 2.0e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

# ==========================================
# Scheduler
# ==========================================
scheduler:
  type: "cosine_with_warmup"
  warmup_ratio: 0.1
  min_lr: 1.0e-6

# ==========================================
# DataLoaderï¼ˆâ­ åˆ©ç”¨ 32 æ ¸å¿ƒï¼‰
# ==========================================
dataloader:
  num_workers: 16  # åˆ©ç”¨ä½ çš„ 32 æ ¸å¿ƒ
  prefetch_factor: 3
  pin_memory: true
  persistent_workers: true
  drop_last: true

# ==========================================
# è¨˜æ†¶é«”å„ªåŒ–ï¼ˆâ­ é—œéµï¼‰
# ==========================================
memory_optimization:
  mixed_precision: true  # âš ï¸ å¿…é ˆå•Ÿç”¨
  amp_dtype: "float16"
  gradient_checkpointing: false  # å‡çµ towers æ™‚ä¸éœ€è¦
  empty_cache_steps: 100
  log_gpu_memory: true
  alert_vram_threshold_gb: 14.5

# ==========================================
# KNN æ¨è«–
# ==========================================
knn:
  K: 20
  distance_metric: "hamming"
  voting_strategy: "softmax"
  tau: 0.07
  top_n_tags: 5
  inference_batch_size: 64

# ==========================================
# æ—¥èªŒèˆ‡ç›£æ§
# ==========================================
logging:
  log_every_n_steps: 50
  
  # Weights & Biases
  use_wandb: true
  wandb_project: "siglip2-multimodal-hash"
  wandb_entity: "natsuki221"  # ä½ çš„ wandb ä½¿ç”¨è€…åç¨±
  
  # TensorBoard
  use_tensorboard: true
  tensorboard_dir: "./experiments/tensorboard"

# ==========================================
# æª¢æŸ¥é»
# ==========================================
checkpointing:
  save_dir: "./outputs/checkpoints"
  save_every_n_epochs: 5
  save_last: true
  save_top_k: 3
  filename_format: "epoch={epoch:02d}-val_mAP={val_mAP:.4f}"

# ==========================================
# å…¶ä»–
# ==========================================
experiment:
  name: "baseline_rtx5080_16gb"
  seed: 42
  deterministic: false
```

### 10.2 Baseline å¯¦é©—é…ç½®

å»ºç«‹ `configs/experiments/baseline.yaml`:

```yaml
# configs/experiments/baseline.yaml
# Baseline å¯¦é©—é…ç½®

defaults:
  - /hardware/rtx5080_16gb  # ç¹¼æ‰¿ç¡¬é«”é…ç½®

# è¦†å¯«å¯¦é©—åç¨±
experiment:
  name: "baseline_siglip2_base_hash64_knn20"
  tags: ["baseline", "siglip2-base", "hash-64", "knn-20"]
  notes: "Baseline experiment with direction+magnitude decomposition"

# ç¢ºèªé—œéµåƒæ•¸
model:
  hash:
    bits: 64  # Baseline ä½¿ç”¨ 64 bits

knn:
  K: 20  # Baseline ä½¿ç”¨ 20 neighbors

# è¨“ç·´è¨­å®š
training:
  num_epochs: 30
  batch_size: 32
  gradient_accumulation_steps: 2
```

---

## 11) å¯¦ä½œç´°ç¯€ï¼ˆâ­ å®Œæ•´ç¨‹å¼ç¢¼ï¼‰

### 11.1 æ¨¡å‹å®šç¾©ï¼ˆ`src/siglip2_multimodal_hash/model.py`ï¼‰

```python
# src/siglip2_multimodal_hash/model.py

import torch
import torch.nn as nn
from transformers import Siglip2Model, Siglip2Processor
from typing import Optional, Dict

class DirectionMagnitudeDecomposer(nn.Module):
    """æ–¹å‘/å¹…åº¦åˆ†è§£æ¨¡çµ„"""
    
    def __init__(self, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
    
    def forward(self, v: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            v: (batch_size, dim) raw embedding
        Returns:
            direction: (batch_size, dim) unit vector
            magnitude: (batch_size, 1) log-norm
        """
        norm = torch.norm(v, p=2, dim=1, keepdim=True)  # (B, 1)
        direction = v / (norm + self.eps)  # (B, D)
        magnitude = torch.log(norm + self.eps)  # (B, 1)
        return direction, magnitude


class HadamardFusion(nn.Module):
    """Hadamard ä¹˜ç©èåˆæ¨¡çµ„"""
    
    def __init__(
        self,
        embed_dim: int,
        mlp_dims: list[int],
        dropout: float = 0.1,
        activation: str = "relu"
    ):
        super().__init__()
        
        # Input: [d_img, d_txt, p_dir, m_img, m_txt]
        input_dim = embed_dim * 3 + 2
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in mlp_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU() if activation == "relu" else nn.GELU(),
                nn.Dropout(dropout)
            ])
            prev_dim = hidden_dim
        
        self.mlp = nn.Sequential(*layers)
    
    def forward(
        self,
        d_img: torch.Tensor,
        d_txt: torch.Tensor,
        m_img: torch.Tensor,
        m_txt: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            d_img: (B, D) image direction
            d_txt: (B, D) text direction
            m_img: (B, 1) image magnitude
            m_txt: (B, 1) text magnitude
        Returns:
            z: (B, mlp_dims[-1]) fused embedding
        """
        p_dir = d_img * d_txt  # Hadamard product
        x = torch.cat([d_img, d_txt, p_dir, m_img, m_txt], dim=1)
        z = self.mlp(x)
        return z


class HashLayer(nn.Module):
    """Hash å±¤"""
    
    def __init__(self, input_dim: int, hash_bits: int):
        super().__init__()
        self.fc = nn.Linear(input_dim, hash_bits)
        self.hash_bits = hash_bits
    
    def forward(self, z: torch.Tensor) -> torch.Tensor:
        """Returns soft hash codes in [-1, 1]"""
        h = torch.tanh(self.fc(z))
        return h
    
    def binarize(self, h: torch.Tensor) -> torch.Tensor:
        """For inference: convert to hard binary {-1, 1}"""
        return torch.sign(h)


class MultimodalHashKNN(nn.Module):
    """å®Œæ•´æ¨¡å‹ï¼šSigLIP2 + æ–¹å‘/å¹…åº¦åˆ†è§£ + Hadamard èåˆ + Hash + KNN"""
    
    def __init__(self, config):
        super().__init__()
        
        # SigLIP2 encoders
        print(f"è¼‰å…¥ SigLIP2 æ¨¡å‹: {config.model.siglip2_variant}")
        self.processor = Siglip2Processor.from_pretrained(
            config.model.siglip2_variant
        )
        self.model = Siglip2Model.from_pretrained(
            config.model.siglip2_variant
        )
        
        # âš ï¸ å¿…é ˆå‡çµ towersï¼ˆRTX 5080 16GB é™åˆ¶ï¼‰
        if config.model.freeze_towers:
            for param in self.model.parameters():
                param.requires_grad = False
            print("âœ“ SigLIP2 towers frozen (saving ~7.5GB VRAM)")
        
        # ç²å– embedding ç¶­åº¦
        self.embed_dim = self.model.config.projection_dim  # 768 for base
        
        # Decomposer
        self.decomposer = DirectionMagnitudeDecomposer(
            eps=config.model.decomposer.eps
        )
        
        # Fusion
        self.fusion = HadamardFusion(
            embed_dim=self.embed_dim,
            mlp_dims=config.model.fusion.mlp_dims,
            dropout=config.model.fusion.dropout,
            activation=config.model.fusion.activation
        )
        
        # Hash layer
        self.hash_layer = HashLayer(
            input_dim=config.model.fusion.mlp_dims[-1],
            hash_bits=config.model.hash.bits
        )
        
        # Classifier head (for training)
        self.classifier = nn.Linear(
            config.model.hash.bits,
            config.model.classifier.num_classes,
            bias=config.model.classifier.use_bias
        )
        
        self.config = config
    
    def forward(
        self,
        pixel_values: torch.Tensor,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None,
        return_components: bool = False
    ) -> torch.Tensor | Dict[str, torch.Tensor]:
        """
        Args:
            pixel_values: (B, C, H, W) images
            input_ids: (B, L) text tokens
            attention_mask: (B, L) attention mask
            return_components: whether to return intermediate results
        
        Returns:
            logits or dict of components
        """
        # Encode
        outputs = self.model(
            pixel_values=pixel_values,
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        v_img = outputs.image_embeds  # (B, D)
        v_txt = outputs.text_embeds   # (B, D)
        
        # Decompose
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        
        # Fuse
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        
        # Hash
        h = self.hash_layer(z)
        
        # Classify
        logits = self.classifier(h)
        
        if return_components:
            return {
                'logits': logits,
                'h': h,
                'd_img': d_img,
                'd_txt': d_txt,
                'm_img': m_img,
                'm_txt': m_txt,
                'z': z,
                'v_img': v_img,
                'v_txt': v_txt
            }
        else:
            return logits
    
    @torch.no_grad()
    def get_hash(
        self,
        pixel_values: torch.Tensor,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """For inference: return hash codes"""
        outputs = self.model(
            pixel_values=pixel_values,
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        v_img = outputs.image_embeds
        v_txt = outputs.text_embeds
        d_img, m_img = self.decomposer(v_img)
        d_txt, m_txt = self.decomposer(v_txt)
        z = self.fusion(d_img, d_txt, m_img, m_txt)
        h = self.hash_layer(z)
        return h
```

### 11.2 è³‡æ–™è¼‰å…¥å™¨ï¼ˆ`src/siglip2_multimodal_hash/dataset.py`ï¼‰

```python
# src/siglip2_multimodal_hash/dataset.py

import torch
from torch.utils.data import Dataset
from pathlib import Path
from PIL import Image
import pickle
import random
from typing import Optional

class COCOMultiLabelDataset(Dataset):
    """COCO å¤šæ¨™ç±¤è³‡æ–™é›†"""
    
    def __init__(
        self,
        data_root: str | Path,
        split: str = "train2014",
        processor = None,
        max_num_patches: int = 256,
        text_max_length: int = 64,
        use_karpathy_split: bool = False,
        karpathy_split_type: str = "train"  # "train", "val", "test"
    ):
        """
        Args:
            data_root: COCO è³‡æ–™é›†æ ¹ç›®éŒ„ï¼ˆä¾‹å¦‚ ./data/cocoï¼‰
            split: "train2014" or "val2014"
            processor: SigLIP2Processor
            max_num_patches: æœ€å¤§ patch æ•¸é‡
            text_max_length: æ–‡å­—æœ€å¤§é•·åº¦
            use_karpathy_split: æ˜¯å¦ä½¿ç”¨ Karpathy split
            karpathy_split_type: Karpathy split é¡å‹
        """
        self.data_root = Path(data_root)
        self.split = split
        self.processor = processor
        self.max_num_patches = max_num_patches
        self.text_max_length = text_max_length
        
        # è¼‰å…¥ç´¢å¼•
        index_file = self.data_root / f"index_{split}.pkl"
        print(f"è¼‰å…¥ç´¢å¼•: {index_file}")
        
        with open(index_file, "rb") as f:
            self.index = pickle.load(f)
        
        # å¦‚æœä½¿ç”¨ Karpathy splitï¼Œéœ€è¦é€²ä¸€æ­¥ç¯©é¸
        if use_karpathy_split:
            self._filter_karpathy_split(karpathy_split_type)
        
        # å»ºç«‹é¡åˆ¥æ˜ å°„ï¼ˆcategory_id -> indexï¼‰
        self.cat_id_to_idx = {
            cat_id: idx
            for idx, cat_id in enumerate(sorted(self.index["categories"].keys()))
        }
        self.num_classes = len(self.cat_id_to_idx)
        
        # å»ºç«‹å½±åƒ ID åˆ—è¡¨
        self.image_ids = list(self.index["images"].keys())
        
        print(f"âœ“ è¼‰å…¥ {len(self.image_ids)} å¼µå½±åƒ")
        print(f"âœ“ {self.num_classes} å€‹é¡åˆ¥")
    
    def _filter_karpathy_split(self, split_type: str):
        """æ ¹æ“š Karpathy split ç¯©é¸å½±åƒ"""
        import json
        
        karpathy_file = self.data_root / "karpathy_split.json"
        if not karpathy_file.exists():
            raise FileNotFoundError(
                f"Karpathy split file not found: {karpathy_file}\n"
                "è«‹åŸ·è¡Œ: python scripts/download_karpathy_split.py"
            )
        
        with open(karpathy_file) as f:
            karpathy_data = json.load(f)
        
        # å»ºç«‹ image_id -> split æ˜ å°„
        id_to_split = {}
        for item in karpathy_data["images"]:
            # COCO å½±åƒ ID æ ¼å¼ï¼šCOCO_train2014_000000123456
            filename = item["filename"]
            img_id = int(filename.split("_")[-1].split(".")[0])
            id_to_split[img_id] = item.get("split", "unknown")
        
        # ç¯©é¸å½±åƒ
        filtered_images = {
            img_id: img_info
            for img_id, img_info in self.index["images"].items()
            if id_to_split.get(img_id) == split_type
        }
        
        self.index["images"] = filtered_images
        print(f"âœ“ Karpathy {split_type} split: {len(filtered_images)} å¼µå½±åƒ")
    
    def __len__(self) -> int:
        return len(self.image_ids)
    
    def __getitem__(self, idx: int) -> dict:
        img_id = self.image_ids[idx]
        img_info = self.index["images"][img_id]
        
        # è¼‰å…¥å½±åƒ
        img_path = self.data_root / "images" / self.split / img_info["file_name"]
        image = Image.open(img_path).convert("RGB")
        
        # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ captionï¼ˆè¨“ç·´æ™‚å¢å¼·ï¼‰
        caption = random.choice(img_info["captions"])
        
        # å»ºç«‹ multi-hot label
        labels = torch.zeros(self.num_classes, dtype=torch.float32)
        for cat_id in img_info["categories"]:
            labels[self.cat_id_to_idx[cat_id]] = 1.0
        
        # ä½¿ç”¨ processor è™•ç†å½±åƒèˆ‡æ–‡å­—
        inputs = self.processor(
            text=[caption],
            images=image,
            return_tensors="pt",
            padding="max_length",
            max_length=self.text_max_length,
            truncation=True
        )
        
        # ç§»é™¤ batch ç¶­åº¦ï¼ˆå› ç‚º DataLoader æœƒè‡ªå‹• batchï¼‰
        return {
            'pixel_values': inputs['pixel_values'].squeeze(0),
            'input_ids': inputs['input_ids'].squeeze(0),
            'attention_mask': inputs['attention_mask'].squeeze(0),
            'labels': labels,
            'image_id': img_id,
            'caption': caption
        }


def create_dataloader(config, split: str = "train"):
    """å»ºç«‹ DataLoader"""
    from torch.utils.data import DataLoader
    from transformers import Siglip2Processor
    
    # è¼‰å…¥ processor
    processor = Siglip2Processor.from_pretrained(
        config.model.siglip2_variant
    )
    
    # æ±ºå®šä½¿ç”¨å“ªå€‹ COCO split
    if split == "train":
        coco_split = "train2014"
        shuffle = True
    else:
        coco_split = "val2014"
        shuffle = False
    
    # å»ºç«‹ dataset
    dataset = COCOMultiLabelDataset(
        data_root=config.paths.data_root,
        split=coco_split,
        processor=processor,
        max_num_patches=config.model.max_num_patches,
        text_max_length=config.model.text_max_length
    )
    
    # å»ºç«‹ dataloader
    dataloader = DataLoader(
        dataset,
        batch_size=config.training.batch_size,
        shuffle=shuffle,
        num_workers=config.dataloader.num_workers,
        pin_memory=config.dataloader.pin_memory,
        prefetch_factor=config.dataloader.prefetch_factor,
        persistent_workers=config.dataloader.persistent_workers,
        drop_last=config.dataloader.drop_last if split == "train" else False
    )
    
    return dataloader
```

### 11.3 æå¤±å‡½æ•¸ï¼ˆ`src/siglip2_multimodal_hash/losses.py`ï¼‰

```python
# src/siglip2_multimodal_hash/losses.py

import torch
import torch.nn as nn
import torch.nn.functional as F

def hash_regularization(
    h: torch.Tensor,
    lambda_balance: float = 0.1,
    lambda_decorr: float = 0.01
) -> torch.Tensor:
    """
    Hash æ­£å‰‡åŒ–æå¤±ï¼ˆä¸‰é …çµ„åˆï¼‰
    
    Args:
        h: (batch_size, hash_bits) soft hash codes
        lambda_balance: bit balance æ¬Šé‡
        lambda_decorr: bit decorrelation æ¬Šé‡
    
    Returns:
        loss_hash: scalar tensor
    """
    # 1. Quantization lossï¼ˆæ¨å‘ Â±1ï¼‰
    loss_quant = torch.mean((torch.abs(h) - 1) ** 2)
    
    # 2. Bit balance lossï¼ˆé¿å…æ‰€æœ‰ bit åå‘åŒä¸€æ¥µï¼‰
    bit_mean = torch.mean(h, dim=0)  # (hash_bits,)
    loss_balance = torch.mean(bit_mean ** 2)
    
    # 3. Bit decorrelation lossï¼ˆé¼“å‹µ bit ç¨ç«‹ï¼‰
    h_centered = h - torch.mean(h, dim=0, keepdim=True)
    cov = (h_centered.T @ h_centered) / h.size(0)  # (B, B)
    loss_decorr = (torch.sum(cov ** 2) - torch.trace(cov ** 2)) / (h.size(1) ** 2)
    
    # çµ„åˆ
    loss_hash = loss_quant + lambda_balance * loss_balance + lambda_decorr * loss_decorr
    
    return loss_hash


def compute_total_loss(
    outputs: dict,
    labels: torch.Tensor,
    config
) -> tuple[torch.Tensor, dict]:
    """
    è¨ˆç®—ç¸½æå¤±
    
    Args:
        outputs: æ¨¡å‹è¼¸å‡ºï¼ˆåŒ…å« logits, h, d_img, d_txt ç­‰ï¼‰
        labels: (B, C) multi-hot labels
        config: é…ç½®ç‰©ä»¶
    
    Returns:
        total_loss: ç¸½æå¤±
        loss_dict: å„é …æå¤±çš„å­—å…¸
    """
    logits = outputs['logits']
    h = outputs['h']
    d_img = outputs['d_img']
    d_txt = outputs['d_txt']
    
    # 1. BCE Lossï¼ˆä¸»è¦ç›£ç£è¨Šè™Ÿï¼‰
    loss_bce = F.binary_cross_entropy_with_logits(logits, labels)
    
    # 2. Cosine Alignment Loss
    loss_cos = 1 - F.cosine_similarity(d_img, d_txt, dim=1).mean()
    
    # 3. Hash Regularization
    loss_hash = hash_regularization(
        h,
        lambda_balance=config.loss.hash_reg.lambda_balance,
        lambda_decorr=config.loss.hash_reg.lambda_decorr
    )
    
    # çµ„åˆç¸½æå¤±
    total_loss = (
        config.loss.bce_weight * loss_bce +
        config.loss.cosine_weight * loss_cos +
        config.loss.hash_weight * loss_hash
    )
    
    # è¿”å›æå¤±å­—å…¸ï¼ˆç”¨æ–¼ loggingï¼‰
    loss_dict = {
        'total': total_loss.item(),
        'bce': loss_bce.item(),
        'cos': loss_cos.item(),
        'hash': loss_hash.item()
    }
    
    return total_loss, loss_dict


class FocalLoss(nn.Module):
    """Focal Lossï¼ˆè™•ç†é¡åˆ¥ä¸å¹³è¡¡ï¼Œå¯é¸ï¼‰"""
    
    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """
        Args:
            logits: (B, C) raw predictions
            labels: (B, C) multi-hot labels
        """
        probs = torch.sigmoid(logits)
        
        # è¨ˆç®— focal weight
        pt = torch.where(labels == 1, probs, 1 - probs)
        focal_weight = (1 - pt) ** self.gamma
        
        # BCE loss with focal weight
        bce = F.binary_cross_entropy_with_logits(logits, labels, reduction='none')
        focal_loss = self.alpha * focal_weight * bce
        
        return focal_loss.mean()
```

### 11.4 ä¸»è¨“ç·´è…³æœ¬ï¼ˆ`scripts/train.py`ï¼‰

```python
# scripts/train.py

import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from pathlib import Path
import hydra
from omegaconf import DictConfig, OmegaConf
import wandb
from tqdm import tqdm
import sys

# åŠ å…¥ src åˆ° Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from siglip2_multimodal_hash.model import MultimodalHashKNN
from siglip2_multimodal_hash.dataset import create_dataloader
from siglip2_multimodal_hash.losses import compute_total_loss
from siglip2_multimodal_hash.utils import (
    get_gpu_memory_info,
    MemoryMonitor,
    set_seed
)


def train_epoch(
    model: MultimodalHashKNN,
    dataloader,
    optimizer,
    scheduler,
    scaler: GradScaler,
    config: DictConfig,
    epoch: int
) -> dict:
    """è¨“ç·´ä¸€å€‹ epoch"""
    
    model.train()
    total_losses = {'total': 0, 'bce': 0, 'cos': 0, 'hash': 0}
    
    accumulation_steps = config.training.gradient_accumulation_steps
    memory_monitor = MemoryMonitor(config.memory_optimization.alert_vram_threshold_gb)
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}")
    
    for batch_idx, batch in enumerate(pbar):
        # ç§»åˆ° GPU
        pixel_values = batch['pixel_values'].to('cuda', non_blocking=True)
        input_ids = batch['input_ids'].to('cuda', non_blocking=True)
        attention_mask = batch['attention_mask'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        # âš ï¸ æ··åˆç²¾åº¦å‰å‘å‚³æ’­
        with autocast(dtype=torch.float16):
            outputs = model(
                pixel_values=pixel_values,
                input_ids=input_ids,
                attention_mask=attention_mask,
                return_components=True
            )
            
            # è¨ˆç®—æå¤±
            loss, loss_dict = compute_total_loss(outputs, labels, config)
            loss = loss / accumulation_steps  # æ¢¯åº¦ç´¯ç©
        
        # åå‘å‚³æ’­
        scaler.scale(loss).backward()
        
        # âš ï¸ æ¢¯åº¦ç´¯ç©
        if (batch_idx + 1) % accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(
                model.parameters(),
                config.training.gradient_clip_norm
            )
            
            # æ›´æ–°åƒæ•¸
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
        
        # ç´¯ç©æå¤±
        for key in total_losses:
            total_losses[key] += loss_dict[key]
        
        # æ›´æ–°é€²åº¦æ¢
        pbar.set_postfix({
            'loss': loss_dict['total'],
            'bce': loss_dict['bce'],
            'mem': f"{memory_monitor.get_stats()['gpu']['allocated_gb']:.1f}GB"
        })
        
        # âš ï¸ å®šæœŸç›£æ§è¨˜æ†¶é«”
        if batch_idx % config.logging.log_every_n_steps == 0:
            if config.memory_optimization.log_gpu_memory:
                memory_monitor.print_stats(f"Batch {batch_idx} - ")
        
        # âš ï¸ å®šæœŸæ¸…ç†å¿«å–
        if batch_idx % config.memory_optimization.empty_cache_steps == 0:
            torch.cuda.empty_cache()
    
    # æ›´æ–°å­¸ç¿’ç‡
    scheduler.step()
    
    # è¿”å›å¹³å‡æå¤±
    n_batches = len(dataloader)
    return {k: v / n_batches for k, v in total_losses.items()}


@torch.no_grad()
def validate(
    model: MultimodalHashKNN,
    dataloader,
    config: DictConfig
) -> dict:
    """é©—è­‰"""
    
    model.eval()
    total_losses = {'total': 0, 'bce': 0, 'cos': 0, 'hash': 0}
    all_logits = []
    all_labels = []
    
    pbar = tqdm(dataloader, desc="Validating")
    
    for batch in pbar:
        pixel_values = batch['pixel_values'].to('cuda', non_blocking=True)
        input_ids = batch['input_ids'].to('cuda', non_blocking=True)
        attention_mask = batch['attention_mask'].to('cuda', non_blocking=True)
        labels = batch['labels'].to('cuda', non_blocking=True)
        
        with autocast(dtype=torch.float16):
            outputs = model(
                pixel_values=pixel_values,
                input_ids=input_ids,
                attention_mask=attention_mask,
                return_components=True
            )
            
            loss, loss_dict = compute_total_loss(outputs, labels, config)
        
        # ç´¯ç©
        for key in total_losses:
            total_losses[key] += loss_dict[key]
        
        all_logits.append(outputs['logits'].cpu())
        all_labels.append(labels.cpu())
    
    # è¨ˆç®—æŒ‡æ¨™
    from sklearn.metrics import average_precision_score, f1_score
    
    all_logits = torch.cat(all_logits, dim=0)
    all_labels = torch.cat(all_labels, dim=0)
    
    y_true = all_labels.numpy()
    y_scores = torch.sigmoid(all_logits).numpy()
    y_pred = (y_scores > 0.5).astype(int)
    
    metrics = {
        'loss': total_losses['total'] / len(dataloader),
        'mAP': average_precision_score(y_true, y_scores, average='macro'),
        'f1_micro': f1_score(y_true, y_pred, average='micro'),
        'f1_macro': f1_score(y_true, y_pred, average='macro'),
    }
    
    return metrics


@hydra.main(version_base=None, config_path="../configs/hardware", config_name="rtx5080_16gb")
def main(config: DictConfig):
    """ä¸»è¨“ç·´å‡½æ•¸"""
    
    # é¡¯ç¤ºé…ç½®
    print("="*60)
    print("è¨“ç·´é…ç½®")
    print("="*60)
    print(OmegaConf.to_yaml(config))
    print("="*60)
    
    # è¨­å®š seed
    set_seed(config.experiment.seed)
    
    # åˆå§‹åŒ– wandb
    if config.logging.use_wandb:
        wandb.init(
            project=config.logging.wandb_project,
            entity=config.logging.wandb_entity,
            config=OmegaConf.to_container(config, resolve=True),
            name=config.experiment.name
        )
    
    # å»ºç«‹æ¨¡å‹
    print("\nå»ºç«‹æ¨¡å‹...")
    model = MultimodalHashKNN(config).cuda()
    
    # é¡¯ç¤ºè¨˜æ†¶é«”è³‡è¨Š
    mem_info = get_gpu_memory_info()
    print(f"æ¨¡å‹è¼‰å…¥å¾Œ GPU è¨˜æ†¶é«”: {mem_info['allocated_gb']:.2f}GB / 16GB")
    
    # å»ºç«‹ DataLoader
    print("\nå»ºç«‹ DataLoader...")
    train_loader = create_dataloader(config, split='train')
    val_loader = create_dataloader(config, split='val')
    
    # å»ºç«‹ optimizer èˆ‡ scheduler
    print("\nå»ºç«‹ optimizer èˆ‡ scheduler...")
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.optimizer.lr,
        weight_decay=config.optimizer.weight_decay,
        betas=config.optimizer.betas
    )
    
    from transformers import get_cosine_schedule_with_warmup
    
    num_training_steps = len(train_loader) * config.training.num_epochs
    num_warmup_steps = int(num_training_steps * config.scheduler.warmup_ratio)
    
    scheduler = get_cosine_schedule_with_warmup(
        optimizer,
        num_warmup_steps=num_warmup_steps,
        num_training_steps=num_training_steps,
        num_cycles=1
    )
    
    # æ··åˆç²¾åº¦ scaler
    scaler = GradScaler()
    
    # è¨“ç·´è¿´åœˆ
    print("\né–‹å§‹è¨“ç·´...")
    print("="*60)
    
    best_val_map = 0
    patience_counter = 0
    
    for epoch in range(config.training.num_epochs):
        print(f"\nEpoch {epoch+1}/{config.training.num_epochs}")
        print("-"*60)
        
        # è¨“ç·´
        train_losses = train_epoch(
            model, train_loader, optimizer, scheduler, scaler, config, epoch
        )
        
        print(f"Train - Loss: {train_losses['total']:.4f} "
              f"(BCE: {train_losses['bce']:.4f}, "
              f"Cos: {train_losses['cos']:.4f}, "
              f"Hash: {train_losses['hash']:.4f})")
        
        # é©—è­‰
        if (epoch + 1) % config.training.val_every_n_epochs == 0:
            val_metrics = validate(model, val_loader, config)
            
            print(f"Val   - Loss: {val_metrics['loss']:.4f}, "
                  f"mAP: {val_metrics['mAP']:.4f}, "
                  f"F1-Micro: {val_metrics['f1_micro']:.4f}, "
                  f"F1-Macro: {val_metrics['f1_macro']:.4f}")
            
            # è¨˜éŒ„åˆ° wandb
            if config.logging.use_wandb:
                wandb.log({
                    'epoch': epoch,
                    'train/loss': train_losses['total'],
                    'train/loss_bce': train_losses['bce'],
                    'train/loss_cos': train_losses['cos'],
                    'train/loss_hash': train_losses['hash'],
                    'val/loss': val_metrics['loss'],
                    'val/mAP': val_metrics['mAP'],
                    'val/f1_micro': val_metrics['f1_micro'],
                    'val/f1_macro': val_metrics['f1_macro'],
                    'lr': optimizer.param_groups[0]['lr']
                })
            
            # å„²å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['mAP'] > best_val_map:
                best_val_map = val_metrics['mAP']
                patience_counter = 0
                
                # å„²å­˜ checkpoint
                checkpoint_dir = Path(config.checkpointing.save_dir)
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                checkpoint_path = checkpoint_dir / f"best_model_epoch{epoch+1}_mAP{val_metrics['mAP']:.4f}.pth"
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'val_mAP': val_metrics['mAP'],
                    'config': OmegaConf.to_container(config, resolve=True)
                }, checkpoint_path)
                
                print(f"âœ“ å„²å­˜æœ€ä½³æ¨¡å‹: {checkpoint_path}")
            else:
                patience_counter += 1
            
            # Early stopping
            if patience_counter >= config.training.early_stopping_patience:
                print(f"\nEarly stopping triggered after {epoch+1} epochs")
                break
    
    print("\n" + "="*60)
    print("è¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³ Val mAP: {best_val_map:.4f}")
    print("="*60)
    
    if config.logging.use_wandb:
        wandb.finish()


if __name__ == "__main__":
    main()
```

### 11.5 å·¥å…·å‡½æ•¸ï¼ˆ`src/siglip2_multimodal_hash/utils.py`ï¼‰

```python
# src/siglip2_multimodal_hash/utils.py

import torch
import random
import numpy as np
from typing import Dict

def set_seed(seed: int = 42):
    """è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡ç¾æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # ä»¥ä¸‹è¨­å®šæœƒæ¸›æ…¢è¨“ç·´ï¼Œä½†ä¿è­‰å¯é‡ç¾
    # torch.backends.cudnn.deterministic = True
    # torch.backends.cudnn.benchmark = False


def get_gpu_memory_info() -> Dict[str, float]:
    """ç²å– GPU è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        max_allocated = torch.cuda.max_memory_allocated() / 1e9
        
        return {
            "allocated_gb": allocated,
            "reserved_gb": reserved,
            "max_allocated_gb": max_allocated,
            "free_gb": 16.0 - reserved
        }
    return {}


class MemoryMonitor:
    """è¨˜æ†¶é«”ç›£æ§å·¥å…·"""
    
    def __init__(self, alert_threshold_gb: float = 14.5):
        self.alert_threshold_gb = alert_threshold_gb
        self.peak_vram = 0
    
    def get_stats(self) -> dict:
        """ç²å–å®Œæ•´è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = {}
        
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            max_allocated = torch.cuda.max_memory_allocated() / 1e9
            
            stats['gpu'] = {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'max_allocated_gb': max_allocated,
                'free_gb': 16.0 - reserved,
                'utilization_%': allocated / 16.0 * 100
            }
            
            self.peak_vram = max(self.peak_vram, allocated)
            
            if allocated > self.alert_threshold_gb:
                stats['gpu']['alert'] = True
        
        return stats
    
    def print_stats(self, prefix: str = ""):
        """åˆ—å°è¨˜æ†¶é«”çµ±è¨ˆ"""
        stats = self.get_stats()
        
        if 'gpu' in stats:
            gpu = stats['gpu']
            print(f"{prefix}GPU: {gpu['allocated_gb']:.2f}GB / 16GB "
                  f"({gpu['utilization_%']:.1f}%), "
                  f"Peak: {self.peak_vram:.2f}GB")
            
            if gpu.get('alert'):
                print(f"  âš ï¸  WARNING: VRAM usage high!")
    
    def reset_peak(self):
        """é‡ç½®å³°å€¼çµ±è¨ˆ"""
        torch.cuda.reset_peak_memory_stats()
        self.peak_vram = 0
```

---

## 12) è©•ä¼°æŒ‡æ¨™

ï¼ˆèˆ‡ v2.1 ç›¸åŒï¼Œçœç•¥ï¼‰

---

## 13) ç¡¬é«”ç‰¹å®šå„ªåŒ–

### 13.1 è¨˜æ†¶é«”ä½¿ç”¨æª¢æŸ¥æ¸…å–®

åœ¨é–‹å§‹è¨“ç·´å‰ï¼Œç¢ºèªä»¥ä¸‹æ‰€æœ‰é …ç›®ï¼š

```bash
# åŸ·è¡Œæª¢æŸ¥è…³æœ¬
cat > scripts/check_memory_config.py << 'EOF'
#!/usr/bin/env python3
import yaml
from pathlib import Path

def check_config():
    config_file = Path("configs/hardware/rtx5080_16gb.yaml")
    
    if not config_file.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return False
    
    with open(config_file) as f:
        config = yaml.safe_load(f)
    
    checks = {
        "âœ… Mixed precision enabled": config['memory_optimization']['mixed_precision'],
        "âœ… Batch size <= 32": config['training']['batch_size'] <= 32,
        "âœ… Towers frozen": config['model']['freeze_towers'],
        "âœ… Gradient accumulation >= 2": config['training']['gradient_accumulation_steps'] >= 2,
        "âœ… Not using SigLIP-large": 'base' in config['model']['siglip2_variant'],
        "âœ… num_workers optimized": config['dataloader']['num_workers'] >= 8,
    }
    
    print("è¨˜æ†¶é«”å„ªåŒ–é…ç½®æª¢æŸ¥:")
    for check, passed in checks.items():
        symbol = "âœ…" if passed else "âŒ"
        print(f"  {symbol} {check.replace('âœ…', '').replace('âŒ', '')}")
    
    if all(checks.values()):
        print("\nâœ… æ‰€æœ‰æª¢æŸ¥é€šéï¼å¯ä»¥å®‰å…¨è¨“ç·´ã€‚")
        return True
    else:
        print("\nâš ï¸  éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œå»ºè­°ä¿®æ­£å¾Œå†è¨“ç·´ã€‚")
        return False

if __name__ == "__main__":
    check_config()
EOF

chmod +x scripts/check_memory_config.py
python scripts/check_memory_config.py
```

---

## 14) åƒè€ƒæ–‡ç»

### æ ¸å¿ƒæ–¹æ³•

1. **SigLIP 2**: Jiasen Lu, et al. "SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features". arXiv:2502.14786, 2025.

2. **MS-COCO Dataset**: Tsung-Yi Lin, et al. "Microsoft COCO: Common Objects in Context". ECCV 2014.

3. **MS-COCO Captions**: Xinlei Chen, et al. "Microsoft COCO Captions: Data Collection and Evaluation Server". arXiv:1504.00325, 2015.

### Hash æ–¹æ³•

1. **Deep Supervised Discrete Hashing**: Qi Li, et al. "Deep Supervised Discrete Hashing". NeurIPS 2017.

2. **HashNet**: Zhangjie Cao, et al. "HashNet: Deep Learning to Hash by Continuation". ICCV 2017.

3. **Learning to Hash Survey**: Jun Wang, et al. "Learning to Hash for Indexing Big Data - A Survey". Proceedings of the IEEE, 2015.

### å¤šæ¨¡æ…‹èåˆ

1. **MCB**: Akira Fukui, et al. "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding". EMNLP 2016.

2. **MUTAN**: Hedi Ben-younes, et al. "MUTAN: Multimodal Tucker Fusion for Visual Question Answering". ICCV 2017.

### KNN èˆ‡ Multi-label

1. **Ranking-based KNN**: Derek Hoiem, et al. "A Ranking-based KNN Approach for Multi-label Classification". AISTATS 2012.

### è¨“ç·´æŠ€å·§

1. **Focal Loss**: Tsung-Yi Lin, et al. "Focal Loss for Dense Object Detection". ICCV 2017.

2. **Mixed Precision Training**: Paulius Micikevicius, et al. "Mixed Precision Training". ICLR 2018.

---

## 15) é™„éŒ„

### é™„éŒ„ A: å¿«é€Ÿå•Ÿå‹•æŒ‡ä»¤ï¼ˆâ­ å°æ‡‰ä½ çš„å°ˆæ¡ˆï¼‰

```bash
# ==========================================
# 0. åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„
# ==========================================
cd ~/Documents/Coding/github.com/natsuki221/AGCH-Improvement

# ==========================================
# 1. å•Ÿå‹•è™›æ“¬ç’°å¢ƒï¼ˆå¦‚æœä½¿ç”¨ conda baseï¼‰
# ==========================================
# ä½ ç›®å‰åœ¨ (AGCH-Improvement) (base)ï¼Œæ‡‰è©²å·²ç¶“å•Ÿå‹•

# ==========================================
# 2. é©—è­‰ç’°å¢ƒ
# ==========================================
python scripts/verify_setup.py

# ==========================================
# 3. å»ºç«‹è³‡æ–™é›†ç´¢å¼•ï¼ˆå¦‚æœé‚„æ²’å»ºç«‹ï¼‰
# ==========================================
python scripts/create_dataset_index.py

# ==========================================
# 4. ä¸‹è¼‰ Karpathy split
# ==========================================
python scripts/download_karpathy_split.py

# ==========================================
# 5. æ¸¬è©¦ SigLIP2 è¼‰å…¥
# ==========================================
python scripts/test_siglip2.py

# ==========================================
# 6. åˆ†æè³‡æ–™é›†çµ±è¨ˆ
# ==========================================
python scripts/analyze_dataset.py

# ==========================================
# 7. æª¢æŸ¥è¨˜æ†¶é«”é…ç½®
# ==========================================
python scripts/check_memory_config.py

# ==========================================
# 8. é–‹å§‹è¨“ç·´ï¼ˆBaselineï¼‰
# ==========================================
python scripts/train.py \
  --config-name rtx5080_16gb \
  experiment.name=baseline_run1

# ==========================================
# 9. ç›£æ§è¨“ç·´ï¼ˆå¦é–‹çµ‚ç«¯ï¼‰
# ==========================================
watch -n 1 nvidia-smi

# ==========================================
# 10. æŸ¥çœ‹ wandb è¨“ç·´æ›²ç·š
# ==========================================
# é–‹å•Ÿç€è¦½å™¨: https://wandb.ai/natsuki221/siglip2-multimodal-hash
```

### é™„éŒ„ B: ç›®å‰å°ˆæ¡ˆç‹€æ…‹æª¢æŸ¥æ¸…å–®

#### âœ… å·²å®Œæˆ

- [x] å°ˆæ¡ˆç›®éŒ„çµæ§‹å»ºç«‹
- [x] `.gitignore` è¨­å®š
- [x] `pyproject.toml` é…ç½®ï¼ˆå« CUDA 12.4ï¼‰
- [x] `requirements.txt` ç”Ÿæˆ
- [x] COCO 2014 è³‡æ–™é›†ä¸‹è¼‰
- [x] åŸºæœ¬è…³æœ¬å»ºç«‹ï¼ˆä¸‹è¼‰ã€åˆ†æã€é©—è­‰ï¼‰
- [x] è™›æ“¬ç’°å¢ƒè¨­å®š

#### âš ï¸ å¾…å®Œæˆ

- [ ] å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬
- [ ] å»ºç«‹è³‡æ–™é›†ç´¢å¼•ï¼ˆ`index_train2014.pkl`, `index_val2014.pkl`ï¼‰
- [ ] ä¸‹è¼‰ Karpathy splitï¼ˆ`karpathy_split.json`ï¼‰
- [ ] å»ºç«‹é…ç½®æª”æ¡ˆï¼ˆ`configs/hardware/rtx5080_16gb.yaml`ï¼‰
- [ ] å¯¦ä½œæ¨¡å‹ç¨‹å¼ç¢¼ï¼ˆ`src/siglip2_multimodal_hash/*.py`ï¼‰
- [ ] å»ºç«‹è¨“ç·´è…³æœ¬ï¼ˆ`scripts/train.py`ï¼‰
- [ ] åŸ·è¡Œç¬¬ä¸€è¼ª baseline è¨“ç·´

### é™„éŒ„ C: ä¸‹ä¸€æ­¥æ“ä½œé †åº

```bash
# æ­¥é©Ÿ 1: å‡ç´š FAISSï¼ˆæ“‡ä¸€ï¼‰
conda install -c pytorch -c nvidia faiss-gpu
# æˆ–å¾æºç¢¼ç·¨è­¯ï¼ˆè¦‹ 2.4 ç¯€ï¼‰

# æ­¥é©Ÿ 2: å»ºç«‹è³‡æ–™é›†ç´¢å¼•
python scripts/create_dataset_index.py
python scripts/download_karpathy_split.py

# æ­¥é©Ÿ 3: å»ºç«‹é…ç½®ç›®éŒ„èˆ‡æª”æ¡ˆ
mkdir -p configs/{hardware,experiments}

# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ configs/hardware/rtx5080_16gb.yaml
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ configs/experiments/baseline.yaml

# æ­¥é©Ÿ 4: å»ºç«‹æ¨¡å‹ç¨‹å¼ç¢¼
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ src/siglip2_multimodal_hash/*.py

# æ­¥é©Ÿ 5: å»ºç«‹è¨“ç·´è…³æœ¬
# è¤‡è£½æœ¬æ–‡ä»¶ä¸­çš„ scripts/train.py

# æ­¥é©Ÿ 6: é©—è­‰ç’°å¢ƒ
python scripts/verify_setup.py
python scripts/check_memory_config.py

# æ­¥é©Ÿ 7: é–‹å§‹è¨“ç·´ï¼
python scripts/train.py
```

---

## çµèª

æœ¬å¯¦é©—è¨ˆç•«å·²å®Œå…¨é‡å°ä½ çš„ **AGCH-Improvement å°ˆæ¡ˆ**é€²è¡Œå„ªåŒ–ï¼š

### âœ… ä¸»è¦ç‰¹é»

1. **å®Œå…¨åŒ¹é…ä½ çš„å°ˆæ¡ˆçµæ§‹** - æ‰€æœ‰è·¯å¾‘ã€æª”æ¡ˆåç¨±éƒ½å°æ‡‰
2. **CUDA 12.4 æ­£ç¢ºé…ç½®** - ä¸æ˜¯ 13.0
3. **PyTorch 2.6.0+cu124** - å°æ‡‰ä½ çš„ pyproject.toml
4. **RTX 5080 16GB å„ªåŒ–** - batch_size=32, æ··åˆç²¾åº¦, æ¢¯åº¦ç´¯ç©
5. **å¯ç«‹å³ä½¿ç”¨çš„ç¨‹å¼ç¢¼** - æ‰€æœ‰è…³æœ¬éƒ½æ˜¯å®Œæ•´ä¸”å¯åŸ·è¡Œçš„
6. **æ•´åˆç¾æœ‰è…³æœ¬** - ä½¿ç”¨ä½ å·²å»ºç«‹çš„ scripts/

### ğŸ“Š é æœŸæ•ˆèƒ½

- è¨“ç·´é€Ÿåº¦: ~1.8 iter/s
- æ¯ epoch: ~35 åˆ†é˜
- å®Œæ•´è¨“ç·´: **~17.5 å°æ™‚**
- VRAM ä½¿ç”¨: **~10.2 GB / 16 GB**

### ğŸ¯ ç«‹å³é–‹å§‹

1. å‡ç´š FAISS åˆ° GPU ç‰ˆæœ¬
2. å»ºç«‹è³‡æ–™é›†ç´¢å¼•
3. è¤‡è£½é…ç½®æª”æ¡ˆèˆ‡æ¨¡å‹ç¨‹å¼ç¢¼
4. åŸ·è¡Œç¬¬ä¸€è¼ªè¨“ç·´

ç¥å¯¦é©—é †åˆ©ï¼ğŸš€
