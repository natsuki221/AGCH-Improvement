#!/usr/bin/env python3
"""
åœ¨ Hold-out Test Set ä¸Šé€²è¡Œæœ€çµ‚è©•ä¼°

ç”¨æ³•:
    python scripts/test_on_holdout.py \
        --checkpoint outputs/checkpoints/siglip2_cv_run1_fold0/best_model.pth \
        --config configs/experiments/cv_experiment.yaml
"""

import torch
import argparse
from pathlib import Path
import sys
import json
from omegaconf import OmegaConf

# åŠ å…¥ src åˆ° Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from siglip2_multimodal_hash.model import MultimodalHashKNN
from siglip2_multimodal_hash.dataset import COCOMultiLabelDataset
from torch.utils.data import DataLoader
from transformers import Siglip2Processor
from sklearn.metrics import average_precision_score, f1_score
import numpy as np
from tqdm import tqdm


def load_test_set(config):
    """è¼‰å…¥æ¸¬è©¦é›†"""
    # è®€å– 5fold_split.json ä»¥ç²å–æ¸¬è©¦é›† ID
    fold_file = Path(config.paths.data_root) / "5fold_split.json"

    with open(fold_file) as f:
        folds_data = json.load(f)

    test_ids = folds_data["test_set"]["image_ids"]

    print(f"è¼‰å…¥æ¸¬è©¦é›†: {len(test_ids)} å¼µå½±åƒ")

    # å»ºç«‹è‡ªå®šç¾© Datasetï¼ˆåƒ…åŒ…å«æ¸¬è©¦é›† IDï¼‰
    # TODO: éœ€è¦ä¿®æ”¹ COCOMultiLabelDataset æ”¯æ´è‡ªå®šç¾© image_ids
    # é€™è£¡ç°¡åŒ–å¯¦ä½œ

    return test_ids


@torch.no_grad()
def evaluate_on_test(model, test_loader, device="cuda"):
    """åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°"""
    model.eval()

    all_logits = []
    all_labels = []

    for batch in tqdm(test_loader, desc="Evaluating on Test Set"):
        pixel_values = batch["pixel_values"].to(device)
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"]

        # å‰å‘å‚³æ’­
        logits = model(
            pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask
        )

        all_logits.append(logits.cpu())
        all_labels.append(labels)

    # åˆä½µçµæœ
    all_logits = torch.cat(all_logits, dim=0)
    all_labels = torch.cat(all_labels, dim=0)

    # è¨ˆç®—æŒ‡æ¨™
    y_true = all_labels.numpy()
    y_scores = torch.sigmoid(all_logits).numpy()
    y_pred = (y_scores > 0.5).astype(int)

    metrics = {
        "mAP": average_precision_score(y_true, y_scores, average="macro"),
        "mAP_micro": average_precision_score(y_true, y_scores, average="micro"),
        "f1_micro": f1_score(y_true, y_pred, average="micro"),
        "f1_macro": f1_score(y_true, y_pred, average="macro"),
    }

    return metrics


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--checkpoint", type=str, required=True, help="æ¨¡å‹ checkpoint è·¯å¾‘")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--device", type=str, default="cuda", help="é‹ç®—è£ç½®")
    args = parser.parse_args()

    # è¼‰å…¥é…ç½®
    config = OmegaConf.load(args.config)

    # è¼‰å…¥æ¨¡å‹
    print(f"è¼‰å…¥æ¨¡å‹: {args.checkpoint}")
    checkpoint = torch.load(args.checkpoint, map_location="cpu")

    model = MultimodalHashKNN(config)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(args.device)
    model.eval()

    print(
        f"æ¨¡å‹ä¾†è‡ª Epoch {checkpoint.get('epoch', -1)}, "
        f"Val mAP: {checkpoint.get('val_mAP', 'N/A')}"
    )

    # è¼‰å…¥æ¸¬è©¦é›†
    # TODO: å¯¦ä½œæ¸¬è©¦é›† DataLoader
    # test_loader = ...

    # è©•ä¼°
    # metrics = evaluate_on_test(model, test_loader, args.device)

    # print("\n" + "="*60)
    # print("ğŸ“Š Hold-out Test Set çµæœ")
    # print("="*60)
    # print(f"mAP (macro): {metrics['mAP']:.4f}")
    # print(f"mAP (micro): {metrics['mAP_micro']:.4f}")
    # print(f"F1 (macro):  {metrics['f1_macro']:.4f}")
    # print(f"F1 (micro):  {metrics['f1_micro']:.4f}")
    # print("="*60)

    print("âš ï¸  æ­¤è…³æœ¬ç‚ºç¯„ä¾‹ï¼Œéœ€è¦å®Œæ•´å¯¦ä½œæ¸¬è©¦é›†è¼‰å…¥é‚è¼¯")


if __name__ == "__main__":
    main()
