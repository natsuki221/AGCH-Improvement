#!/usr/bin/env python3
"""
èšåˆ 5-Fold Cross-Validation çš„å¯¦é©—çµæœ
æ”¯æ´æ‰€æœ‰å¤šæ¨™ç±¤åˆ†é¡ç ”ç©¶å¸¸ç”¨æŒ‡æ¨™

ç”¨æ³•:
    python scripts/aggregate_cv_results.py --exp_prefix siglip2_cv_run1_fold
"""

import argparse
import glob
import torch
import numpy as np
from pathlib import Path
import json
import re

# æ‰€æœ‰è¿½è¹¤çš„æŒ‡æ¨™åŠå…¶æ–¹å‘ï¼ˆTrue=è¶Šé«˜è¶Šå¥½ï¼ŒFalse=è¶Šä½è¶Šå¥½ï¼‰
METRICS = {
    "mAP": ("mAP (â†‘)", True),
    "auc_macro": ("AUC-Macro (â†‘)", True),
    "auc_micro": ("AUC-Micro (â†‘)", True),
    "f1_macro": ("F1-Macro (â†‘)", True),
    "f1_micro": ("F1-Micro (â†‘)", True),
    "precision_macro": ("Precision-Macro (â†‘)", True),
    "precision_micro": ("Precision-Micro (â†‘)", True),
    "recall_macro": ("Recall-Macro (â†‘)", True),
    "recall_micro": ("Recall-Micro (â†‘)", True),
    "lrap": ("LRAP (â†‘)", True),
    "hamming_loss": ("Hamming Loss (â†“)", False),
    "ranking_loss": ("Ranking Loss (â†“)", False),
    "coverage_error": ("Coverage Error (â†“)", False),
    "mae": ("MAE (â†“)", False),
}


def compute_stats(values):
    """è¨ˆç®—çµ±è¨ˆé‡"""
    return {
        "mean": float(np.mean(values)),
        "std": float(np.std(values, ddof=1)) if len(values) > 1 else 0.0,
        "min": float(np.min(values)),
        "max": float(np.max(values)),
        "median": float(np.median(values)),
    }


def main():
    parser = argparse.ArgumentParser(description="èšåˆ 5-Fold CV çµæœ")
    parser.add_argument(
        "--exp_prefix", type=str, required=True, help="å¯¦é©—åç¨±å‰ç¶´ï¼ˆä¾‹å¦‚: siglip2_cv_run1_foldï¼‰"
    )
    parser.add_argument("--results_dir", type=str, default="outputs/checkpoints", help="çµæœç›®éŒ„")
    parser.add_argument(
        "--output_file", type=str, default="cv_results_summary.json", help="è¼¸å‡ºæª”æ¡ˆåç¨±"
    )
    args = parser.parse_args()

    # æœå°‹æ‰€æœ‰ fold çš„æ¨¡å‹
    pattern = f"{args.results_dir}/{args.exp_prefix}*/*.pth"
    files = glob.glob(pattern)

    print(f"æœå°‹è·¯å¾‘: {pattern}")
    print(f"æ‰¾åˆ° {len(files)} å€‹æ¨¡å‹æª”æ¡ˆ\n")

    if not files:
        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçµæœã€‚")
        return

    # æ”¶é›†æ¯å€‹ fold çš„æ‰€æœ‰æŒ‡æ¨™
    fold_results = []
    metrics_by_fold = {m: {} for m in METRICS.keys()}

    for f in sorted(files):
        try:
            ckpt = torch.load(f, map_location="cpu", weights_only=False)

            fold_name = Path(f).parent.name
            epoch = ckpt.get("epoch", -1)

            # å˜—è©¦å¾ val_metrics å–å¾—å®Œæ•´æŒ‡æ¨™ï¼ˆæ–°æ ¼å¼ï¼‰
            val_metrics = ckpt.get("val_metrics", None)

            # å‘å¾Œå…¼å®¹ï¼šå¾å–®ç¨æ¬„ä½å–å¾—
            if val_metrics is None:
                val_metrics = {"mAP": ckpt.get("val_mAP", None)}

            if val_metrics.get("mAP") is None:
                print(f" âš ï¸ {fold_name}: ç„¡ mAP è³‡è¨Šï¼Œè·³é")
                continue

            # æå– fold ç·¨è™Ÿ
            match = re.search(r"fold(\d+)", fold_name)
            fold_idx = int(match.group(1)) if match else -1

            # æ”¶é›†çµæœ
            fold_info = {
                "fold": fold_idx,
                "fold_name": fold_name,
                "epoch": epoch,
                "checkpoint_path": str(f),
                "metrics": {},
            }

            for metric_key in METRICS.keys():
                value = val_metrics.get(metric_key)
                if value is not None:
                    fold_info["metrics"][metric_key] = float(value)
                    metrics_by_fold[metric_key][fold_idx] = float(value)

            fold_results.append(fold_info)

            # é¡¯ç¤ºæ¯å€‹ fold çš„çµæœ
            mAP = val_metrics.get("mAP", 0)
            auc = val_metrics.get("auc_macro", 0)
            f1 = val_metrics.get("f1_macro", 0)
            print(
                f" - Fold {fold_idx}: Epoch {epoch:2d} | mAP={mAP:.4f} | AUC={auc:.4f} | F1={f1:.4f}"
            )

        except Exception as e:
            print(f" âŒ è®€å–éŒ¯èª¤ {f}: {e}")

    if not fold_results:
        print("\nâš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçµæœã€‚")
        return

    # è¨ˆç®—æ‰€æœ‰æŒ‡æ¨™çš„çµ±è¨ˆé‡
    all_stats = {}

    print("\n" + "=" * 70)
    print("ğŸ† 5-Fold Cross-Validation æœ€çµ‚çµæœ")
    print("=" * 70)

    # ä¸»è¦æŒ‡æ¨™è¡¨æ ¼
    print("\nğŸ“Š ä¸»è¦æŒ‡æ¨™:")
    print("-" * 50)
    print(f"{'æŒ‡æ¨™':<25} {'Mean':>10} {'Â± Std':>10}")
    print("-" * 50)

    for metric_key, (display_name, higher_better) in METRICS.items():
        values = list(metrics_by_fold[metric_key].values())
        if values:
            stats = compute_stats(values)
            all_stats[metric_key] = stats
            print(f"{display_name:<25} {stats['mean']:>10.4f} {stats['std']:>9.4f}")

    print("-" * 50)

    # è«–æ–‡æ ¼å¼
    print("\nğŸ“ è«–æ–‡å ±å‘Šæ ¼å¼:")
    print("=" * 70)

    key_metrics = ["mAP", "auc_macro", "f1_macro", "precision_macro", "recall_macro"]
    for m in key_metrics:
        if m in all_stats:
            stats = all_stats[m]
            display = METRICS[m][0].split(" ")[0]
            print(f"   {display}: {stats['mean']:.2f} Â± {stats['std']:.2f}")

    print("=" * 70)

    # å„²å­˜å®Œæ•´çµæœ
    summary = {
        "experiment": args.exp_prefix,
        "num_folds": len(fold_results),
        "statistics": all_stats,
        "fold_results": fold_results,
    }

    output_path = Path(args.results_dir) / args.output_file
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ å®Œæ•´çµæœå·²å„²å­˜è‡³: {output_path}")


if __name__ == "__main__":
    main()
